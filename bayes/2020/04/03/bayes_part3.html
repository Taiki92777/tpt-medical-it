<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>ベイズ勉強会 Part 3 1次元ガウス分布のベイズ推論 | T/T</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="ベイズ勉強会 Part 3 1次元ガウス分布のベイズ推論" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="1次元ガウス分布のベイズ推論を実践する" />
<meta property="og:description" content="1次元ガウス分布のベイズ推論を実践する" />
<link rel="canonical" href="https://vintea01.github.io/tpt-medical-it/bayes/2020/04/03/bayes_part3.html" />
<meta property="og:url" content="https://vintea01.github.io/tpt-medical-it/bayes/2020/04/03/bayes_part3.html" />
<meta property="og:site_name" content="T/T" />
<meta property="og:image" content="https://vintea01.github.io/tpt-medical-it/images/dag1.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-03T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-04-03T00:00:00-05:00","dateModified":"2020-04-03T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://vintea01.github.io/tpt-medical-it/bayes/2020/04/03/bayes_part3.html"},"description":"1次元ガウス分布のベイズ推論を実践する","image":"https://vintea01.github.io/tpt-medical-it/images/dag1.png","@type":"BlogPosting","url":"https://vintea01.github.io/tpt-medical-it/bayes/2020/04/03/bayes_part3.html","headline":"ベイズ勉強会 Part 3 1次元ガウス分布のベイズ推論","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/tpt-medical-it/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://vintea01.github.io/tpt-medical-it/feed.xml" title="T/T" /><link rel="shortcut icon" type="image/x-icon" href="/tpt-medical-it/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>ベイズ勉強会 Part 3 1次元ガウス分布のベイズ推論 | T/T</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="ベイズ勉強会 Part 3 1次元ガウス分布のベイズ推論" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="1次元ガウス分布のベイズ推論を実践する" />
<meta property="og:description" content="1次元ガウス分布のベイズ推論を実践する" />
<link rel="canonical" href="https://vintea01.github.io/tpt-medical-it/bayes/2020/04/03/bayes_part3.html" />
<meta property="og:url" content="https://vintea01.github.io/tpt-medical-it/bayes/2020/04/03/bayes_part3.html" />
<meta property="og:site_name" content="T/T" />
<meta property="og:image" content="https://vintea01.github.io/tpt-medical-it/images/dag1.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-03T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2020-04-03T00:00:00-05:00","dateModified":"2020-04-03T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://vintea01.github.io/tpt-medical-it/bayes/2020/04/03/bayes_part3.html"},"description":"1次元ガウス分布のベイズ推論を実践する","image":"https://vintea01.github.io/tpt-medical-it/images/dag1.png","@type":"BlogPosting","url":"https://vintea01.github.io/tpt-medical-it/bayes/2020/04/03/bayes_part3.html","headline":"ベイズ勉強会 Part 3 1次元ガウス分布のベイズ推論","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://vintea01.github.io/tpt-medical-it/feed.xml" title="T/T" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/tpt-medical-it/">T/T</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/tpt-medical-it/about/">About Me</a><a class="page-link" href="/tpt-medical-it/search/">Search</a><a class="page-link" href="/tpt-medical-it/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">ベイズ勉強会 Part 3 1次元ガウス分布のベイズ推論</h1><p class="page-description">1次元ガウス分布のベイズ推論を実践する</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-04-03T00:00:00-05:00" itemprop="datePublished">
        Apr 3, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/tpt-medical-it/categories/#bayes">bayes</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#1次元ガウス分布">1次元ガウス分布 </a></li>
<li class="toc-entry toc-h1"><a href="#平均が未知、精度が既知の場合">平均が未知、精度が既知の場合 </a>
<ul>
<li class="toc-entry toc-h2"><a href="#モデルの構築">モデルの構築 </a></li>
<li class="toc-entry toc-h2"><a href="#事後分布の推論">事後分布の推論 </a></li>
<li class="toc-entry toc-h2"><a href="#予測分布の算出">予測分布の算出 </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#平均が既知、精度が未知の場合">平均が既知、精度が未知の場合 </a>
<ul>
<li class="toc-entry toc-h2"><a href="#モデルの構築">モデルの構築 </a></li>
<li class="toc-entry toc-h2"><a href="#事後分布の推論">事後分布の推論 </a></li>
<li class="toc-entry toc-h2"><a href="#予測分布の算出">予測分布の算出 </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#平均と精度がともに未知の場合">平均と精度がともに未知の場合 </a>
<ul>
<li class="toc-entry toc-h2"><a href="#モデルの構築">モデルの構築 </a></li>
<li class="toc-entry toc-h2"><a href="#事後分布の推論">事後分布の推論 </a>
<ul>
<li class="toc-entry toc-h3"><a href="#平均に注目">平均に注目 </a></li>
<li class="toc-entry toc-h3"><a href="#精度に注目">精度に注目 </a></li>
<li class="toc-entry toc-h3"><a href="#まとめ">まとめ </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#予測分布の導出">予測分布の導出 </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-03-bayes_part3.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>参考図書 <sup id="fnref-1" class="footnote-ref"><a href="#fn-1">1</a></sup></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="1次元ガウス分布">
<a class="anchor" href="#1%E6%AC%A1%E5%85%83%E3%82%AC%E3%82%A6%E3%82%B9%E5%88%86%E5%B8%83" aria-hidden="true"><span class="octicon octicon-link"></span></a>1次元ガウス分布<a class="anchor-link" href="#1%E6%AC%A1%E5%85%83%E3%82%AC%E3%82%A6%E3%82%B9%E5%88%86%E5%B8%83"> </a>
</h1>
<p>1次元のガウス分布(以下本ページでは単に「ガウス分布」と呼ぶ)は、次の確率密度関数で表される$x \in \mathbb{R}$を生成する確率分布である。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>1次元ガウス分布の確率密度関数$$\mathcal{N}(x|\mu,\sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} exp\{-\frac{(x-\mu)^2}{2\sigma^2}\}$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>パラメータは$\mu \in \mathbb{R}, \sigma^2 \in \mathbb{R^+}$の2つで、それぞれ平均と分散である。精度パラメータ$\lambda = \sigma^{-2}$を用いて書くこともある。精度で書くと以下のようになる。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>精度で表した1次元ガウス分布の確率密度関数$$\mathcal{N}(x|\mu,\lambda^{-1}) = \frac{1}{\sqrt{2 \pi}} \lambda^{\frac{1}{2}}exp\{-\frac{1}{2}(x-\mu)^2 \lambda\}$$
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>以下、観測されたデータ$\mathcal{D}=\{x_1,\dots,x_N\}$の各点$x_n$と未知の観測$x_*$は同じ1次元ガウス分布から独立に生成されたと仮定してベイズ推論を行う。</p>
<h1 id="平均が未知、精度が既知の場合">
<a class="anchor" href="#%E5%B9%B3%E5%9D%87%E3%81%8C%E6%9C%AA%E7%9F%A5%E3%80%81%E7%B2%BE%E5%BA%A6%E3%81%8C%E6%97%A2%E7%9F%A5%E3%81%AE%E5%A0%B4%E5%90%88" aria-hidden="true"><span class="octicon octicon-link"></span></a>平均が未知、精度が既知の場合<a class="anchor-link" href="#%E5%B9%B3%E5%9D%87%E3%81%8C%E6%9C%AA%E7%9F%A5%E3%80%81%E7%B2%BE%E5%BA%A6%E3%81%8C%E6%97%A2%E7%9F%A5%E3%81%AE%E5%A0%B4%E5%90%88"> </a>
</h1>
<p>ガウス分布の2つのパラメータのうち、精度パラメータ$\lambda$が既知である状況でベイズ推論を行う。</p>
<h2 id="モデルの構築">
<a class="anchor" href="#%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%A7%8B%E7%AF%89" aria-hidden="true"><span class="octicon octicon-link"></span></a>モデルの構築<a class="anchor-link" href="#%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%A7%8B%E7%AF%89"> </a>
</h2>
<p>平均$\mu$だけが未知という条件で、尤度関数をガウス分布にした場合、そのパラメータ$\mu$の事前分布はどうすればよいだろうか。$\mu$の条件は$\mu \in \mathbb{R}$であることのみであり、実数を1つ出力する分布を事前分布とすればベイズ推論ができそうだ。このような分布は様々だが、1次元ガウス分布を用いることで事後分布も1次元ガウス分布となることが知られている。つまり尤度関数が1次元ガウス分布の場合の共役事前分布は1次元ガウス分布である。これを用いて同時分布を構築すると以下のようになる。</p>
$$
\begin{eqnarray}
    p(\mathcal{D},x_*,\mu) &amp;=&amp; p(\mathcal{D}|\mu)p(x_*|\mu)p(\mu) \\
    p(\mathcal{D}|\mu) &amp;=&amp; \Pi_{n=1}^{N} \mathcal{N}(x_n|\mu, \lambda^{-1}) \\
    p(x_*|\mu) &amp;=&amp; \mathcal{N}(x_*|\mu, \lambda^{-1}) \\
    p(\mu) &amp;=&amp; \mathcal{N}(\mu|m, \lambda_{\mu}^{-1})
\end{eqnarray}
$$<p>$p(\mu)$の$m \in \mathbb{R}, \lambda_{\mu} \in \mathbb{R^+}$は固定されたハイパーパラメータである。</p>
<h2 id="事後分布の推論">
<a class="anchor" href="#%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83%E3%81%AE%E6%8E%A8%E8%AB%96" aria-hidden="true"><span class="octicon octicon-link"></span></a>事後分布の推論<a class="anchor-link" href="#%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83%E3%81%AE%E6%8E%A8%E8%AB%96"> </a>
</h2>
<p>事後分布$p(\mu|\mathcal{D})$を求める。ベイズの定理から次のように書ける。分母は形状には関わらないので省く。</p>
$$
\begin{eqnarray}
    p(\mu|\mathcal{D}) &amp;\propto&amp; p(\mathcal{D}|\mu) p(\mu) \\
    &amp;=&amp; \{\Pi_{n=1}^{N} p(x_n|\mu)\}p(\mu) \\
    &amp;=&amp; \{\Pi_{n=1}^{N} \mathcal{N}(x_n|\mu, \lambda^{-1})\} \mathcal{N}(\mu|m,\lambda_{\mu}^{-1})
\end{eqnarray}
$$<p>対数をとると、</p>
$$
\begin{eqnarray}
    p(\mu|\mathcal{D}) &amp;=&amp; \Sigma_{n=1}^{N} \ln \mathcal{N}(x_n|\mu,\lambda^{-1}) + \ln \mathcal{N}(\mu|m,\lambda_{\mu}^{-1}) + const. \\
    &amp;=&amp; \Sigma_{n=1}^{N} \{-\frac{1}{2}(x_n-\mu)^2 \lambda\} + \{-\frac{1}{2}(\mu-m)^2 \lambda_{\mu}\} + const. \\
    &amp;=&amp; -\frac{1}{2}\left[\Sigma_{n=1}^{N}\{(x_n^2 -2x_n\mu + \mu^2)\lambda\} + (\mu^2 - 2\mu m + m^2)\lambda_{\mu}\right] + const. \\
    &amp;=&amp; -\frac{1}{2}\{(N\lambda + \lambda_{\mu})\mu^2 - 2(\Sigma_{n=1}^{N} x_n \lambda + m \lambda_{\mu})\mu\} + const.
\end{eqnarray}
$$<p>最後の変形では$\mu$に関わらない値は$const.$に吸収させている。これを平方完成するとガウス分布の形になっていることがわかるがここでは結果から逆算的に求める。事後分布が次のようなガウス分布で書けるとする。</p>
$$
p(\mu|\mathcal{D}) = \mathcal{N}(\mu|\hat{m},\hat{\lambda_{\mu}}^{-1})
$$<p>対数をとると</p>
$$
\begin{eqnarray}
    \ln p(\mu|\mathcal{D}) &amp;=&amp; -\frac{1}{2}(\mu-\hat{m})^2 \hat{\lambda_{\mu}} \\
    &amp;=&amp; -\frac{1}{2}\{\hat{\lambda_{\mu}} \mu^2 - 2\hat{m} \hat{\lambda_{\mu}} \mu\} + const.
\end{eqnarray}
$$<p>となるので、事後分布のパラメータ$\hat{m},\hat{\lambda_{\mu}}$は次のように求まる。</p>
$$
\begin{eqnarray}
    \hat{\lambda_{\mu}} &amp;=&amp; N \lambda + \lambda_{\mu} \\
    \hat{m} &amp;=&amp; \frac{\lambda \Sigma_{n=1}^{N} x_n + \lambda_{\mu}m}{\hat{\lambda_{\mu}}}
\end{eqnarray}
$$<p>以上で事後分布の推論が完了した。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>更新された精度パラメータは、ハイパーパラメータに$N\lambda$だけ加えたものでありデータ数$N$が大きくなる程精度が上がる、すなわち事後分布のばらつきが小さくなりかつハイパーパラメータの影響が小さくなることを示している。平均パラメータはハイパーパラメータ$m$と$\Sigma{n=1}^{N}x_n$の重み付き和の形になっておりこれもデータ数が増えるほどハイパーパラメータの影響を受けにくくなることがわかる。
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="予測分布の算出">
<a class="anchor" href="#%E4%BA%88%E6%B8%AC%E5%88%86%E5%B8%83%E3%81%AE%E7%AE%97%E5%87%BA" aria-hidden="true"><span class="octicon octicon-link"></span></a>予測分布の算出<a class="anchor-link" href="#%E4%BA%88%E6%B8%AC%E5%88%86%E5%B8%83%E3%81%AE%E7%AE%97%E5%87%BA"> </a>
</h2>
<p>モデル全体の事後分布をパラメータ$\mu$で周辺化することで未知の観測$x_*$に対する予測分布が得られる。ハット記号を付けるのが面倒なので、学習していない事前分布から予測分布を算出し、後で更新されたパラメータを代入してみることにする。</p>
$$
\begin{eqnarray}
    p(x_*) &amp;=&amp; \int p(x_*|\mu) p(\mu) d\mu \\
    &amp;=&amp; \int \mathcal{N}(x_*|\mu,\lambda^{-1})\mathcal{N}(\mu|m,\lambda_{\mu}^{-1}) d\mu
\end{eqnarray}
$$<p>これを直接計算するのは大変なので、ベイズの定理と対数をうまく使ってみる。ベイズの定理から、</p>
$$
p(\mu|x_*) = \frac{p(x_*|\mu)p(\mu)}{p(x_*)}
$$<p>$p(x_*)$を左辺に置いて対数をとると、</p>
$$
\ln p(x_*) = \ln p(x_*|\mu) - \ln p(\mu|x_*) + const.
$$<p>$\ln p(\mu)$は$x_*$には関係ないので$const.$とした。$p(\mu|x_*)$は$p(\mu|\mathcal{D})$に$\mathcal{D}=x_*$とすれば求まる。</p>
$$
\begin{eqnarray}
    p(\mu|x_*) &amp;=&amp; \mathcal{N}(\mu|m(x_*), (\lambda + \lambda_{\mu})^{-1}) \\
    ただし　m(x_*) &amp;=&amp; \frac{\lambda x_* + \lambda_{\mu}m}{\lambda + \lambda_{\mu}}
\end{eqnarray}
$$<p>これと$p(x_*|\mu) = \mathcal{N}(\mu, \lambda^{-1})$を代入すると</p>
$$
\begin{eqnarray}
    \ln p(x_*) &amp;=&amp; \ln p(x_*|\mu) - \ln p(\mu|x_*) + const. \\
    &amp;=&amp; -\frac{1}{2} \{ \lambda (x_* - \mu)^2 - (\lambda + \lambda_{\mu})(\mu - m(x_*))^2 \} + const. \\
    &amp;=&amp; -\frac{1}{2} \{ \lambda x_*^2 - 2 \lambda \mu x_* - \frac{\lambda^2 x_*^2 + 2 \lambda \lambda_{\mu} m x_*}{\lambda + \lambda_{\mu}} + 2 \lambda \mu x_* \} + const. \\
    &amp;=&amp; -\frac{1}{2} \{ \frac{\lambda^2 x_*^2 + \lambda \lambda_{\mu} x_*^2 - \lambda^2 x_*^2 - 2 \lambda \lambda_{\mu} m x_*}{\lambda + \lambda_{\mu}}\} + const. \\
    &amp;=&amp; -\frac{1}{2} \{ \frac{\lambda \lambda_{\mu}}{\lambda + \lambda_{\mu}} x_*^2 - \frac{2m\lambda\lambda_{\mu}}{\lambda + \lambda_{\mu}} x_* \} + const.
\end{eqnarray}
$$<p>$x_*$の2次関数の形にできたので事後分布と同じく逆算的に計算すると、予測分布$p(x_*)$は</p>
$$
\begin{eqnarray}
    p(x_*) &amp;=&amp; \mathcal{N} (x_* | \mu_*, \lambda_{*}^{-1}) \\
    ただし　\lambda_* &amp;=&amp; \frac{\lambda \lambda_{\mu}}{\lambda + \lambda_{\mu}} \\
    \mu_* &amp;=&amp; m
\end{eqnarray}
$$<p>となる。これに$\hat{m}, \hat{\lambda_{\mu}}$を代入することで学習した後の予測分布$p(x_*|\mathcal{D})$は</p>
$$
\begin{eqnarray}
    p(x_*) &amp;=&amp; \mathcal{N} (x_* | \mu_*, \lambda_{*}^{-1}) \\
    ただし　\lambda_* &amp;=&amp; \frac{\lambda (N\lambda + \lambda_{\mu})}{\lambda + (N\lambda + \lambda_{\mu})} \\
    \mu_* &amp;=&amp; \frac{\lambda \Sigma_{n=1}^{N} x_n + \lambda_{\mu}m}{N\lambda + \lambda_{\mu}}
\end{eqnarray}
$$<p>と求まる。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>精度から見た結果の意味
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<blockquote>
<p>精度について逆数をとると意味がわかりやすい。</p>
$$\lambda_*^{-1} = \lambda^{-1} + \hat{\lambda_{\mu}}^{-1}$$<p>精度の逆数は分散なので、この式は「予測分布の分散は観測分布の分散と事後分布の分散の和である」という意味になる。</p>
<p>今回は観測分布の分散が実際の分散に等しいことを仮定しているので、データ数が増え事後分布の分散が小さくなれば予測分布は実際の分布の分散とほぼ一致する。</p>
</blockquote>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="平均が既知、精度が未知の場合">
<a class="anchor" href="#%E5%B9%B3%E5%9D%87%E3%81%8C%E6%97%A2%E7%9F%A5%E3%80%81%E7%B2%BE%E5%BA%A6%E3%81%8C%E6%9C%AA%E7%9F%A5%E3%81%AE%E5%A0%B4%E5%90%88" aria-hidden="true"><span class="octicon octicon-link"></span></a>平均が既知、精度が未知の場合<a class="anchor-link" href="#%E5%B9%B3%E5%9D%87%E3%81%8C%E6%97%A2%E7%9F%A5%E3%80%81%E7%B2%BE%E5%BA%A6%E3%81%8C%E6%9C%AA%E7%9F%A5%E3%81%AE%E5%A0%B4%E5%90%88"> </a>
</h1>
<p>今度は、平均パラメータ$\mu$が既知で、精度パラメータ$\lambda$が未知の場合でベイズ推論を行う。</p>
<h2 id="モデルの構築">
<a class="anchor" href="#%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%A7%8B%E7%AF%89" aria-hidden="true"><span class="octicon octicon-link"></span></a>モデルの構築<a class="anchor-link" href="#%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%A7%8B%E7%AF%89"> </a>
</h2>
<p>精度パラメータ$\lambda$は正の実数である必要がある。正の実数を出力する確率分布にはガンマ分布があり、平均既知精度未知の場合の1次元ガウス分布の共役事前分布として知られている。事前分布にガンマ分布を採用すると次のようにモデル構築することになる。</p>
$$
\begin{eqnarray}
    p(\mathcal{D},x_*,\lambda) &amp;=&amp; p(\mathcal{D}|\lambda)p(x_*|\lambda)p(\lambda) \\
    p(\mathcal{D}|\lambda) &amp;=&amp; \Pi_{n=1}^{N} \mathcal{N}(x_n|\mu, \lambda^{-1}) \\
    p(x_*|\lambda) &amp;=&amp; \mathcal{N}(x_*|\mu, \lambda^{-1}) \\
    p(\lambda) &amp;=&amp; Gam(\lambda|a, b)
\end{eqnarray}
$$<p>このモデルのハイパーパラメータは$a,b$である。$\mu$は既知の値という設定だが、$\mu$をハイパーパラメータとして推論していると考えることもできる。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>ガンマ分布
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<blockquote>
<p>ガンマ分布は$a, b \in \mathbb{R^+}$をパラメータに持ち、正の実数を生成する確率分布である。ガンマ分布の確率密度関数は次の通り。</p>
$$Gam(\lambda|a,b) = C_G(a,b)\lambda^{a-1}e^{-b\lambda}$$<p>$C_G(a,b)$は正規化係数であり、</p>
$$C_G(a,b) = \frac{b^a}{\Gamma(a)}$$
</blockquote>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="事後分布の推論">
<a class="anchor" href="#%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83%E3%81%AE%E6%8E%A8%E8%AB%96" aria-hidden="true"><span class="octicon octicon-link"></span></a>事後分布の推論<a class="anchor-link" href="#%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83%E3%81%AE%E6%8E%A8%E8%AB%96"> </a>
</h2>
<p>事後分布$p(\lambda|\mathcal{D})$を推論する。ベイズの定理から</p>
$$
\begin{eqnarray}
    p(\lambda|\mathcal{D}) &amp;\propto&amp; p(\mathcal{D}|\lambda)p(\lambda) \\
    &amp;=&amp; \{ \Pi_{n=1}^{N} p(x_n|\lambda) \} p(\lambda) \\
    &amp;=&amp; \{ \Pi_{n=1}^{N} \mathcal{N}(x_n|\mu, \lambda^{-1}) \} Gam(\lambda|a,b)
\end{eqnarray}
$$<p>対数をとる。</p>
$$
\begin{eqnarray}
    \ln p(\lambda|\mathcal{D}) &amp;=&amp; \Sigma_{n=1}^{N} \ln \mathcal{N}(x_n|\mu,\lambda^{-1}) + \ln Gam(\lambda|a,b) + const. \\
    &amp;=&amp; \Sigma_{n=1}^{N}\{\frac{1}{2} \ln \lambda - \frac{(x_n-\mu)^2 \lambda}{2}\} + (a-1)\ln \lambda -b\lambda + const. \\
    &amp;=&amp; (\frac{N}{2}+a-1)\ln \lambda - \{\frac{1}{2}\Sigma_{n=1}^{N}(x_n-\mu)^2 + b\}\lambda + const.
\end{eqnarray}
$$<p>対数を戻せばこれはガンマ分布となることがわかる。</p>
$$
\begin{eqnarray}
    p(\lambda|\mathcal{D}) &amp;=&amp; Gam(\lambda|\hat{a},\hat{b}) \\
    ただし　\hat{a} &amp;=&amp; \frac{N}{2} + a \\
    \hat{b} &amp;=&amp; \frac{1}{2} \Sigma_{n=1}^{N} (x_n-\mu)^2 + b
\end{eqnarray}
$$<h2 id="予測分布の算出">
<a class="anchor" href="#%E4%BA%88%E6%B8%AC%E5%88%86%E5%B8%83%E3%81%AE%E7%AE%97%E5%87%BA" aria-hidden="true"><span class="octicon octicon-link"></span></a>予測分布の算出<a class="anchor-link" href="#%E4%BA%88%E6%B8%AC%E5%88%86%E5%B8%83%E3%81%AE%E7%AE%97%E5%87%BA"> </a>
</h2>
<p>事後分布の形状が事前分布と同じなので、学習前の予測分布$p(x_*)$を計算すれば、学習後の$\hat{a},\hat{b}$を代入するだけで$p(x_*|\mathcal{D})$がわかる。</p>
$$
p(x_*) = \int p(x_*|\lambda)p(\lambda) d\lambda
$$<p>を直接計算せずにベイズの定理と対数計算で簡単に計算してみる。</p>
$$
p(\lambda|x_*) = \frac{p(x_*|\lambda)p(\lambda)}{p(x_*)}
$$<p>対数をとり、$p(\lambda)$を定数にまとめれば</p>
$$
\ln p(x_*) = \ln p(x_*|\lambda) - \ln p(\lambda|x_*) + const.
$$<p>$\ln p(\lambda|x_*)$は事後分布の形に合わせれば</p>
$$
\begin{eqnarray}
    p(\lambda|x_*) &amp;=&amp; Gam(\lambda|\frac{1}{2}+a,b(x_*)) \\
    ただし　b(x_*) &amp;=&amp; \frac{1}{2}(x_*-\mu)^2 + b
\end{eqnarray}
$$<p>と書ける。これを代入して</p>
$$
\begin{eqnarray}
    \ln p(x_*) &amp;=&amp; \ln \mathcal{N}(x_*|\mu,\lambda^{-1}) - \ln Gam(\lambda|\frac{1}{2}+a,b(x_*)) + cosnt. \\
    &amp;=&amp; \frac{1}{2} \ln \lambda - \frac{(x_*-\mu)^2 \lambda}{2} - (a-\frac{1}{2})\ln \lambda + \{\frac{1}{2}(x_*-\mu)^2 + b \} \lambda - \ln C_G(a+\frac{1}{2}, \frac{1}{2}(x_*-\mu)^2 + b) + const. \\
    &amp;=&amp; - (a+\frac{1}{2})\ln \{\frac{1}{2}(x_*-\mu)^2 + b\} + \Gamma(a+\frac{1}{2}) + const. \\
    &amp;=&amp; - \frac{2a+1}{2} \ln \{ 1 + \frac{1}{2b}(x_*-\mu)^2 \} + const.
\end{eqnarray}
$$<p>となる。途中、$x_*$を含まない項は$const.$に吸収させている。また、$\lambda$に関わる項は消えている。この結果は1次元のStudentのt分布に対数をとったものと同じ形になっている。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>1次元のStudentのt分布
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<blockquote>
<p>1次元のStudentのt分布は次の確率密度関数で表される。</p>
$$St(x|\mu_s,\lambda_s,\nu_s) = \frac{\Gamma(\frac{\nu_s + 1}{2})}{\Gamma(\frac{\nu_s}{2})}(\frac{\lambda_s}{\pi \nu_s})^{\frac{1}{2}}\{ 1 + \frac{\lambda_s}{\nu_s} (x-\mu_s)^2 \}^{-\frac{\nu_s+1}{2}}$$<p>対数をとり$x$に関わらない部分をconst.にまとめると</p>
$$\ln St(x|\mu_s,\lambda_s,\nu_s) = -\frac{\nu_s+1}{2} \ln \{ 1 + \frac{\lambda_s}{\nu_s} (x-\mu_s)^2 \} + const.$$
</blockquote>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>対数t分布との対応を見れば、予測分布は次のように書けることがわかる。</p>
$$
\begin{eqnarray}
    p(x_*) &amp;=&amp; St(x_*|\mu_s,\lambda_s,\nu_s) \\
    ただし　\mu_s &amp;=&amp; \mu \\
    \lambda_s &amp;=&amp; \frac{a}{b} \\
    \nu_s &amp;=&amp; 2a
\end{eqnarray}
$$<p>学習により更新された$\hat{a},\hat{b}$を代入すると次のようになる。</p>
$$
\begin{eqnarray}
    p(x_*|\mathcal{D}) &amp;=&amp; St(x_*|\mu_s,\lambda_s,\nu_s) \\
    ただし　\mu_s &amp;=&amp; \mu \\
    \lambda_s &amp;=&amp; \frac{N+2a}{\Sigma_{n=1}^{N} (x_n-\mu)^2 + 2b} \\
    \nu_s &amp;=&amp; N + 2a
\end{eqnarray}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="平均と精度がともに未知の場合">
<a class="anchor" href="#%E5%B9%B3%E5%9D%87%E3%81%A8%E7%B2%BE%E5%BA%A6%E3%81%8C%E3%81%A8%E3%82%82%E3%81%AB%E6%9C%AA%E7%9F%A5%E3%81%AE%E5%A0%B4%E5%90%88" aria-hidden="true"><span class="octicon octicon-link"></span></a>平均と精度がともに未知の場合<a class="anchor-link" href="#%E5%B9%B3%E5%9D%87%E3%81%A8%E7%B2%BE%E5%BA%A6%E3%81%8C%E3%81%A8%E3%82%82%E3%81%AB%E6%9C%AA%E7%9F%A5%E3%81%AE%E5%A0%B4%E5%90%88"> </a>
</h1>
<p>次に、平均と精度がともに未知の場合のベイズ推論を実践してみる。モデルのパラメータが2個になっても、やることは変わらない。</p>
<h2 id="モデルの構築">
<a class="anchor" href="#%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%A7%8B%E7%AF%89" aria-hidden="true"><span class="octicon octicon-link"></span></a>モデルの構築<a class="anchor-link" href="#%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%A7%8B%E7%AF%89"> </a>
</h2>
<p>平均についてガウス事前分布を、精度についてガンマ事前分布をそれぞれ設定し次のような同時分布を作ることも可能である(尤度関数は前と同じなので省略)。</p>
$$
\begin{eqnarray}
    p(\mathcal{D},x_*,\mu,\lambda) &amp;=&amp; p(\mathcal{D}|\mu,\lambda^{-1})p(x_*|\mu,\lambda^{-1})p(\mu)p(\lambda) \\
    p(\mu) &amp;=&amp; \mathcal{N}(\mu|m,\lambda_{\mu}^{-1}) \\
    p(\lambda) &amp;=&amp; Gam(\lambda|a,b)
\end{eqnarray}
$$<p>が、実はガウス・ガンマ分布という事前分布を用いると事後分布もガウス・ガンマ分布となることが知られている。ここではガウス・ガンマ分布を用いる。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>ガウス・ガンマ分布
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<blockquote>
<p>ガウス・ガンマ分布は$m, \beta, a, b$をパラメータに持ち、$\mu, \lambda$という2つの確率変数を生成する確率分布である。確率密度関数は次のように書ける。</p>
$$
\begin{eqnarray}
p(\mu,\lambda) &amp;=&amp; NG(\mu,\lambda|m,\beta,a,b) \\
&amp;=&amp; \mathcal{N}(\mu|m,(\beta \lambda)^{-1})Gam(\lambda|a,b)
\end{eqnarray}
$$<p></p>
</blockquote>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>ガウス事前分布・ガンマ事前分布を別々に設定する場合との違いは$\mu$が$\lambda$に条件づけられていることである。グラフィカルモデルで示すと次のようになる。</p>
<p><img src="/tpt-medical-it/images/copied_from_nb/dags/dag_gauss1.png" alt="ガウス事前分布とガンマ事前分布を別々に設定した場合"></p>
<p><img src="/tpt-medical-it/images/copied_from_nb/dags/dag_gauss2.png" alt="ガウス・ガンマ分布を使った場合"></p>
<p>ガウス・ガンマ分布を使った場合モデルは次のようになる(尤度関数は省略)。</p>
$$
\begin{eqnarray}
    p(\mathcal{D},x_*,\mu,\lambda) &amp;=&amp; p(\mathcal{D}|\mu,\lambda^{-1})p(x_*|\mu,\lambda^{-1})p(\mu,\lambda) \\
    p(\mu,\lambda) &amp;=&amp; NG(\mu,\lambda|m,\beta,a,b)
\end{eqnarray}
$$<h2 id="事後分布の推論">
<a class="anchor" href="#%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83%E3%81%AE%E6%8E%A8%E8%AB%96" aria-hidden="true"><span class="octicon octicon-link"></span></a>事後分布の推論<a class="anchor-link" href="#%E4%BA%8B%E5%BE%8C%E5%88%86%E5%B8%83%E3%81%AE%E6%8E%A8%E8%AB%96"> </a>
</h2>
<p>$\mu$が$\lambda$に条件づけられているので、同時分布$p(\mathcal{D},\mu,\lambda)$は次のように変形できる。</p>
$$
p(\mathcal{D},\mu,\lambda) = p(\mu|\lambda,\mathcal{D})p(\lambda|\mathcal{D})p(\mathcal{D})
$$<p>未観測の変数の事後分布は同時分布を観測された変数の確率で割ることで求まるのでこの場合の事後分布は、</p>
$$
\frac{p(\mathcal{D},\mu,\lambda)}{p(\mathcal{D})} = p(\mu|\lambda,\mathcal{D})p(\lambda|\mathcal{D})
$$<p>より、$p(\mu|\lambda,\mathcal{D})p(\lambda|\mathcal{D})$のことを指す。</p>
<h3 id="平均に注目">
<a class="anchor" href="#%E5%B9%B3%E5%9D%87%E3%81%AB%E6%B3%A8%E7%9B%AE" aria-hidden="true"><span class="octicon octicon-link"></span></a>平均に注目<a class="anchor-link" href="#%E5%B9%B3%E5%9D%87%E3%81%AB%E6%B3%A8%E7%9B%AE"> </a>
</h3>
<p>まず平均にのみ注目し$p(\mu|\lambda,\mathcal{D})$について考える。平均未知精度既知の場合の事後分布の結果に対し$\lambda$を$\beta \lambda$に置き換えれば、</p>
$$
\begin{eqnarray}
    p(\mu|\lambda,\mathcal{D}) &amp;=&amp; \mathcal{N}(\mu|\hat{m},(\hat{\beta}\lambda)^{-1}) \\
    ただし　\hat{\beta} &amp;=&amp; N + \beta \\
    \hat{m} &amp;=&amp; \frac{1}{\hat{\beta}}(\Sigma_{n=1}^{N} x_n + \beta m)
\end{eqnarray}
$$<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>置き換えによって$\lambda_{\mu}=\beta \lambda$となっていることを利用した。
</div>
<h3 id="精度に注目">
<a class="anchor" href="#%E7%B2%BE%E5%BA%A6%E3%81%AB%E6%B3%A8%E7%9B%AE" aria-hidden="true"><span class="octicon octicon-link"></span></a>精度に注目<a class="anchor-link" href="#%E7%B2%BE%E5%BA%A6%E3%81%AB%E6%B3%A8%E7%9B%AE"> </a>
</h3>
<p>次に精度に関わる部分$p(\lambda|\mathcal{D})$を求める。同時分布から、</p>
$$
\begin{eqnarray}
    p(\lambda|\mathcal{D}) &amp;=&amp; \frac{p(\mathcal{D},\mu,\lambda)}{p(\mu|\lambda,\mathcal{D})p(\mathcal{D})} \\
    &amp;\propto&amp; \frac{p(\mathcal{D},\mu,\lambda)}{p(\mu|\lambda,\mathcal{D})} \\
    &amp;=&amp; \frac{p(\mathcal{D}|\mu,\lambda)p(\mu,\lambda)}{p(\mu|\lambda,\mathcal{D})} \\
    &amp;=&amp; \frac{\{\Pi_{n=1}^{N} \mathcal{N}(x_n|\mu,\lambda^{-1})\} \mathcal{N}(\mu|m,(\beta \lambda)^{-1})Gam(\lambda|a,b)}{\mathcal{N}(\mu|\hat{m},(\hat{\beta}\lambda)^{-1})}
\end{eqnarray}
$$<p>対数をとって整理していく。</p>
$$
\begin{eqnarray}
    \ln p(\lambda|\mathcal{D}) &amp;=&amp; \Sigma_{n=1}^{N} \{\ln \mathcal{N}(x_n|\mu,\lambda^{-1}) \} + \ln \mathcal{N}(\mu|m,(\beta \lambda)^{-1}) + \ln Gam(\lambda|a,b) - \ln \mathcal{N}(\mu|\hat{m},(\hat{\beta}\lambda)^{-1}) + const. \\
    &amp;=&amp; \Sigma_{n=1}^{N} \{\frac{1}{2}\ln \lambda - \frac{(x_n-\mu)^2 \lambda}{2}\} + \frac{\ln \beta + \ln \lambda}{2} - \frac{(\mu-m)^2 \beta\lambda}{2} + (a-1)\ln\lambda -b\lambda - \frac{\ln \hat{\beta} + \ln \lambda}{2} + \frac{(\mu-\hat{m})^2 \hat{\beta}\lambda}{2} + const.\\
    &amp;=&amp; (\frac{N}{2} + a - 1)\ln \lambda - \frac{1}{2}\{ \Sigma_{n=1}^{N} x_n^2 - 2\mu \Sigma_{n=1}^{N} x_n + N\mu^2 + \beta \mu^2 - 2\mu m \beta + m^2\beta + 2 b - \mu^2 \hat{\beta} + 2\mu \hat{m} \hat{\beta} - \hat{m}^2 \hat{\beta} \}\lambda + const. \\
    &amp;=&amp; (\frac{N}{2} + a - 1)\ln \lambda - \frac{1}{2}\{ \Sigma_{n=1}^{N} x_n^2 + 2\mu(\hat{m}\hat{\beta}- \Sigma_{n=1}^{N} x_n - m \beta) + (N + \beta - \hat{\beta}) \mu^2 + m^2 \beta - \hat{m}^2 \hat{\beta} + 2b \} \lambda + const. \\
    &amp;=&amp; (\frac{N}{2} + a - 1)\ln \lambda - \{\frac{1}{2}(\Sigma_{n=1}^{N} x_n^2 + \beta m^2 - \hat{\beta} \hat{m}^2) + b\} \lambda + const.
\end{eqnarray}
$$<p>ガンマ分布の定義式と照らし合わせて</p>
$$
\begin{eqnarray}
    p(\lambda|\mathcal{D}) &amp;=&amp; Gam(\lambda|\hat{a},\hat{b}) \\
    ただし　\hat{a} &amp;=&amp; \frac{N}{2} + a \\
    \hat{b} &amp;=&amp; \frac{1}{2}(\Sigma_{n=1}^{N} x_n^2 + \beta m^2 - \hat{\beta} \hat{m}^2) + b
\end{eqnarray}
$$<h3 id="まとめ">
<a class="anchor" href="#%E3%81%BE%E3%81%A8%E3%82%81" aria-hidden="true"><span class="octicon octicon-link"></span></a>まとめ<a class="anchor-link" href="#%E3%81%BE%E3%81%A8%E3%82%81"> </a>
</h3>
<p>結局求めたい事後分布$p(\mu|\lambda,\mathcal{D})p(\lambda|\mathcal{D})$は更新されたハイパーパラメータ$\hat{m},\hat{\beta},\hat{a},\hat{b}$を持つガウス・ガンマ分布の形になる。</p>
$$
\begin{eqnarray}
    p(\mu|\lambda,\mathcal{D})p(\lambda|\mathcal{D}) &amp;=&amp; \mathcal{N}(\mu|\hat{m},(\hat{\beta}\lambda)^{-1})Gam(\lambda|\hat{a},\hat{b}) \\
    &amp;=&amp; NG(\mu, \lambda|\hat{m},\hat{\beta},\hat{a},\hat{b})
\end{eqnarray}
$$<h2 id="予測分布の導出">
<a class="anchor" href="#%E4%BA%88%E6%B8%AC%E5%88%86%E5%B8%83%E3%81%AE%E5%B0%8E%E5%87%BA" aria-hidden="true"><span class="octicon octicon-link"></span></a>予測分布の導出<a class="anchor-link" href="#%E4%BA%88%E6%B8%AC%E5%88%86%E5%B8%83%E3%81%AE%E5%B0%8E%E5%87%BA"> </a>
</h2>
<p>事前分布と事後分布が同じ形状であるから、学習前の予測分布を導出し、更新されたハイパーパラメータを代入することで学習後の予測分布を求めることができる。</p>
<p>学習前の予測分布は以下のように2つの変数を積分除去することで求められる。</p>
<p>
$$p(x_*) = \int \int p(x_*|\mu,\lambda)p(\mu,\lambda)d\mu d\lambda$$
</p>
<p>でもできれば積分はしたくないのでベイズの定理から求めてみる。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>積分は式変形も面倒だしコンピュータにとっても計算コストが高いのでできるだけしたくない。いかに積分を回避するかが肝。
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>ベイズの定理から</p>
$$
p(\mu,\lambda|x_*) = \frac{p(x_*|\mu,\lambda)p(\mu,\lambda)}{p(x_*)} 
$$<p>より</p>
$$
\ln p(x_*) = \ln p(x_*|\mu,\lambda) - \ln p(\mu,\lambda|x_*) + const.
$$<p>事後分布の結果を流用して、</p>
$$
\begin{eqnarray}
    p(\mu, \lambda|x_*) &amp;=&amp; \mathcal{N}(\mu|m(x_*), \{(1+\beta)\lambda \}^{-1})Gam(\lambda|\frac{1}{2}+a,b(x_*)) \\
    ただし　m(x_*) &amp;=&amp; \frac{x_*+\beta m}{1+\beta} \\
    b(x_*) &amp;=&amp; \frac{\beta}{2(1+\beta)}(x_*-m)^2 + b
\end{eqnarray}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>$m(x_*),b(x_*)$の導出
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<blockquote>
<p>$\hat{m},\hat{b}$を$\mathcal{D}=x_*$として計算すると</p>
$$
\begin{eqnarray}
    \hat{m} &amp;=&amp; \frac{1}{\hat{\beta}}(\Sigma_{n=1}^{N} x_n + \beta m) \\
    &amp;=&amp; \frac{1}{1+\beta}(x_*+\beta m)
\end{eqnarray}
$$$$
\begin{eqnarray}
    \hat{b} &amp;=&amp; \frac{1}{2}(\Sigma_{n=1}^{N} x_n^2 + \beta m^2 - \hat{\beta} \hat{m}^2) + b \\
    &amp;=&amp; \frac{1}{2}\{x_*^2 + \beta m^2 - (1+\beta)(\frac{x_*+\beta m}{1+\beta})^2\} + b \\
    &amp;=&amp; \frac{1}{2(1+\beta)}\{(1+\beta)(x_*^2+\beta m^2) - x_*^2 - 2x_* \beta m - \beta^2 m^2\} + b \\
    &amp;=&amp; \frac{1}{2(1+\beta)}\{\beta x_*^2 - 2\beta x_* m + \beta m^2\} +b \\
    &amp;=&amp; \frac{\beta}{2(1+\beta)}(x_*-m)^2 + b
\end{eqnarray}
$$
</blockquote>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>よって予測分布$p(x_*)$は</p>
$$
\begin{eqnarray}
    \ln p(x_*) = \ln \mathcal{N}(x_*|\mu,\lambda) - \ln \mathcal{N}(\mu|m(x_*),\{(1+\beta)\lambda\}^{-1}) - \ln Gam(\lambda|\frac{1}{2}+a,b(x_*))
\end{eqnarray}
$$<p>以下執筆中。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="footnotes"><p id="fn-1">1. <a href="https://www.kspub.co.jp/book/detail/1538320.html">『ベイズ推論による機械学習入門』(須山敦志、講談社)</a><a href="#fnref-1" class="footnote footnotes">↩</a></p></div>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="Vintea01/tpt-medical-it"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/tpt-medical-it/bayes/2020/04/03/bayes_part3.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/tpt-medical-it/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/tpt-medical-it/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/tpt-medical-it/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A gang of medical students playing with Information Technologies.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/Vintea01" title="Vintea01"><svg class="svg-icon grey"><use xlink:href="/tpt-medical-it/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
