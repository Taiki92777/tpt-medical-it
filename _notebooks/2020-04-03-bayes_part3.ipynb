{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ベイズ勉強会 Part 3 1次元ガウス分布のベイズ推論\n",
    "> 1次元ガウス分布のベイズ推論を実践する\n",
    "\n",
    "- toc: true \n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [bayes]\n",
    "- image: images/dag1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考図書 {% fn 1 %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1次元ガウス分布\n",
    "\n",
    "1次元のガウス分布(以下本ページでは単に「ガウス分布」と呼ぶ)は、次の確率密度関数で表される$x \\in \\mathbb{R}$を生成する確率分布である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: 1次元ガウス分布の確率密度関数$$\\mathcal{N}(x|\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} exp\\{-\\frac{(x-\\mu)^2}{2\\sigma^2}\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パラメータは$\\mu \\in \\mathbb{R}, \\sigma^2 \\in \\mathbb{R^+}$の2つで、それぞれ平均と分散である。精度パラメータ$\\lambda = \\sigma^{-2}$を用いて書くこともある。精度で書くと以下のようになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: 精度で表した1次元ガウス分布の確率密度関数$$\\mathcal{N}(x|\\mu,\\lambda^{-1}) = \\frac{1}{\\sqrt{2 \\pi}} \\lambda^{\\frac{1}{2}}exp\\{-\\frac{1}{2}(x-\\mu)^2 \\lambda\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下、観測されたデータ$\\mathcal{D}=\\{x_1,\\dots,x_N\\}$の各点$x_n$と未知の観測$x_*$は同じ1次元ガウス分布から独立に生成されたと仮定してベイズ推論を行う。\n",
    "\n",
    "# 平均が未知、精度が既知の場合\n",
    "\n",
    "ガウス分布の2つのパラメータのうち、精度パラメータ$\\lambda$が既知である状況でベイズ推論を行う。\n",
    "\n",
    "## モデルの構築\n",
    "\n",
    "平均$\\mu$だけが未知という条件で、尤度関数をガウス分布にした場合、そのパラメータ$\\mu$の事前分布はどうすればよいだろうか。$\\mu$の条件は$\\mu \\in \\mathbb{R}$であることのみであり、実数を1つ出力する分布を事前分布とすればベイズ推論ができそうだ。このような分布は様々だが、1次元ガウス分布を用いることで事後分布も1次元ガウス分布となることが知られている。つまり尤度関数が1次元ガウス分布の場合の共役事前分布は1次元ガウス分布である。これを用いて同時分布を構築すると以下のようになる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(\\mathcal{D},x_*,\\mu) &=& p(\\mathcal{D}|\\mu)p(x_*|\\mu)p(\\mu) \\\\\n",
    "    p(\\mathcal{D}|\\mu) &=& \\Pi_{n=1}^{N} \\mathcal{N}(x_n|\\mu, \\lambda^{-1}) \\\\\n",
    "    p(x_*|\\mu) &=& \\mathcal{N}(x_*|\\mu, \\lambda^{-1}) \\\\\n",
    "    p(\\mu) &=& \\mathcal{N}(\\mu|m, \\lambda_{\\mu}^{-1})\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "$p(\\mu)$の$m \\in \\mathbb{R}, \\lambda_{\\mu} \\in \\mathbb{R^+}$は固定されたハイパーパラメータである。\n",
    "\n",
    "## 事後分布の推論\n",
    "\n",
    "事後分布$p(\\mu|\\mathcal{D})$を求める。ベイズの定理から次のように書ける。分母は形状には関わらないので省く。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(\\mu|\\mathcal{D}) &\\propto& p(\\mathcal{D}|\\mu) p(\\mu) \\\\\n",
    "    &=& \\{\\Pi_{n=1}^{N} p(x_n|\\mu)\\}p(\\mu) \\\\\n",
    "    &=& \\{\\Pi_{n=1}^{N} \\mathcal{N}(x_n|\\mu, \\lambda^{-1})\\} \\mathcal{N}(\\mu|m,\\lambda_{\\mu}^{-1})\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "対数をとると、\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(\\mu|\\mathcal{D}) &=& \\Sigma_{n=1}^{N} \\ln \\mathcal{N}(x_n|\\mu,\\lambda^{-1}) + \\ln \\mathcal{N}(\\mu|m,\\lambda_{\\mu}^{-1}) + const. \\\\\n",
    "    &=& \\Sigma_{n=1}^{N} \\{-\\frac{1}{2}(x_n-\\mu)^2 \\lambda\\} + \\{-\\frac{1}{2}(\\mu-m)^2 \\lambda_{\\mu}\\} + const. \\\\\n",
    "    &=& -\\frac{1}{2}\\left[\\Sigma_{n=1}^{N}\\{(x_n^2 -2x_n\\mu + \\mu^2)\\lambda\\} + (\\mu^2 - 2\\mu m + m^2)\\lambda_{\\mu}\\right] + const. \\\\\n",
    "    &=& -\\frac{1}{2}\\{(N\\lambda + \\lambda_{\\mu})\\mu^2 - 2(\\Sigma_{n=1}^{N} x_n \\lambda + m \\lambda_{\\mu})\\mu\\} + const.\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "最後の変形では$\\mu$に関わらない値は$const.$に吸収させている。これを平方完成するとガウス分布の形になっていることがわかるがここでは結果から逆算的に求める。事後分布が次のようなガウス分布で書けるとする。\n",
    "\n",
    "$$\n",
    "p(\\mu|\\mathcal{D}) = \\mathcal{N}(\\mu|\\hat{m},\\hat{\\lambda_{\\mu}}^{-1})\n",
    "$$\n",
    "\n",
    "対数をとると\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    \\ln p(\\mu|\\mathcal{D}) &=& -\\frac{1}{2}(\\mu-\\hat{m})^2 \\hat{\\lambda_{\\mu}} \\\\\n",
    "    &=& -\\frac{1}{2}\\{\\hat{\\lambda_{\\mu}} \\mu^2 - 2\\hat{m} \\hat{\\lambda_{\\mu}} \\mu\\} + const.\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "となるので、事後分布のパラメータ$\\hat{m},\\hat{\\lambda_{\\mu}}$は次のように求まる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    \\hat{\\lambda_{\\mu}} &=& N \\lambda + \\lambda_{\\mu} \\\\\n",
    "    \\hat{m} &=& \\frac{\\lambda \\Sigma_{n=1}^{N} x_n + \\lambda_{\\mu}m}{\\hat{\\lambda_{\\mu}}}\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "以上で事後分布の推論が完了した。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: 更新された精度パラメータは、ハイパーパラメータに$N\\lambda$だけ加えたものでありデータ数$N$が大きくなる程精度が上がる、すなわち事後分布のばらつきが小さくなりかつハイパーパラメータの影響が小さくなることを示している。平均パラメータはハイパーパラメータ$m$と$\\Sigma{n=1}^{N}x_n$の重み付き和の形になっておりこれもデータ数が増えるほどハイパーパラメータの影響を受けにくくなることがわかる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測分布の算出\n",
    "\n",
    "モデル全体の事後分布をパラメータ$\\mu$で周辺化することで未知の観測$x_*$に対する予測分布が得られる。ハット記号を付けるのが面倒なので、学習していない事前分布から予測分布を算出し、後で更新されたパラメータを代入してみることにする。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(x_*) &=& \\int p(x_*|\\mu) p(\\mu) d\\mu \\\\\n",
    "    &=& \\int \\mathcal{N}(x_*|\\mu,\\lambda^{-1})\\mathcal{N}(\\mu|m,\\lambda_{\\mu}^{-1}) d\\mu\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "これを直接計算するのは大変なので、ベイズの定理と対数をうまく使ってみる。ベイズの定理から、\n",
    "\n",
    "$$\n",
    "p(\\mu|x_*) = \\frac{p(x_*|\\mu)p(\\mu)}{p(x_*)}\n",
    "$$\n",
    "\n",
    "$p(x_*)$を左辺に置いて対数をとると、\n",
    "\n",
    "$$\n",
    "\\ln p(x_*) = \\ln p(x_*|\\mu) - \\ln p(\\mu|x_*) + const.\n",
    "$$\n",
    "\n",
    "$\\ln p(\\mu)$は$x_*$には関係ないので$const.$とした。$p(\\mu|x_*)$は$p(\\mu|\\mathcal{D})$に$\\mathcal{D}=x_*$とすれば求まる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(\\mu|x_*) &=& \\mathcal{N}(\\mu|m(x_*), (\\lambda + \\lambda_{\\mu})^{-1}) \\\\\n",
    "    ただし　m(x_*) &=& \\frac{\\lambda x_* + \\lambda_{\\mu}m}{\\lambda + \\lambda_{\\mu}}\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "これと$p(x_*|\\mu) = \\mathcal{N}(\\mu, \\lambda^{-1})$を代入すると\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    \\ln p(x_*) &=& \\ln p(x_*|\\mu) - \\ln p(\\mu|x_*) + const. \\\\\n",
    "    &=& -\\frac{1}{2} \\{ \\lambda (x_* - \\mu)^2 - (\\lambda + \\lambda_{\\mu})(\\mu - m(x_*))^2 \\} + const. \\\\\n",
    "    &=& -\\frac{1}{2} \\{ \\lambda x_*^2 - 2 \\lambda \\mu x_* - \\frac{\\lambda^2 x_*^2 + 2 \\lambda \\lambda_{\\mu} m x_*}{\\lambda + \\lambda_{\\mu}} + 2 \\lambda \\mu x_* \\} + const. \\\\\n",
    "    &=& -\\frac{1}{2} \\{ \\frac{\\lambda^2 x_*^2 + \\lambda \\lambda_{\\mu} x_*^2 - \\lambda^2 x_*^2 - 2 \\lambda \\lambda_{\\mu} m x_*}{\\lambda + \\lambda_{\\mu}}\\} + const. \\\\\n",
    "    &=& -\\frac{1}{2} \\{ \\frac{\\lambda \\lambda_{\\mu}}{\\lambda + \\lambda_{\\mu}} x_*^2 - \\frac{2m\\lambda\\lambda_{\\mu}}{\\lambda + \\lambda_{\\mu}} x_* \\} + const.\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "$x_*$の2次関数の形にできたので事後分布と同じく逆算的に計算すると、予測分布$p(x_*)$は\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(x_*) &=& \\mathcal{N} (x_* | \\mu_*, \\lambda_{*}^{-1}) \\\\\n",
    "    ただし　\\lambda_* &=& \\frac{\\lambda \\lambda_{\\mu}}{\\lambda + \\lambda_{\\mu}} \\\\\n",
    "    \\mu_* &=& m\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "となる。これに$\\hat{m}, \\hat{\\lambda_{\\mu}}$を代入することで学習した後の予測分布$p(x_*|\\mathcal{D})$は\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(x_*) &=& \\mathcal{N} (x_* | \\mu_*, \\lambda_{*}^{-1}) \\\\\n",
    "    ただし　\\lambda_* &=& \\frac{\\lambda (N\\lambda + \\lambda_{\\mu})}{\\lambda + (N\\lambda + \\lambda_{\\mu})} \\\\\n",
    "    \\mu_* &=& \\frac{\\lambda \\Sigma_{n=1}^{N} x_n + \\lambda_{\\mu}m}{N\\lambda + \\lambda_{\\mu}}\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "と求まる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: 精度から見た結果の意味"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> 精度について逆数をとると意味がわかりやすい。\n",
    ">>\n",
    ">> $$\\lambda_*^{-1} = \\lambda^{-1} + \\hat{\\lambda_{\\mu}}^{-1}$$\n",
    ">>\n",
    ">> 精度の逆数は分散なので、この式は「予測分布の分散は観測分布の分散と事後分布の分散の和である」という意味になる。\n",
    ">>\n",
    ">> 今回は観測分布の分散が実際の分散に等しいことを仮定しているので、データ数が増え事後分布の分散が小さくなれば予測分布は実際の分布の分散とほぼ一致する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 平均が既知、精度が未知の場合\n",
    "\n",
    "今度は、平均パラメータ$\\mu$が既知で、精度パラメータ$\\lambda$が未知の場合でベイズ推論を行う。\n",
    "\n",
    "## モデルの構築\n",
    "\n",
    "精度パラメータ$\\lambda$は正の実数である必要がある。正の実数を出力する確率分布にはガンマ分布があり、平均既知精度未知の場合の1次元ガウス分布の共役事前分布として知られている。事前分布にガンマ分布を採用すると次のようにモデル構築することになる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(\\mathcal{D},x_*,\\lambda) &=& p(\\mathcal{D}|\\lambda)p(x_*|\\lambda)p(\\lambda) \\\\\n",
    "    p(\\mathcal{D}|\\lambda) &=& \\Pi_{n=1}^{N} \\mathcal{N}(x_n|\\mu, \\lambda^{-1}) \\\\\n",
    "    p(x_*|\\lambda) &=& \\mathcal{N}(x_*|\\mu, \\lambda^{-1}) \\\\\n",
    "    p(\\lambda) &=& Gam(\\lambda|a, b)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "このモデルのハイパーパラメータは$a,b$である。$\\mu$は既知の値という設定だが、$\\mu$をハイパーパラメータとして推論していると考えることもできる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: ガンマ分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ガンマ分布は$a, b \\in \\mathbb{R^+}$をパラメータに持ち、正の実数を生成する確率分布である。ガンマ分布の確率密度関数は次の通り。\n",
    ">>\n",
    ">> $$Gam(\\lambda|a,b) = C_G(a,b)\\lambda^{a-1}e^{-b\\lambda}$$\n",
    ">>\n",
    ">> $C_G(a,b)$は正規化係数であり、\n",
    ">>\n",
    ">> $$C_G(a,b) = \\frac{b^a}{\\Gamma(a)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 事後分布の推論\n",
    "\n",
    "事後分布$p(\\lambda|\\mathcal{D})$を推論する。ベイズの定理から\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(\\lambda|\\mathcal{D}) &\\propto& p(\\mathcal{D}|\\lambda)p(\\lambda) \\\\\n",
    "    &=& \\{ \\Pi_{n=1}^{N} p(x_n|\\lambda) \\} p(\\lambda) \\\\\n",
    "    &=& \\{ \\Pi_{n=1}^{N} \\mathcal{N}(x_n|\\mu, \\lambda^{-1}) \\} Gam(\\lambda|a,b)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "対数をとる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    \\ln p(\\lambda|\\mathcal{D}) &=& \\Sigma_{n=1}^{N} \\ln \\mathcal{N}(x_n|\\mu,\\lambda^{-1}) + \\ln Gam(\\lambda|a,b) + const. \\\\\n",
    "    &=& \\Sigma_{n=1}^{N}\\{\\frac{1}{2} \\ln \\lambda - \\frac{(x_n-\\mu)^2 \\lambda}{2}\\} + (a-1)\\ln \\lambda -b\\lambda + const. \\\\\n",
    "    &=& (\\frac{N}{2}+a-1)\\ln \\lambda - \\{\\frac{1}{2}\\Sigma_{n=1}^{N}(x_n-\\mu)^2 + b\\}\\lambda + const.\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "対数を戻せばこれはガンマ分布となることがわかる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(\\lambda|\\mathcal{D}) &=& Gam(\\lambda|\\hat{a},\\hat{b}) \\\\\n",
    "    ただし　\\hat{a} &=& \\frac{N}{2} + a \\\\\n",
    "    \\hat{b} &=& \\frac{1}{2} \\Sigma_{n=1}^{N} (x_n-\\mu)^2 + b\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "## 予測分布の算出\n",
    "\n",
    "事後分布の形状が事前分布と同じなので、学習前の予測分布$p(x_*)$を計算すれば、学習後の$\\hat{a},\\hat{b}$を代入するだけで$p(x_*|\\mathcal{D})$がわかる。\n",
    "\n",
    "$$\n",
    "p(x_*) = \\int p(x_*|\\lambda)p(\\lambda) d\\lambda\n",
    "$$\n",
    "\n",
    "を直接計算せずにベイズの定理と対数計算で簡単に計算してみる。\n",
    "\n",
    "$$\n",
    "p(\\lambda|x_*) = \\frac{p(x_*|\\lambda)p(\\lambda)}{p(x_*)}\n",
    "$$\n",
    "\n",
    "対数をとり、$p(\\lambda)$を定数にまとめれば\n",
    "\n",
    "$$\n",
    "\\ln p(x_*) = \\ln p(x_*|\\lambda) - \\ln p(\\lambda|x_*) + const.\n",
    "$$\n",
    "\n",
    "$\\ln p(\\lambda|x_*)$は事後分布の形に合わせれば\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(\\lambda|x_*) &=& Gam(\\lambda|\\frac{1}{2}+a,b(x_*)) \\\\\n",
    "    ただし　b(x_*) &=& \\frac{1}{2}(x_*-\\mu)^2 + b\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "と書ける。これを代入して\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    \\ln p(x_*) &=& \\ln \\mathcal{N}(x_*|\\mu,\\lambda^{-1}) - \\ln Gam(\\lambda|\\frac{1}{2}+a,b(x_*)) + cosnt. \\\\\n",
    "    &=& \\frac{1}{2} \\ln \\lambda - \\frac{(x_*-\\mu)^2 \\lambda}{2} - (a-\\frac{1}{2})\\ln \\lambda + \\{\\frac{1}{2}(x_*-\\mu)^2 + b \\} \\lambda - \\ln C_G(a+\\frac{1}{2}, \\frac{1}{2}(x_*-\\mu)^2 + b) + const. \\\\\n",
    "    &=& - (a+\\frac{1}{2})\\ln \\{\\frac{1}{2}(x_*-\\mu)^2 + b\\} + \\Gamma(a+\\frac{1}{2}) + const. \\\\\n",
    "    &=& - \\frac{2a+1}{2} \\ln \\{ 1 + \\frac{1}{2b}(x_*-\\mu)^2 \\} + const.\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "となる。途中、$x_*$を含まない項は$const.$に吸収させている。また、$\\lambda$に関わる項は消えている。この結果は1次元のStudentのt分布に対数をとったものと同じ形になっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: 1次元のStudentのt分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> 1次元のStudentのt分布は次の確率密度関数で表される。\n",
    ">>\n",
    ">> $$St(x|\\mu_s,\\lambda_s,\\nu_s) = \\frac{\\Gamma(\\frac{\\nu_s + 1}{2})}{\\Gamma(\\frac{\\nu_s}{2})}(\\frac{\\lambda_s}{\\pi \\nu_s})^{\\frac{1}{2}}\\{ 1 + \\frac{\\lambda_s}{\\nu_s} (x-\\mu_s)^2 \\}^{-\\frac{\\nu_s+1}{2}}$$\n",
    "\n",
    ">> 対数をとり$x$に関わらない部分をconst.にまとめると\n",
    ">>\n",
    ">> $$\\ln St(x|\\mu_s,\\lambda_s,\\nu_s) = -\\frac{\\nu_s+1}{2} \\ln \\{ 1 + \\frac{\\lambda_s}{\\nu_s} (x-\\mu_s)^2 \\} + const.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "対数t分布との対応を見れば、予測分布は次のように書けることがわかる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(x_*) &=& St(x_*|\\mu_s,\\lambda_s,\\nu_s) \\\\\n",
    "    ただし　\\mu_s &=& \\mu \\\\\n",
    "    \\lambda_s &=& \\frac{a}{b} \\\\\n",
    "    \\nu_s &=& 2a\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "学習により更新された$\\hat{a},\\hat{b}$を代入すると次のようになる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(x_*|\\mathcal{D}) &=& St(x_*|\\mu_s,\\lambda_s,\\nu_s) \\\\\n",
    "    ただし　\\mu_s &=& \\mu \\\\\n",
    "    \\lambda_s &=& \\frac{N+2a}{\\Sigma_{n=1}^{N} (x_n-\\mu)^2 + 2b} \\\\\n",
    "    \\nu_s &=& N + 2a\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 平均と精度がともに未知の場合\n",
    "\n",
    "次に、平均と精度がともに未知の場合のベイズ推論を実践してみる。モデルのパラメータが2個になっても、やることは変わらない。\n",
    "\n",
    "## モデルの構築\n",
    "\n",
    "平均についてガウス事前分布を、精度についてガンマ事前分布をそれぞれ設定し次のような同時分布を作ることも可能である(尤度関数は前と同じなので省略)。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(\\mathcal{D},x_*,\\mu,\\lambda) &=& p(\\mathcal{D}|\\mu,\\lambda^{-1})p(x_*|\\mu,\\lambda^{-1})p(\\mu)p(\\lambda) \\\\\n",
    "    p(\\mu) &=& \\mathcal{N}(\\mu|m,\\lambda_{\\mu}^{-1}) \\\\\n",
    "    p(\\lambda) &=& Gam(\\lambda|a,b)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "が、実はガウス・ガンマ分布という事前分布を用いると事後分布もガウス・ガンマ分布となることが知られている。ここではガウス・ガンマ分布を用いる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: ガウス・ガンマ分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ガウス・ガンマ分布は$m, \\beta, a, b$をパラメータに持ち、$\\mu, \\lambda$という2つの確率変数を生成する確率分布である。確率密度関数は次のように書ける。\n",
    ">>\n",
    ">> $$\n",
    "\\begin{eqnarray}\n",
    "p(\\mu,\\lambda) &=& NG(\\mu,\\lambda|m,\\beta,a,b) \\\\\n",
    "&=& \\mathcal{N}(\\mu|m,(\\beta \\lambda)^{-1})Gam(\\lambda|a,b)\n",
    "\\end{eqnarray}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ガウス事前分布・ガンマ事前分布を別々に設定する場合との違いは$\\mu$が$\\lambda$に条件づけられていることである。グラフィカルモデルで示すと次のようになる。\n",
    "\n",
    "![ガウス事前分布とガンマ事前分布を別々に設定した場合](dags/dag_gauss1.png)\n",
    "\n",
    "![ガウス・ガンマ分布を使った場合](dags/dag_gauss2.png)\n",
    "\n",
    "ガウス・ガンマ分布を使った場合モデルは次のようになる(尤度関数は省略)。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(\\mathcal{D},x_*,\\mu,\\lambda) &=& p(\\mathcal{D}|\\mu,\\lambda^{-1})p(x_*|\\mu,\\lambda^{-1})p(\\mu,\\lambda) \\\\\n",
    "    p(\\mu,\\lambda) &=& NG(\\mu,\\lambda|m,\\beta,a,b)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "## 事後分布の推論\n",
    "\n",
    "$\\mu$が$\\lambda$に条件づけられているので、同時分布$p(\\mathcal{D},\\mu,\\lambda)$は次のように変形できる。\n",
    "\n",
    "$$\n",
    "p(\\mathcal{D},\\mu,\\lambda) = p(\\mu|\\lambda,\\mathcal{D})p(\\lambda|\\mathcal{D})p(\\mathcal{D})\n",
    "$$\n",
    "\n",
    "未観測の変数の事後分布は同時分布を観測された変数の確率で割ることで求まるのでこの場合の事後分布は、\n",
    "\n",
    "$$\n",
    "\\frac{p(\\mathcal{D},\\mu,\\lambda)}{p(\\mathcal{D})} = p(\\mu|\\lambda,\\mathcal{D})p(\\lambda|\\mathcal{D})\n",
    "$$\n",
    "\n",
    "より、$p(\\mu|\\lambda,\\mathcal{D})p(\\lambda|\\mathcal{D})$のことを指す。\n",
    "\n",
    "### 平均に注目\n",
    "\n",
    "まず平均にのみ注目し$p(\\mu|\\lambda,\\mathcal{D})$について考える。平均未知精度既知の場合の事後分布の結果に対し$\\lambda$を$\\beta \\lambda$に置き換えれば、\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(\\mu|\\lambda,\\mathcal{D}) &=& \\mathcal{N}(\\mu|\\hat{m},(\\hat{\\beta}\\lambda)^{-1}) \\\\\n",
    "    ただし　\\hat{\\beta} &=& N + \\beta \\\\\n",
    "    \\hat{m} &=& \\frac{1}{\\hat{\\beta}}(\\Sigma_{n=1}^{N} x_n + \\beta m)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "> Note: 置き換えによって$\\lambda_{\\mu}=\\beta \\lambda$となっていることを利用した。\n",
    "\n",
    "### 精度に注目\n",
    "\n",
    "次に精度に関わる部分$p(\\lambda|\\mathcal{D})$を求める。同時分布から、\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(\\lambda|\\mathcal{D}) &=& \\frac{p(\\mathcal{D},\\mu,\\lambda)}{p(\\mu|\\lambda,\\mathcal{D})p(\\mathcal{D})} \\\\\n",
    "    &\\propto& \\frac{p(\\mathcal{D},\\mu,\\lambda)}{p(\\mu|\\lambda,\\mathcal{D})} \\\\\n",
    "    &=& \\frac{p(\\mathcal{D}|\\mu,\\lambda)p(\\mu,\\lambda)}{p(\\mu|\\lambda,\\mathcal{D})} \\\\\n",
    "    &=& \\frac{\\{\\Pi_{n=1}^{N} \\mathcal{N}(x_n|\\mu,\\lambda^{-1})\\} \\mathcal{N}(\\mu|m,(\\beta \\lambda)^{-1})Gam(\\lambda|a,b)}{\\mathcal{N}(\\mu|\\hat{m},(\\hat{\\beta}\\lambda)^{-1})}\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "対数をとって整理していく。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    \\ln p(\\lambda|\\mathcal{D}) &=& \\Sigma_{n=1}^{N} \\{\\ln \\mathcal{N}(x_n|\\mu,\\lambda^{-1}) \\} + \\ln \\mathcal{N}(\\mu|m,(\\beta \\lambda)^{-1}) + \\ln Gam(\\lambda|a,b) - \\ln \\mathcal{N}(\\mu|\\hat{m},(\\hat{\\beta}\\lambda)^{-1}) + const. \\\\\n",
    "    &=& \\Sigma_{n=1}^{N} \\{\\frac{1}{2}\\ln \\lambda - \\frac{(x_n-\\mu)^2 \\lambda}{2}\\} + \\frac{\\ln \\beta + \\ln \\lambda}{2} - \\frac{(\\mu-m)^2 \\beta\\lambda}{2} + (a-1)\\ln\\lambda -b\\lambda - \\frac{\\ln \\hat{\\beta} + \\ln \\lambda}{2} + \\frac{(\\mu-\\hat{m})^2 \\hat{\\beta}\\lambda}{2} + const.\\\\\n",
    "    &=& (\\frac{N}{2} + a - 1)\\ln \\lambda - \\frac{1}{2}\\{ \\Sigma_{n=1}^{N} x_n^2 - 2\\mu \\Sigma_{n=1}^{N} x_n + N\\mu^2 + \\beta \\mu^2 - 2\\mu m \\beta + m^2\\beta + 2 b - \\mu^2 \\hat{\\beta} + 2\\mu \\hat{m} \\hat{\\beta} - \\hat{m}^2 \\hat{\\beta} \\}\\lambda + const. \\\\\n",
    "    &=& (\\frac{N}{2} + a - 1)\\ln \\lambda - \\frac{1}{2}\\{ \\Sigma_{n=1}^{N} x_n^2 + 2\\mu(\\hat{m}\\hat{\\beta}- \\Sigma_{n=1}^{N} x_n - m \\beta) + (N + \\beta - \\hat{\\beta}) \\mu^2 + m^2 \\beta - \\hat{m}^2 \\hat{\\beta} + 2b \\} \\lambda + const. \\\\\n",
    "    &=& (\\frac{N}{2} + a - 1)\\ln \\lambda - \\{\\frac{1}{2}(\\Sigma_{n=1}^{N} x_n^2 + \\beta m^2 - \\hat{\\beta} \\hat{m}^2) + b\\} \\lambda + const.\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "ガンマ分布の定義式と照らし合わせて\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(\\lambda|\\mathcal{D}) &=& Gam(\\lambda|\\hat{a},\\hat{b}) \\\\\n",
    "    ただし　\\hat{a} &=& \\frac{N}{2} + a \\\\\n",
    "    \\hat{b} &=& \\frac{1}{2}(\\Sigma_{n=1}^{N} x_n^2 + \\beta m^2 - \\hat{\\beta} \\hat{m}^2) + b\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "### まとめ\n",
    "\n",
    "結局求めたい事後分布$p(\\mu|\\lambda,\\mathcal{D})p(\\lambda|\\mathcal{D})$は更新されたハイパーパラメータ$\\hat{m},\\hat{\\beta},\\hat{a},\\hat{b}$を持つガウス・ガンマ分布の形になる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(\\mu|\\lambda,\\mathcal{D})p(\\lambda|\\mathcal{D}) &=& \\mathcal{N}(\\mu|\\hat{m},(\\hat{\\beta}\\lambda)^{-1})Gam(\\lambda|\\hat{a},\\hat{b}) \\\\\n",
    "    &=& NG(\\mu, \\lambda|\\hat{m},\\hat{\\beta},\\hat{a},\\hat{b})\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "## 予測分布の導出\n",
    "\n",
    "事前分布と事後分布が同じ形状であるから、学習前の予測分布を導出し、更新されたハイパーパラメータを代入することで学習後の予測分布を求めることができる。\n",
    "\n",
    "学習前の予測分布は以下のように2つの変数を積分除去することで求められる。\n",
    "\n",
    "$$p(x_*) = \\int \\int p(x_*|\\mu,\\lambda)p(\\mu,\\lambda)d\\mu d\\lambda$$\n",
    "\n",
    "でもできれば積分はしたくないのでベイズの定理から求めてみる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: 積分は式変形も面倒だしコンピュータにとっても計算コストが高いのでできるだけしたくない。いかに積分を回避するかが肝。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベイズの定理から\n",
    "\n",
    "$$\n",
    "p(\\mu,\\lambda|x_*) = \\frac{p(x_*|\\mu,\\lambda)p(\\mu,\\lambda)}{p(x_*)} \n",
    "$$\n",
    "\n",
    "より\n",
    "\n",
    "$$\n",
    "\\ln p(x_*) = \\ln p(x_*|\\mu,\\lambda) - \\ln p(\\mu,\\lambda|x_*) + const.\n",
    "$$\n",
    "\n",
    "事後分布の結果を流用して、\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p(\\mu, \\lambda|x_*) &=& \\mathcal{N}(\\mu|m(x_*), \\{(1+\\beta)\\lambda \\}^{-1})Gam(\\lambda|\\frac{1}{2}+a,b(x_*)) \\\\\n",
    "    ただし　m(x_*) &=& \\frac{x_*+\\beta m}{1+\\beta} \\\\\n",
    "    b(x_*) &=& \\frac{\\beta}{2(1+\\beta)}(x_*-m)^2 + b\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: $m(x_*),b(x_*)$の導出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> $\\hat{m},\\hat{b}$を$\\mathcal{D}=x_*$として計算すると\n",
    ">>\n",
    ">>$$\n",
    "\\begin{eqnarray}\n",
    "    \\hat{m} &=& \\frac{1}{\\hat{\\beta}}(\\Sigma_{n=1}^{N} x_n + \\beta m) \\\\\n",
    "    &=& \\frac{1}{1+\\beta}(x_*+\\beta m)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    ">>\n",
    ">>$$\n",
    "\\begin{eqnarray}\n",
    "    \\hat{b} &=& \\frac{1}{2}(\\Sigma_{n=1}^{N} x_n^2 + \\beta m^2 - \\hat{\\beta} \\hat{m}^2) + b \\\\\n",
    "    &=& \\frac{1}{2}\\{x_*^2 + \\beta m^2 - (1+\\beta)(\\frac{x_*+\\beta m}{1+\\beta})^2\\} + b \\\\\n",
    "    &=& \\frac{1}{2(1+\\beta)}\\{(1+\\beta)(x_*^2+\\beta m^2) - x_*^2 - 2x_* \\beta m - \\beta^2 m^2\\} + b \\\\\n",
    "    &=& \\frac{1}{2(1+\\beta)}\\{\\beta x_*^2 - 2\\beta x_* m + \\beta m^2\\} +b \\\\\n",
    "    &=& \\frac{\\beta}{2(1+\\beta)}(x_*-m)^2 + b\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "よって予測分布$p(x_*)$は\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    \\ln p(x_*) = \\ln \\mathcal{N}(x_*|\\mu,\\lambda) - \\ln \\mathcal{N}(\\mu|m(x_*),\\{(1+\\beta)\\lambda\\}^{-1}) - \\ln Gam(\\lambda|\\frac{1}{2}+a,b(x_*))\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "以下執筆中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{ '[『ベイズ推論による機械学習入門』(須山敦志、講談社)](https://www.kspub.co.jp/book/detail/1538320.html)' | fndetail: 1 }}"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
