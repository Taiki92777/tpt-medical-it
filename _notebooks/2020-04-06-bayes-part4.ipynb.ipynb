{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ベイズ勉強会 Part 4 多次元ガウス分布のベイズ推論\n",
    "> 多次元ガウス分布のベイズ推論を実践する\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [bayes]\n",
    "- image: images/dag1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベイズ勉強会資料は『ベイズ推論による機械学習入門』{% fn 1 %}を元に、途中式計算をできるだけ省略せずに行ったものです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多次元ガウス分布\n",
    "\n",
    "多次元ガウス分布はD次元ベクトル${\\bf x} \\in \\mathbb{R}^D$を生成するための確率分布であり、以下の確率密度関数で表される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: 多次元ガウス分布の確率密度関数 $$\\frac{1}{\\sqrt{(2\\pi)^D |{\\bf \\Sigma} }|}\\exp{\\{-\\frac{1}{2}({\\bf x}-{\\bf \\mu})^\\mathrm{T} {\\bf \\Sigma}^{-1} ({\\bf x}-{\\bf \\mu})\\} }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\bf \\mu} \\in \\mathbb{R}^D$は平均パラメータ、${\\bf \\Sigma}$は共分散行列パラメータで$D \\times D$の正定値行列である必要がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: 正定値行列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> 固有値が全て正の実正方行列を正定値行列と呼ぶ。実正方行列${\\bf A}$が正定値行列である必要十分条件は任意の非ゼロベクトル${\\bf x}$に関して、\n",
    ">>\n",
    ">> $${\\bf x}^\\mathrm{T} {\\bf A}{\\bf x} > 0$$\n",
    ">>\n",
    ">> が成り立つこと。正定値行列の逆行列も正定値行列である。また全ての固有値が正であることから、\n",
    ">>\n",
    ">> $$|{\\bf A}| > 0$$\n",
    ">>\n",
    ">> が成り立つ。\n",
    ">>\n",
    ">> また、対称行列であるので\n",
    ">>\n",
    ">> $${\\bf A}^{\\mathrm{T} } = {\\bf A}$$\n",
    ">>\n",
    ">> が成り立つ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多次元ガウス分布を対数で表示すると、"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: 多次元ガウス分布の対数表示 $$\\ln \\mathcal{N}({\\bf x}|{\\bf \\mu},{\\bf \\Sigma})=-\\frac{1}{2}\\{({\\bf x}-{\\bf \\mu})^\\mathrm{T} {\\bf \\Sigma}^{-1}({\\bf x}-{\\bf \\mu}) + \\ln |{\\bf \\Sigma}| + D \\ln 2\\pi\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1次元ガウス分布と同様に分散の逆元として精度を定義できる。共分散行列$\\bf{\\Sigma}$の逆行列として精度行列$\\bf{\\Lambda}$を定義する。すなわち$\\bf{\\Lambda}=\\bf{\\Sigma}^{-1}$である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: 多次元ガウス分布を精度行列で表した場合 $$\\frac{1}{\\sqrt{(2\\pi)^D} }|{\\bf \\Lambda}|^{\\frac{1}{2} }\\exp{\\{-\\frac{1}{2}({\\bf x}-{\\bf \\mu})^\\mathrm{T} {\\bf \\Lambda} ({\\bf x}-{\\bf \\mu})\\} }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: 多次元ガウス分布の対数表示(精度行列で表した場合) $$\\ln \\mathcal{N}({\\bf x}|{\\bf \\mu},{\\bf \\Lambda}^{-1})=-\\frac{1}{2}\\{({\\bf x}-{\\bf \\mu})^\\mathrm{T} {\\bf \\Lambda}({\\bf x}-{\\bf \\mu}) - \\ln |{\\bf \\Lambda}| + D\\ln 2\\pi\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この多次元ガウス分布のベイズ推論を行っていく。1次元ガウス分布と同様、平均パラメータ未知、精度パラメータ未知、両方未知の場合の順に行う。なお本稿では特に断り無い限り多次元ガウス分布のことをガウス分布と呼ぶ。\n",
    "\n",
    "# 平均未知\n",
    "\n",
    "D次元の確率変数${\\bf x} \\in \\mathbb{R}^D$の平均パラメータ${\\bf \\mu} \\in \\mathbb{R}^D$のみが未知で、精度行列${\\bf \\Lambda} \\in \\mathbb{R}^{D \\times D}$は既に与えられている、またはハイパーパラメータとして、ベイズ推論を行ってみる。N個のデータ${\\bf X} = \\{ {\\bf x}_1,\\dots,{\\bf x}_N\\}$が観測されていて、予測する未知の観測を${\\bf x}_*$とおく。\n",
    "\n",
    "## モデルの構築\n",
    "\n",
    "平均のみが未知の時は、ガウス分布を事前分布とすることで共役性が満たされることがわかっている。${\\bf m} \\in \\mathbb{R}^D, {\\bf \\Lambda}_{\\mu} \\in \\mathbb{R}^{D \\times D}$をハイパーパラメータとして同時分布は次のようになる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p({\\bf X},{\\bf x}_*,{\\bf \\mu}) &=& p({\\bf X}|{\\bf \\mu})p({\\bf x}_*|{\\bf \\mu})p({\\bf \\mu}) \\\\\n",
    "    p({\\bf X}|{\\bf \\mu}) &=& \\Pi_{n=1}^{N} \\mathcal{N}({\\bf x}_n|{\\bf \\mu},{\\bf \\Lambda}^{-1}) \\\\\n",
    "    p({\\bf x}_*|{\\bf \\mu}) &=& \\mathcal{N}({\\bf x}_*|{\\bf \\mu},{\\bf \\Lambda}^{-1}) \\\\\n",
    "    p({\\bf \\mu}) &=& \\mathcal{N}({\\bf \\mu}|{\\bf m},{\\bf \\Lambda}_{\\mu}^{-1})\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "## 事後分布の推論\n",
    "\n",
    "ベイズの定理を用いて事後分布$p({\\bf \\mu}|{\\bf X})$は次のようになる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p({\\bf \\mu}|{\\bf X}) &\\propto& p({\\bf X}|{\\bf \\mu})p({\\bf \\mu}) \\\\\n",
    "    &=& \\{ \\Pi_{n=1}^{N} p({\\bf x}_n|{\\bf \\mu})\\}p({\\bf \\mu}) \\\\\n",
    "    &=& \\Pi_{n=1}^{N} \\{\\mathcal{N}({\\bf x}_n|{\\bf \\mu},{\\bf \\Lambda}^{-1})\\} \\mathcal{N}({\\bf \\mu}|{\\bf m},{\\bf \\Lambda}_{\\mu}^{-1})\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "対数をとると\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    \\ln p({\\bf \\mu}|{\\bf X}) &=& \\Sigma_{n=1}^{N} \\ln \\mathcal{N}({\\bf x}_n|{\\bf \\mu},{\\bf \\Lambda}^{-1}) + \\ln \\mathcal{N}({\\bf \\mu}|{\\bf m},{\\bf \\Lambda}_{\\mu}^{-1}) + const. \\\\\n",
    "    &=& -\\frac{1}{2} \\Sigma_{n=1}^{N} ({\\bf x}_n-{\\bf \\mu})^\\mathrm{T} {\\bf \\Lambda}({\\bf x}_n-{\\bf \\mu}) - \\frac{1}{2}({\\bf \\mu}-{\\bf m})^\\mathrm{T}{\\bf \\Lambda}_{\\mu}({\\bf \\mu}-{\\bf m}) + const. \\\\\n",
    "    &=& -\\frac{1}{2} \\Sigma_{n=1}^{N} ({\\bf x}_n^{\\mathrm{T} }-{\\bf \\mu}^{\\mathrm{T} }){\\bf \\Lambda}({\\bf x}_n-{\\bf \\mu}) - \\frac{1}{2}({\\bf \\mu}^{\\mathrm{T} }-{\\bf m}^{\\mathrm{T} }) {\\bf \\Lambda}_{\\mu}({\\bf \\mu}-{\\bf m}) + const. \\\\\n",
    "    &=& \\frac{1}{2}\\Sigma_{n=1}^{N}\\{ {\\bf x}_n^{\\mathrm{T} }{\\bf \\Lambda}{\\bf \\mu}\\} + \\frac{1}{2} {\\bf \\mu}^{\\mathrm{T} } {\\bf \\Lambda}\\Sigma_{n=1}^{N} {\\bf x}_n - \\frac{N}{2} {\\bf \\mu}^{\\mathrm{T} }{\\bf \\Lambda}{\\bf \\mu} - \\frac{1}{2} {\\bf \\mu}^{\\mathrm{T} }{\\bf \\Lambda}_{\\mu}{\\bf \\mu} + \\frac{1}{2}{\\bf \\mu}^{\\mathrm{T} }{\\bf \\Lambda}_{\\mu}{\\bf m} + \\frac{1}{2}{\\bf m}^{\\mathrm{T} }{\\bf \\Lambda}_{\\mu}{\\bf \\mu} + const.\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、${\\bf x}_n^{\\mathrm{T} }{\\bf \\Lambda}{\\bf \\mu}$は行数と列数について(1×D)×(D×D)×(D×1)=(1×1)よりスカラーなので次が成り立つ。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    {\\bf x}_n^{\\mathrm{T} }{\\bf \\Lambda}{\\bf \\mu} &=& ({\\bf x}_n^{\\mathrm{T} }{\\bf \\Lambda}{\\bf \\mu})^{\\mathrm{T} }　(スカラーを転置しても同じ) \\\\\n",
    "    &=& {\\bf \\mu}^{\\mathrm{T} } {\\bf \\Lambda}^{\\mathrm{T} } {\\bf x}_n　(これは公式通り) \\\\\n",
    "    &=& {\\bf \\mu}^{\\mathrm{T} } {\\bf \\Lambda} {\\bf x}_n　({\\bf \\Lambda}は対称行列)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "${\\bf m}^{\\mathrm{T} }{\\bf \\Lambda}_{\\mu} {\\bf \\mu}$についても同様であり、\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    \\ln p({\\bf \\mu}|{\\bf X}) &=& \\frac{1}{2}\\Sigma_{n=1}^{N}\\{ {\\bf x}_n^{\\mathrm{T} }{\\bf \\Lambda}{\\bf \\mu}\\} + \\frac{1}{2} {\\bf \\mu}^{\\mathrm{T} } {\\bf \\Lambda}\\Sigma_{n=1}^{N} {\\bf x}_n - \\frac{N}{2} {\\bf \\mu}^{\\mathrm{T} }{\\bf \\Lambda}{\\bf \\mu} - \\frac{1}{2} {\\bf \\mu}^{\\mathrm{T} }{\\bf \\Lambda}_{\\mu}{\\bf \\mu} + \\frac{1}{2}{\\bf \\mu}^{\\mathrm{T} }{\\bf \\Lambda}_{\\mu}{\\bf m} + \\frac{1}{2}{\\bf m}^{\\mathrm{T} }{\\bf \\Lambda}_{\\mu}{\\bf \\mu} + const. \\\\\n",
    "    &=& \\frac{1}{2}{\\bf \\mu}^{\\mathrm{T} } {\\bf \\Lambda}\\Sigma_{n=1}^{N} {\\bf x}_n + \\frac{1}{2}{\\bf \\mu}^{\\mathrm{T} } {\\bf \\Lambda}\\Sigma_{n=1}^{N} {\\bf x}_n - \\frac{N}{2} {\\bf \\mu}^{\\mathrm{T} }{\\bf \\Lambda}{\\bf \\mu} - \\frac{1}{2} {\\bf \\mu}^{\\mathrm{T} }{\\bf \\Lambda}_{\\mu}{\\bf \\mu} + \\frac{1}{2}{\\bf \\mu}^{\\mathrm{T} }{\\bf \\Lambda}_{\\mu}{\\bf m} + + \\frac{1}{2}{\\bf \\mu}^{\\mathrm{T} }{\\bf \\Lambda}_{\\mu}{\\bf m} + const. \\\\\n",
    "    &=& - \\frac{1}{2}\\{ {\\bf \\mu}^{\\mathrm{T} } (N {\\bf \\Lambda}+{\\bf \\Lambda}_{\\mu}){\\bf \\mu} - 2 {\\bf \\mu}^{\\mathrm{T} }({\\bf \\Lambda} \\Sigma_{n=1}^{N} {\\bf x}_n + {\\bf \\Lambda}_{\\mu} {\\bf m})\\} + const.\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "${\\bf \\mu}$に関する上に凸の二次関数となり、ガウス分布であることがわかる。1次元と同様に逆算的に計算していく。\n",
    "\n",
    "$$p({\\bf \\mu}|{\\bf X}) = \\mathcal{N}({\\bf \\mu}|\\hat{\\bf m},\\hat{\\bf \\Lambda}_{\\bf \\mu}^{-1})$$\n",
    "\n",
    "とおき、対数をとって${\\bf \\mu}$について整理すると\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    \\ln p({\\bf \\mu}|{\\bf X}) &=& -\\frac{1}{2}\\{({\\bf \\mu}-\\hat{\\bf m})^\\mathrm{T} \\hat{\\bf \\Lambda}_{\\bf \\mu} ({\\bf \\mu}-\\hat{\\bf m}) \\} + const. \\\\\n",
    "    &=& -\\frac{1}{2} \\{ {\\bf \\mu}^{\\mathrm{T} } \\hat{\\bf \\Lambda}_{\\bf \\mu} {\\bf \\mu} - \\hat{\\bf m}^{\\mathrm{T} } \\hat{\\bf \\Lambda}_{\\bf \\mu} {\\bf \\mu} - {\\bf \\mu}^{\\mathrm{T} } \\hat{\\bf \\Lambda}_{\\bf \\mu} \\hat{\\bf m} \\} + const. \\\\\n",
    "    &=& -\\frac{1}{2} \\{ {\\bf \\mu}^{\\mathrm{T} } \\hat{\\bf \\Lambda}_{\\bf \\mu} {\\bf \\mu}-2{\\bf \\mu}^{\\mathrm{T} } \\hat{\\bf \\Lambda}_{\\bf \\mu} \\hat{\\bf m} \\} + const.\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "対応関係を見れば\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    \\hat{\\bf \\Lambda}_{\\bf \\mu} = N{\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu} \\\\\n",
    "    \\hat{\\bf m} = \\hat{\\bf \\Lambda}_{\\bf \\mu}^{-1}({\\bf \\Lambda} \\Sigma_{n=1}^{N} {\\bf x}_n + {\\bf \\Lambda}_{\\mu} {\\bf m})\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "と事後分布のハイパーパラメータが求まる。\n",
    "\n",
    "## 予測分布の導出\n",
    "\n",
    "簡単のために学習前の事前分布を用いて予測分布を導出し、更新されたハイパーパラメータを代入することで学習後の予測分布を計算する。1次元の時と同様、ベイズの定理と対数化を利用し積分計算を避ける。\n",
    "\n",
    "$$\\ln p({\\bf x}_*) = \\ln p({\\bf x}_*|{\\bf \\mu}) - \\ln p({\\bf \\mu}|{\\bf x}_*) + const.$$\n",
    "\n",
    "$\\ln p({\\bf \\mu}|{\\bf x}_*)$は${\\bf x}_*$を学習した後の事後分布と見なせるので、\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p({\\bf \\mu}|{\\bf x}_*) &=& \\mathcal{N}({\\bf \\mu}|{\\bf m}({\\bf x}_*), ({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1}) \\\\\n",
    "    ただし　{\\bf m}({\\bf x}_*) &=& ({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1} ({\\bf \\Lambda}{\\bf x}_* + {\\bf \\Lambda}_{\\bf \\mu} {\\bf m})\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "したがって、\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    \\ln p({\\bf x}_*) &=& \\ln p({\\bf x}_*|{\\bf \\mu}) - \\ln p({\\bf \\mu}|{\\bf x}_*) + const. \\\\\n",
    "    &=& -\\frac{({\\bf x}_*-{\\bf \\mu})^\\mathrm{T}{\\bf \\Lambda}({\\bf x}_*-{\\bf \\mu})}{2} + \\frac{({\\bf \\mu}-{\\bf m}({\\bf x}_*))^\\mathrm{T}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\mu})({\\bf \\mu}-{\\bf m}({\\bf x}_*))}{2} + const. \\\\\n",
    "    &=& -\\frac{1}{2}\\{ {\\bf x}_*^{\\mathrm{T} }{\\bf \\Lambda}{\\bf x}_* - {\\bf x}_*^{\\mathrm{T} }{\\bf \\Lambda}{\\bf \\mu} - {\\bf \\mu}^\\mathrm{T}{\\bf \\Lambda}{\\bf x}_* - {\\bf m}({\\bf x}_*)^\\mathrm{T} ({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu}) {\\bf m}({\\bf x}_*) + {\\bf m}({\\bf x}_*)^\\mathrm{T}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu}){\\bf \\mu} + {\\bf \\mu}^\\mathrm{T}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu}){\\bf m}({\\bf x}_*) \\} + const. \\\\\n",
    "    &=& -\\frac{1}{2}\\{ {\\bf x}_*^{\\mathrm{T} }{\\bf \\Lambda}{\\bf x}_* - 2 {\\bf x}_*^{\\mathrm{T} }{\\bf \\Lambda}{\\bf \\mu} - {\\bf m}({\\bf x}_*)^\\mathrm{T} ({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu}) {\\bf m}({\\bf x}_*) + 2 {\\bf \\mu}^\\mathrm{T}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu}){\\bf m}({\\bf x}_*)\\} + const. \\\\\n",
    "    &=& -\\frac{1}{2}\\{ {\\bf x}_*^{\\mathrm{T} }{\\bf \\Lambda}{\\bf x}_* - 2 {\\bf x}_*^{\\mathrm{T} }{\\bf \\Lambda}{\\bf \\mu} - {\\bf m}({\\bf x}_*)^\\mathrm{T} ({\\bf \\Lambda}{\\bf x}_* + {\\bf \\Lambda}_{\\bf \\mu}{\\bf m}) + 2{\\bf \\mu}^\\mathrm{T}{\\bf \\Lambda}{\\bf x}_*\\} + const. \\\\\n",
    "    &=& -\\frac{1}{2}\\{ {\\bf x}_*^{\\mathrm{T} }{\\bf \\Lambda}{\\bf x}_* - ({\\bf \\Lambda}{\\bf x}_* + {\\bf \\Lambda}_{\\bf \\mu}{\\bf m})^\\mathrm{T} {\\bf m}({\\bf x}_*) \\} + const.　({\\bf m}({\\bf x}_*)^\\mathrm{T} ({\\bf \\Lambda}{\\bf x}_* + {\\bf \\Lambda}_{\\bf \\mu}{\\bf m})はスカラーなので転置しても変わらない) \\\\\n",
    "    &=& -\\frac{1}{2}\\{ {\\bf x}_*^{\\mathrm{T} }{\\bf \\Lambda}{\\bf x}_* - ({\\bf \\Lambda}{\\bf x}_* + {\\bf \\Lambda}_{\\bf \\mu}{\\bf m})^\\mathrm{T} ({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1} ({\\bf \\Lambda}{\\bf x}_* + {\\bf \\Lambda}_{\\bf \\mu}{\\bf m}) \\} + const. \\\\\n",
    "    &=& -\\frac{1}{2}\\{ {\\bf x}_*^{\\mathrm{T} }{\\bf \\Lambda}{\\bf x}_* - ({\\bf \\Lambda}{\\bf x}_*)^\\mathrm{T}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1}{\\bf \\Lambda}{\\bf x}_* - ({\\bf \\Lambda}{\\bf x}_*)^\\mathrm{T}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1}{\\bf \\Lambda}_{\\bf \\mu}{\\bf m} - ({\\bf \\Lambda}_{\\bf \\mu}{\\bf m})^\\mathrm{T}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1}{\\bf \\Lambda}{\\bf x}_*\\} + const. \\\\\n",
    "    &=& -\\frac{1}{2}\\{ {\\bf x}_*^{\\mathrm{T} }{\\bf \\Lambda}{\\bf x}_* - {\\bf x}_*^\\mathrm{T}{\\bf \\Lambda}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1}{\\bf \\Lambda}{\\bf x}_* - 2{\\bf x}_*^\\mathrm{T}{\\bf \\Lambda}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1}{\\bf \\Lambda}_{\\bf \\mu}{\\bf m} \\} + const. \\\\\n",
    "    &=& -\\frac{1}{2}\\{ {\\bf x}_*^{\\mathrm{T} } ({\\bf \\Lambda}-{\\bf \\Lambda}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1}{\\bf \\Lambda}) {\\bf x}_* - 2{\\bf x}_*^\\mathrm{T}{\\bf \\Lambda}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1}{\\bf \\Lambda}_{\\bf \\mu}{\\bf m} \\} + const.\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "ここで\n",
    "\n",
    "$$\n",
    "p({\\bf x}_*) = \\mathcal{N}({\\bf x}_*|{\\bf \\mu}_*,{\\bf \\Lambda}_*^{-1})\n",
    "$$\n",
    "\n",
    "と書けるとすると\n",
    "\n",
    "$$\n",
    "\\ln p({\\bf x}_*) = -\\frac{1}{2} \\{ {\\bf x}_*^{\\mathrm{T} } {\\bf \\Lambda}_{*} {\\bf x}_* -2{\\bf x}_*^{\\mathrm{T} } {\\bf \\Lambda}_{*} {\\bf \\mu}_*\\} + const.\n",
    "$$\n",
    "\n",
    "であるから、対応関係から\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    {\\bf \\Lambda}_* &=& {\\bf \\Lambda}-{\\bf \\Lambda}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1}{\\bf \\Lambda} \\\\\n",
    "    {\\bf \\mu}_* &=& {\\bf \\Lambda}_*^{-1} {\\bf \\Lambda}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1}{\\bf \\Lambda}_{\\bf \\mu}{\\bf m}\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "ウッドベリーの公式を使うことで更に簡潔な形にできる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: ウッドベリーの公式 $$({\\bf A}+{\\bf U}{\\bf B}{\\bf V})^{-1} = {\\bf A}^{-1} - {\\bf A}^{-1}{\\bf U}({\\bf B}^{-1}+{\\bf V}{\\bf A}^{-1}{\\bf U})^{-1}{\\bf V}{\\bf A}^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: ウッドベリーの公式(${\\bf A},{\\bf B}$の次元が等しく, ${\\bf U},{\\bf V}$が単位行列の場合) $$({\\bf A}+{\\bf B})^{-1} = {\\bf A}^{-1} - {\\bf A}^{-1}({\\bf A}^{-1} + {\\bf B}^{-1})^{-1} {\\bf A}^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\bf \\Lambda}_*$について、${\\bf A}={\\bf \\Lambda}^{-1},{\\bf B}={\\bf \\Lambda}_{\\bf \\mu}^{-1}$とおくと、\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    {\\bf \\Lambda}_* &=& {\\bf \\Lambda}-{\\bf \\Lambda}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1}{\\bf \\Lambda} \\\\\n",
    "    &=& {\\bf A}^{-1} - {\\bf A}^{-1}({\\bf A}^{-1} + {\\bf B}^{-1})^{-1} {\\bf A}^{-1} \\\\\n",
    "    &=& ({\\bf A}+{\\bf B})^{-1} \\\\\n",
    "    &=& ({\\bf \\Lambda}^{-1} + {\\bf \\Lambda}_{\\mu}^{-1})^{-1}\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "${\\bf \\mu}_*$は、${\\bf \\Lambda}_* = {\\bf \\Lambda}-{\\bf \\Lambda} ({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1} {\\bf \\Lambda}$より\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    {\\bf \\Lambda}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1}{\\bf \\Lambda} &=& {\\bf \\Lambda} - {\\bf \\Lambda}_* \\\\\n",
    "    {\\bf \\Lambda}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1} &=& ({\\bf \\Lambda} - {\\bf \\Lambda}_*){\\bf \\Lambda}^{-1}\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "だから\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    {\\bf \\mu}_* &=& {\\bf \\Lambda}_*^{-1} {\\bf \\Lambda}({\\bf \\Lambda}+{\\bf \\Lambda}_{\\bf \\mu})^{-1}{\\bf \\Lambda}_{\\bf \\mu}{\\bf m} \\\\\n",
    "    &=& {\\bf \\Lambda}_*^{-1} ({\\bf \\Lambda} - {\\bf \\Lambda}_*){\\bf \\Lambda}^{-1}{\\bf \\Lambda}_{\\bf \\mu}{\\bf m} \\\\\n",
    "    &=& \\{ {\\bf \\Lambda}_*^{-1}{\\bf \\Lambda}{\\bf \\Lambda}^{-1}{\\bf \\Lambda}_{\\bf \\mu} - {\\bf \\Lambda}_*^{-1}{\\bf \\Lambda}_* {\\bf \\Lambda}^{-1}{\\bf \\Lambda}_{\\bf \\mu} \\}{\\bf m} \\\\\n",
    "    &=& \\{ {\\bf \\Lambda}_*^{-1}{\\bf \\Lambda}_{\\bf \\mu} -  {\\bf \\Lambda}^{-1}{\\bf \\Lambda}_{\\bf \\mu} \\}{\\bf m} \\\\\n",
    "    &=& \\{ ({\\bf \\Lambda}^{-1} + {\\bf \\Lambda}_{\\mu}^{-1}){\\bf \\Lambda}_{\\bf \\mu} -  {\\bf \\Lambda}^{-1}{\\bf \\Lambda}_{\\bf \\mu}\\}{\\bf m} \\\\\n",
    "    &=& {\\bf I}_D {\\bf m} = {\\bf m}\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "まとめると、\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    {\\bf \\Lambda}_* &=& ({\\bf \\Lambda}^{-1} + {\\bf \\Lambda}_{\\mu}^{-1})^{-1} \\\\\n",
    "    {\\bf \\mu}_* &=& {\\bf m}\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "これらに、更新されたハイパーパラメータ$\\hat{\\bf m},\\hat{\\bf \\Lambda}_{\\bf \\mu}$を代入して学習後の予測分布$p({\\bf x}_*|{\\bf X})$が求まる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 精度行列未知\n",
    "\n",
    "## モデルの構築\n",
    "\n",
    "多次元ガウス分布の精度行列は正定値行列である必要がある。$D \\times D$の正定値行列を生成する確率分布にウィシャート分布がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: ウィシャート分布の確率密度関数 $$\\mathcal{W}({\\bf \\Lambda}|\\nu,{\\bf W}) = C_\\mathcal{W} (\\nu, {\\bf W})|{\\bf \\Lambda}|^{\\frac{\\nu-D-1}{2} } exp\\{ -\\frac{1}{2} Tr({\\bf W}^{-1} {\\bf \\Lambda})\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\nu$は自由度パラメータで、$\\nu > D - 1$を満たす必要がある。また、パラメータ${\\bf W}$は$D \\times D$の正定値行列である。$Tr()$はトレースといい、行列の対角成分の和をとる演算である。ウィシャート分布も対数化することで計算の見通しが良くなる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: ウィシャート分布の対数化 $$\\ln \\mathcal{W} ({\\bf \\Lambda}|\\nu,{\\bf W}) = \\frac{\\nu-D-1}{2} \\ln |{\\bf \\Lambda}| - \\frac{1}{2} Tr({\\bf W}^{-1} {\\bf \\Lambda}) + \\ln C_\\mathcal{W} (\\nu, {\\bf W})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: 対数化された正規化項 $$\\ln C_\\mathcal{W} (\\nu, {\\bf W}) = - \\frac{\\nu}{2} \\ln |{\\bf W}| - \\ln \\frac{\\nu D}{2} \\ln 2 - \\frac{D(D-1)}{4} \\ln \\pi - \\Sigma_{d=1}^{D} \\ln \\Gamma(\\frac{\\nu+1+d}{2})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: トレースについて成り立つ等式 $$\\begin{eqnarray} Tr({\\bf A}) &=& Tr({\\bf A}^\\mathrm{T}) \\\\ Tr({\\bf A} + {\\bf B}) &=& Tr({\\bf A}) + Tr({\\bf B}) \\\\ Tr({\\bf AB}) &=& Tr({\\bf BA}) \\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さて、このウィシャート分布を用いてモデルを構築すると次のようになる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p({\\bf X},{\\bf x}_*,{\\bf \\Lambda}) &=& p({\\bf X}|{\\bf \\Lambda})p({\\bf x}_*|{\\bf \\Lambda})p({\\bf \\Lambda}) \\\\\n",
    "    p({\\bf x}_*|{\\bf \\Lambda}) &=& \\mathcal{N}({\\bf x}_* |{\\bf \\mu}, {\\bf \\Lambda}^{-1}) \\\\\n",
    "    p({\\bf X}|{\\bf \\Lambda}) &=& \\Pi_{n=1}^{N} \\mathcal{N}({\\bf x}_n |{\\bf \\mu}, {\\bf \\Lambda}^{-1}) \\\\\n",
    "    p({\\bf \\Lambda}) &=& \\mathcal{W}({\\bf \\Lambda}|\\nu, {\\bf W})\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "## 事後分布の推論\n",
    "\n",
    "データ${\\bf X}$を観測した後の事後分布は\n",
    "\n",
    "$$\n",
    "p({\\bf \\Lambda}|{\\bf X}) \\propto p({\\bf X}|{\\bf \\Lambda}) p({\\bf \\Lambda})\n",
    "$$\n",
    "\n",
    "ゆえ対数化すると\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    \\ln p({\\bf \\Lambda}|{\\bf X}) &=& \\Sigma_{n=1}^{N} \\ln \\mathcal{N} ({\\bf x}_n|{\\bf \\mu}, {\\bf \\Lambda}^{-1}) + \\ln \\mathcal{W}({\\bf \\Lambda} |\\nu, {\\bf W}) + const. \\\\\n",
    "    &=& - \\frac{1}{2} \\{ \\Sigma_{n=1}^{N} ({\\bf x}_n-{\\bf \\mu})^\\mathrm{T} {\\bf \\Lambda}({\\bf x}_n-{\\bf \\mu}) -  N \\ln |{\\bf \\Lambda}| \\} + \\frac{\\nu-D-1}{2} \\ln |{\\bf \\Lambda}| - \\frac{1}{2} Tr({\\bf W}^{-1} {\\bf \\Lambda}) + const. \\\\\n",
    "    &=& \\frac{N+\\nu-D-1}{2} \\ln |{\\bf \\Lambda}| - \\frac{1}{2} \\Sigma_{n=1}^{N} Tr \\{ ({\\bf x}_n-{\\bf \\mu})^\\mathrm{T} {\\bf \\Lambda}({\\bf x}_n-{\\bf \\mu}) \\} - \\frac{1}{2} Tr({\\bf W}^{-1} {\\bf \\Lambda}) + const.　(スカラーのトレースをとっても同じ) \\\\\n",
    "    &=& \\frac{N+\\nu-D-1}{2} \\ln |{\\bf \\Lambda}| - \\frac{1}{2} \\Sigma_{n=1}^{N} Tr \\{ ({\\bf x}_n-{\\bf \\mu})({\\bf x}_n-{\\bf \\mu})^\\mathrm{T} {\\bf \\Lambda} \\} - \\frac{1}{2} Tr({\\bf W}^{-1} {\\bf \\Lambda}) + const.　(トレース内では対角成分が同じであれば順番を入れ替えても問題ない) \\\\\n",
    "    &=& \\frac{N+\\nu-D-1}{2} \\ln |{\\bf \\Lambda}| - \\frac{1}{2} Tr \\left[ \\{ \\Sigma_{n=1}^{N} ({\\bf x}_n-{\\bf \\mu})({\\bf x}_n-{\\bf \\mu})^\\mathrm{T} + {\\bf W}^{-1} \\} {\\bf \\Lambda} \\right] + const.　(トレースの和は和のトレース)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "ウィシャート分布との対応を見れば、\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p({\\bf \\Lambda}|{\\bf X}) &=& \\mathcal{W}({\\bf \\Lambda}|\\hat{\\nu}, \\hat{\\bf W}) \\\\\n",
    "    ただし　\\hat{\\bf W}^{-1} &=& \\Sigma_{n=1}^{N} ({\\bf x}_n - {\\bf \\mu})({\\bf x}_n - {\\bf \\mu})^\\mathrm{T} + {\\bf W}^{-1} \\\\\n",
    "    \\hat{\\nu} &=& N + \\nu\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "となる。\n",
    "\n",
    "## 予測分布の導出\n",
    "\n",
    "事前分布と事後分布の形が同じなので、表記がシンプルになるよう学習前のハイパーパラメータで予測分布を計算し、後で代入する。\n",
    "\n",
    "積分計算を避け、ベイズの定理と対数を利用する。学習前の予測分布$p({\\bf x}_*)$は、\n",
    "\n",
    "$$\n",
    "\\ln p({\\bf x}_*) = \\ln p({\\bf x}_*|{\\bf \\Lambda}) - \\ln p({\\bf \\Lambda}|{\\bf x}_*) + const.\n",
    "$$\n",
    "\n",
    "と表せる。事後分布の結果を流用して\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p({\\bf \\Lambda}|{\\bf x}_*) &=& \\mathcal{W}({\\bf \\Lambda}|1+\\nu , {\\bf W}({\\bf x}_*)) \\\\\n",
    "    ただし　{\\bf W} ({\\bf x}_*)^{-1} &=& ({\\bf x}_* - {\\bf \\mu})({\\bf x}_* - {\\bf \\mu})^\\mathrm{T} + {\\bf W}^{-1}\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "よって\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    \\ln p({\\bf x}_*) &=& \\ln p({\\bf x}_*|{\\bf \\Lambda}) - \\ln p({\\bf \\Lambda}|{\\bf x}_*) + const. \\\\\n",
    "    &=& -\\frac{1}{2} \\left[ ({\\bf x}_* -{\\bf \\mu})^\\mathrm{T} {\\bf \\Lambda} ({\\bf x}_* -{\\bf \\mu}) - Tr \\{ {\\bf W}({\\bf x}_*)^{-1}{\\bf \\Lambda} \\} - (\\nu + 1) \\ln |{\\bf W} ({\\bf x}_*)| \\right] + const.\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "行列式、トレースの性質を使いながら計算を進める。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: 行列式の性質 $$\\begin{eqnarray} |c{\\bf A}| &=& c^N |{\\bf A}| \\\\ |{\\bf A}^\\mathrm{T}| &=& |{\\bf A}| \\\\ |{\\bf A}{\\bf B}| &=& |{\\bf A}| |{\\bf B}| \\\\ |{\\bf A}^{-1}| &=& |{\\bf A}|^{-1} \\\\ |{\\bf I}_N + {\\bf C} {\\bf D}^\\mathrm{T} | &=& |{\\bf I}_M + {\\bf C}^\\mathrm{T} {\\bf D}|　(この{\\bf C}と{\\bf D}はN \\times M行列) \\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{eqnarray}\n",
    "    \\ln p({\\bf x}_*) &=& -\\frac{1}{2} \\left[ Tr \\{ ({\\bf x}_* -{\\bf \\mu})^\\mathrm{T} {\\bf \\Lambda} ({\\bf x}_* -{\\bf \\mu})) \\} - Tr \\{ ({\\bf x}_* - {\\bf \\mu})({\\bf x}_* - {\\bf \\mu})^\\mathrm{T} {\\bf \\Lambda}) \\} + (\\nu + 1) \\ln |{\\bf W} ({\\bf x}_*)^{-1}| \\right] + const. \\\\\n",
    "    &=& - \\frac{1+\\nu}{2} \\ln |({\\bf x}_* - {\\bf \\mu})({\\bf x}_* - {\\bf \\mu})^\\mathrm{T} + {\\bf W}^{-1}| + const. \\\\\n",
    "    &=& - \\frac{1+\\nu}{2} \\ln |{\\bf W}^{-1} \\{ {\\bf W} ({\\bf x}_* - {\\bf \\mu})({\\bf x}_* - {\\bf \\mu})^\\mathrm{T} + {\\bf I}_D \\}| + const. \\\\\n",
    "    &=& - \\frac{1+\\nu}{2} \\ln |{\\bf W}^{-1}| |{\\bf I}_D + {\\bf W} ({\\bf x}_* - {\\bf \\mu})({\\bf x}_* - {\\bf \\mu})^\\mathrm{T}| + const. \\\\\n",
    "    &=& - \\frac{1+\\nu}{2} \\ln |{\\bf I}_D + {\\bf W} ({\\bf x}_* - {\\bf \\mu})({\\bf x}_* - {\\bf \\mu})^\\mathrm{T} | + const. \\\\\n",
    "    &=& - \\frac{1+\\nu}{2} \\ln |{\\bf I}_1 + \\{ {\\bf W} ({\\bf x}_* - {\\bf \\mu}) \\}^\\mathrm{T} ({\\bf x}_* - {\\bf \\mu}) | + const.　(D \\times 1行列になっている) \\\\\n",
    "    &=& - \\frac{1+\\nu}{2} \\ln \\{ 1 + ({\\bf x}_* - {\\bf \\mu})^\\mathrm{T} {\\bf W} ({\\bf x}_* - {\\bf \\mu}) \\} + const.\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "これは多次元のStudentのt分布になっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: 多次元のStudentのt分布: $$St({\\bf x} | {\\bf \\mu}_s , {\\bf \\Lambda}_s , \\nu_s) = \\frac{\\Gamma(\\frac{\\nu_s + D}{2})}{\\Gamma(\\frac{\\nu_s}{2})} \\frac{|{\\bf \\Lambda}_s|^{\\frac{1}{2} } } {(\\pi \\nu_s)^{\\frac{D}{2} }} \\left\\{ 1 + \\frac{1}{\\nu_s} ({\\bf x} - {\\bf \\mu}_s)^\\mathrm{T} {\\bf \\Lambda}_s ({\\bf x} - {\\bf \\mu}_s) \\right\\}^{- \\frac{\\nu_s + D}{2} }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これを対数化して${\\bf x}$に関わる項だけ抜き出すと、\n",
    "\n",
    "$$\n",
    "\\ln St({\\bf x} | {\\bf \\mu}_s , {\\bf \\Lambda}_s , \\nu_s) = - \\frac{\\nu_s + D}{2} \\ln \\left\\{ 1 + \\frac{1}{\\nu_s} ({\\bf x} - {\\bf \\mu}_s)^\\mathrm{T} {\\bf \\Lambda}_s ({\\bf x} - {\\bf \\mu}_s) \\right\\} + const.\n",
    "$$\n",
    "\n",
    "対応を見ると学習前の予測分布$p({\\bf x}_*)$は次のように表せる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p({\\bf x}_*) &=& St({\\bf x} | {\\bf \\mu}_s , {\\bf \\Lambda}_s , \\nu_s) \\\\\n",
    "    ただし　{\\bf \\mu}_s &=& {\\bf \\mu} \\\\\n",
    "    {\\bf \\Lambda}_s &=& (1-D+\\nu){\\bf W} \\\\\n",
    "    \\nu_s &=& 1-D+\\nu\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "学習後の予測分布$p({\\bf x}_* | {\\bf X})$はこれに更新されたハイパーパラメータを代入することで求まる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 平均・精度行列未知\n",
    "\n",
    "## モデル構築\n",
    "\n",
    "平均パラメータの事前分布をガウス分布、精度パラメータの事前分布をウィシャート分布と別々に決めてもいいが、ガウス・ウィシャート分布が尤度関数がガウス分布の場合の共役事前分布として知られている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: ガウス・ウィシャート分布 $$NW({\\bf \\mu}, {\\bf \\Lambda}|{\\bf m},\\beta,\\nu,{\\bf W}) = \\mathcal{N}({\\bf \\mu}|{\\bf m}, (\\beta {\\bf \\Lambda})^{-1}) \\mathcal{W} ({\\bf \\Lambda}|\\nu, {\\bf W})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ガウス・ウィシャート分布を事前分布とした場合のモデルは次のようになる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p({\\bf X},{\\bf x}_*,{\\bf \\mu}, {\\bf \\Lambda}) &=& p({\\bf X}|{\\bf \\mu}, {\\bf \\Lambda})p({\\bf x}_*|{\\bf \\mu}, {\\bf \\Lambda}) p({\\bf \\mu}) p({\\bf \\Lambda}) \\\\\n",
    "    p({\\bf \\mu}, {\\bf \\Lambda}) &=& NW({\\bf \\mu}, {\\bf \\Lambda}|{\\bf m},\\beta,\\nu,{\\bf W})\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 事後分布の推論\n",
    "\n",
    "データ${\\bf X}$を観測した後の事後分布を求める。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p({\\bf \\mu}, {\\bf \\Lambda}| {\\bf X}) &=& \\frac{p({\\bf X}, {\\bf \\mu}, {\\bf \\Lambda})}{p({\\bf X})} \\\\\n",
    "    &=& \\frac{p({\\bf \\mu}|{\\bf \\Lambda}, {\\bf X}) p({\\bf \\Lambda}|{\\bf X}) p({\\bf X}) }{p({\\bf X})} \\\\\n",
    "    &=& p({\\bf \\mu}|{\\bf \\Lambda}, {\\bf X}) p({\\bf \\Lambda}|{\\bf X})\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "1次元の場合と同様に、平均と精度の事後分布を別々に求めてみる。\n",
    "\n",
    "### 平均の事後分布\n",
    "\n",
    "平均未知の場合の事後分布で精度行列を$\\beta {\\bf \\Lambda}$とおくことにより求まる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p({\\bf \\mu}|{\\bf \\Lambda}, {\\bf X}) &=& \\mathcal{N}({\\bf \\mu}|\\hat{\\bf m}, (\\hat{\\beta} {\\bf \\Lambda})^{-1}) \\\\\n",
    "    ただし　\\hat{\\beta} &=& N + \\beta \\\\\n",
    "    \\hat{\\bf m} &=& \\frac{1}{\\hat{\\beta}}(\\Sigma_{n=1}^{N} {\\bf x}_n + \\beta {\\bf m})\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: この部分の式変形 $$\\begin{eqnarray} {\\bf \\Lambda}_{\\bf \\mu} &=& \\beta {\\bf \\Lambda},　 \\hat{\\bf \\Lambda}_{\\bf \\mu} = \\hat{\\beta} {\\bf \\Lambda}　とおいて平均未知の式を見れば、 \\\\ \\hat{\\beta} {\\bf \\Lambda} &=& N {\\bf \\Lambda} + \\beta {\\bf \\Lambda}　ゆえ \\\\ \\hat{\\beta} &=& N + \\beta \\\\ \\hat{\\bf m} &=& \\frac{1}{\\hat{\\beta} } \\hat{\\bf \\Lambda}^{-1} ({\\bf \\Lambda} \\Sigma_{n=1}^{N} {\\bf x}_n + \\beta {\\bf \\Lambda} {\\bf m}) \\\\ &=& \\frac{1}{\\hat{\\beta} }(\\Sigma_{n=1}^{N} {\\bf x}_n + \\beta {\\bf m}) \\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精度の事後分布\n",
    "\n",
    "ベイズの定理より、\n",
    "\n",
    "$$\n",
    "p({\\bf \\mu}, {\\bf \\Lambda}| {\\bf X}) = \\frac{p({\\bf X}|{\\bf \\mu}, {\\bf \\Lambda})p({\\bf \\mu},{\\bf \\Lambda})}{p({\\bf X})}\n",
    "$$\n",
    "\n",
    "が成り立つので、\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p({\\bf \\mu}|{\\bf \\Lambda}, {\\bf X}) p({\\bf \\Lambda}|{\\bf X}) &=& \\frac{p({\\bf X}|{\\bf \\mu}, {\\bf \\Lambda})p({\\bf \\mu},{\\bf \\Lambda})}{p({\\bf X})} \\\\\n",
    "    p({\\bf \\Lambda}|{\\bf X}) &=& \\frac{p({\\bf X}|{\\bf \\mu}, {\\bf \\Lambda})p({\\bf \\mu},{\\bf \\Lambda})}{p({\\bf X})p({\\bf \\mu}|{\\bf \\Lambda}, {\\bf X})} \\\\\n",
    "    \\ln p({\\bf \\Lambda}|{\\bf X}) &=& \\ln p({\\bf X}|{\\bf \\mu}, {\\bf \\Lambda}) + \\ln p({\\bf \\mu},{\\bf \\Lambda}) - \\ln p({\\bf \\mu}|{\\bf \\Lambda}, {\\bf X}) + const. \\\\\n",
    "    &=& \\Sigma_{n=1}^{N} \\ln \\mathcal{N}({\\bf x}_n|{\\bf \\mu}, {\\bf \\Lambda}^{-1}) + \\ln NW({\\bf \\mu}, {\\bf \\Lambda}|{\\bf m},\\beta,\\nu,{\\bf W}) - \\ln \\mathcal{N}({\\bf \\mu}|\\hat{\\bf m}, (\\hat{\\beta} {\\bf \\Lambda})^{-1}) + const. \\\\\n",
    "    &=& \\Sigma_{n=1}^{N} \\ln \\mathcal{N}({\\bf x}_n|{\\bf \\mu}, {\\bf \\Lambda}^{-1}) + \\ln \\mathcal{N}({\\bf \\mu}|{\\bf m}, (\\beta {\\bf \\Lambda})^{-1}) + \\ln \\mathcal{W} ({\\bf \\Lambda}|\\nu, {\\bf W}) - \\ln \\mathcal{N}({\\bf \\mu}|\\hat{\\bf m}, (\\hat{\\beta} {\\bf \\Lambda})^{-1}) + const. \\\\\n",
    "    &=& - \\frac{1}{2} \\{ \\Sigma_{n=1}^{N} ({\\bf x}_n - {\\bf \\mu})^\\mathrm{T} {\\bf \\Lambda} ({\\bf x}_n - {\\bf \\mu}) - N \\ln |{\\bf \\Lambda}| \\} - \\frac{\\beta}{2} ({\\bf \\mu} - {\\bf m})^\\mathrm{T} {\\bf \\Lambda} ({\\bf \\mu} - {\\bf m}) + \\frac{1}{2} \\ln |\\beta {\\bf \\Lambda}| + \\frac{\\nu-D-1}{2} \\ln |{\\bf \\Lambda}| - \\frac{1}{2} Tr({\\bf W}^\\mathrm{T} {\\bf \\Lambda}) + \\frac{\\hat{\\beta}}{2} ({\\bf \\mu} - \\hat{\\bf m})^\\mathrm{T} {\\bf \\Lambda} ({\\bf \\mu} - \\hat{\\bf m}) - \\frac{1}{2} \\ln |\\hat{\\beta} {\\bf \\Lambda}| + const. \\\\\n",
    "    &=& - \\frac{1}{2} \\{ \\Sigma_{n=1}^{N} ({\\bf x}_n - {\\bf \\mu})^\\mathrm{T} {\\bf \\Lambda} ({\\bf x}_n - {\\bf \\mu}) - N \\ln |{\\bf \\Lambda}| \\} - \\frac{\\beta}{2} ({\\bf \\mu} - {\\bf m})^\\mathrm{T} {\\bf \\Lambda} ({\\bf \\mu} - {\\bf m}) + \\frac{1}{2} \\ln |{\\bf \\Lambda}| + \\frac{\\nu-D-1}{2} \\ln |{\\bf \\Lambda}| - \\frac{1}{2} Tr({\\bf W}^{-1} {\\bf \\Lambda}) + \\frac{\\hat{\\beta}}{2} ({\\bf \\mu} - \\hat{\\bf m})^\\mathrm{T} {\\bf \\Lambda} ({\\bf \\mu} - \\hat{\\bf m}) - \\frac{1}{2} \\ln |{\\bf \\Lambda}| + const.　(|\\beta {\\bf \\Lambda}|=\\beta^{D} |{\\bf \\Lambda}|だが対数を取っているのでconst.に吸収させている。) \\\\\n",
    "    &=& \\frac{N+\\nu-D-1}{2} \\ln |{\\bf \\Lambda}| - \\frac{1}{2} Tr \\left[ \\{ \\Sigma_{n=1}^{N} {\\bf x}_n {\\bf x}_n^\\mathrm{T} + \\beta {\\bf m} {\\bf m}^\\mathrm{T} - \\hat{\\beta} \\hat{\\bf m} \\hat{\\bf m}^\\mathrm{T} + {\\bf W}^{-1} \\} {\\bf \\Lambda} \\right] + const.　(スカラーはトレースを取ってまとめた)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "と整理できる。これをウィシャート分布の定義式と対応関係を取って\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p({\\bf \\Lambda}|{\\bf X}) &=& \\mathcal{W}({\\bf \\Lambda}|\\hat{\\nu},\\hat{\\bf W}) \\\\\n",
    "    ただし　\\hat{\\bf W}^{-1} &=& \\Sigma_{n=1}^{N} {\\bf x}_n {\\bf x}_n^\\mathrm{T} + \\beta {\\bf m} {\\bf m}^\\mathrm{T} - \\hat{\\beta} \\hat{\\bf m} \\hat{\\bf m}^\\mathrm{T} + {\\bf W}^{-1} \\\\\n",
    "    \\hat{\\nu} &=& N + \\nu\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "### 事後分布をまとめる\n",
    "\n",
    "以上をまとめて事後分布は次のようになる。\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    p({\\bf \\mu}, {\\bf \\Lambda}|{\\bf X}) &=& NW({\\bf \\mu}, {\\bf \\Lambda}| \\hat{\\bf m}, \\hat{\\beta}, \\hat{\\nu}, \\hat{\\bf W}) \\\\\n",
    "    ただし　\\hat{\\beta} &=& N + \\beta \\\\\n",
    "    \\hat{\\bf m} &=& \\frac{1}{\\hat{\\beta}}(\\Sigma_{n=1}^{N} {\\bf x}_n + \\beta {\\bf m}) \\\\\n",
    "    ただし　\\hat{\\bf W}^{-1} &=& \\Sigma_{n=1}^{N} {\\bf x}_n {\\bf x}_n^\\mathrm{T} + \\beta {\\bf m} {\\bf m}^\\mathrm{T} - \\hat{\\beta} \\hat{\\bf m} \\hat{\\bf m}^\\mathrm{T} + {\\bf W}^{-1} \\\\\n",
    "    \\hat{\\nu} &=& N + \\nu\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{ '[須山敦志. 杉山将. ベイズ推論による機械学習入門. 講談社, 2017.](https://www.kspub.co.jp/book/detail/1538320.html)' | fndetail: 1 }}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
