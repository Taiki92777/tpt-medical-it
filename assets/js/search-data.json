{
  
    
        "post0": {
            "title": "Circular Binary Segmentation",
            "content": "&#24517;&#35201;&#12394;&#12497;&#12483;&#12465;&#12540;&#12472;&#12398;&#12452;&#12531;&#12509;&#12540;&#12488; . library(DNAcopy) library(tidyverse) . Registered S3 methods overwritten by &#39;ggplot2&#39;: method from [.quosures rlang c.quosures rlang print.quosures rlang Registered S3 method overwritten by &#39;rvest&#39;: method from read_xml.response xml2 ── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ── ✔ ggplot2 3.1.1 ✔ purrr 0.3.2 ✔ tibble 2.1.1 ✔ dplyr 0.8.0.1 ✔ tidyr 0.8.3 ✔ stringr 1.4.0 ✔ readr 1.3.1 ✔ forcats 0.4.0 ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ✖ dplyr::filter() masks stats::filter() ✖ dplyr::lag() masks stats::lag() . &#12469;&#12531;&#12503;&#12523;&#12487;&#12540;&#12479;&#12398;&#12452;&#12531;&#12509;&#12540;&#12488; . data(coriell) head(coriell) . CloneChromosomePositionCoriell.05296Coriell.13330 . GS1-232B23 | 1 | 0 | NA | 0.207470 | . RP11-82d16 | 1 | 468 | 0.008824 | 0.063076 | . RP11-62m23 | 1 | 2241 | -0.000890 | 0.123881 | . RP11-60j11 | 1 | 4504 | 0.075875 | 0.154343 | . RP11-111O05 | 1 | 5440 | 0.017303 | -0.043890 | . RP11-51b04 | 1 | 7000 | -0.006770 | 0.094144 | . &#12392;&#12426;&#12354;&#12360;&#12378;&#21487;&#35222;&#21270; . coriell.rmna &lt;- drop_na(coriell) chrom_pos &lt;- coriell.rmna %&gt;% mutate(id = 1:nrow(coriell.rmna)) %&gt;% group_by(Chromosome) %&gt;% summarise(min = min(id), pos = median(id), max=max(id)) y.pos &lt;- replace(rep(-1.6, 23), seq(0,23,2), -1.5) coriell.rmna %&gt;% mutate(id = 1:nrow(coriell.rmna), class = coriell.rmna$Chromosome %% 2) %&gt;% ggplot2::ggplot() + geom_point(mapping = aes(x = interaction(Chromosome, id, lex.order=T), y = Coriell.05296, color=class)) + annotate(geom = &quot;text&quot;, x = chrom_pos$pos, y = y.pos, size=3, label = unique(coriell.rmna$Chromosome)) + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(), legend.position=&quot;none&quot;) . Circular Binary Segmentation&#12399;&#12497;&#12483;&#12465;&#12540;&#12472;&#21270;&#12373;&#12428;&#12390;&#12356;&#12427; . #1 DNAcopyオブジェクトの作成 | #2 外れ値の除去（後述） | #3 Circular Binary Segmentationの実行 | . ※実装に関してはパッケージの中身をみるか、またはpythonが読める人ならこちらが役に立つ。 . CNA.object &lt;- CNA(cbind(coriell$Coriell.05296), coriell$Chromosome, coriell$Position, data.type=&quot;logratio&quot;, sampleid=&quot;c05296&quot;) #1 smoothed.CNA.object &lt;- smooth.CNA(CNA.object) #2 segment.smoothed.CNA.object &lt;- segment(smoothed.CNA.object, verbose=1) #3 . Warning message in CNA(cbind(coriell$Coriell.05296), coriell$Chromosome, coriell$Position, : “array has repeated maploc positions ” . Analyzing: c05296 . . オブジェクトの中身をみれば、具体的なブレイクポイントがわかる。 . segment.smoothed.CNA.object . Call: segment(x = smoothed.CNA.object, verbose = 1) ID chrom loc.start loc.end num.mark seg.mean 1 c05296 1 468 240000 132 0.0212 2 c05296 2 0 245000 64 0.0095 3 c05296 3 0 218000 86 0.0025 4 c05296 4 0 171809 143 -0.0087 5 c05296 4 172856 179118 9 0.1752 6 c05296 4 179200 184000 13 -0.0350 7 c05296 5 0 198500 108 -0.0107 8 c05296 6 0 188000 85 -0.0048 9 c05296 7 0 161500 172 -0.0042 10 c05296 8 0 147000 151 -0.0026 11 c05296 9 0 115000 111 -0.0236 12 c05296 10 0 64187 53 -0.0165 13 c05296 10 65000 69549 4 0.3509 14 c05296 10 70547 110000 37 0.5164 15 c05296 10 110412 142000 32 -0.0076 16 c05296 11 0 34420 51 0.0121 17 c05296 11 35416 39623 15 -0.6511 18 c05296 11 43357 145000 119 0.0171 19 c05296 12 0 142000 94 0.0204 20 c05296 13 3426 100500 57 -0.0337 21 c05296 14 770 97000 76 0.0191 22 c05296 15 0 79000 66 0.0138 23 c05296 16 0 84000 66 0.0270 24 c05296 17 0 86000 91 0.0538 25 c05296 18 0 86000 53 0.0018 26 c05296 19 0 70000 37 -0.0274 27 c05296 20 0 73000 87 0.0129 28 c05296 21 3131 17703 18 0.0763 29 c05296 21 17704 30000 15 -0.0231 30 c05296 22 1100 33000 16 0.0183 31 c05296 23 0 155000 51 0.7184 . DataFrameも取得可能 . segment.smoothed.CNA.object[[&#39;output&#39;]] . IDchromloc.startloc.endnum.markseg.mean . c05296 | 1 | 468 | 240000 | 132 | 0.0212 | . c05296 | 2 | 0 | 245000 | 64 | 0.0095 | . c05296 | 3 | 0 | 218000 | 86 | 0.0025 | . c05296 | 4 | 0 | 171809 | 143 | -0.0087 | . c05296 | 4 | 172856 | 179118 | 9 | 0.1752 | . c05296 | 4 | 179200 | 184000 | 13 | -0.0350 | . c05296 | 5 | 0 | 198500 | 108 | -0.0107 | . c05296 | 6 | 0 | 188000 | 85 | -0.0048 | . c05296 | 7 | 0 | 161500 | 172 | -0.0042 | . c05296 | 8 | 0 | 147000 | 151 | -0.0026 | . c05296 | 9 | 0 | 115000 | 111 | -0.0236 | . c05296 | 10 | 0 | 64187 | 53 | -0.0165 | . c05296 | 10 | 65000 | 69549 | 4 | 0.3509 | . c05296 | 10 | 70547 | 110000 | 37 | 0.5164 | . c05296 | 10 | 110412 | 142000 | 32 | -0.0076 | . c05296 | 11 | 0 | 34420 | 51 | 0.0121 | . c05296 | 11 | 35416 | 39623 | 15 | -0.6511 | . c05296 | 11 | 43357 | 145000 | 119 | 0.0171 | . c05296 | 12 | 0 | 142000 | 94 | 0.0204 | . c05296 | 13 | 3426 | 100500 | 57 | -0.0337 | . c05296 | 14 | 770 | 97000 | 76 | 0.0191 | . c05296 | 15 | 0 | 79000 | 66 | 0.0138 | . c05296 | 16 | 0 | 84000 | 66 | 0.0270 | . c05296 | 17 | 0 | 86000 | 91 | 0.0538 | . c05296 | 18 | 0 | 86000 | 53 | 0.0018 | . c05296 | 19 | 0 | 70000 | 37 | -0.0274 | . c05296 | 20 | 0 | 73000 | 87 | 0.0129 | . c05296 | 21 | 3131 | 17703 | 18 | 0.0763 | . c05296 | 21 | 17704 | 30000 | 15 | -0.0231 | . c05296 | 22 | 1100 | 33000 | 16 | 0.0183 | . c05296 | 23 | 0 | 155000 | 51 | 0.7184 | . 可視化も一瞬 . plot(segment.smoothed.CNA.object, plot.type=&quot;whole&quot;) . &#22806;&#12428;&#20516;&#12398;&#38500;&#21435;&#12395;&#38306;&#12375;&#12390; . 各添字 $i (i = 1, 2, ..., n)$ に対して、$i - R, ..., i, ..., i + R (2≤R≤5)$ のウィンドウを定義する。 . $m_i$ をウィンドウ領域の中央値とし、$ hat sigma$ を標準偏差とする。 . 観測値 $X_i$ がウィンドウ領域の最大値または最小値だった場合、その値に最も近い値を持つ $X_j$ を探す。 . $|X_j - X_i|&gt;L hat sigma (default: L=4)$ だった場合、$X_i$ を $m_{i}+sign(X_i-X_j)M hat sigma$ に置き換える。 .",
            "url": "https://vintea01.github.io/tpt-medical-it/bioinformatics/2020/04/07/circular-binary-segmentation.html",
            "relUrl": "/bioinformatics/2020/04/07/circular-binary-segmentation.html",
            "date": " • Apr 7, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "ベイズ勉強会 Part 4 多次元ガウス分布のベイズ推論",
            "content": "ベイズ勉強会資料は『ベイズ推論による機械学習入門』1を元に、途中式計算をできるだけ省略せずに行ったものです。 . &#22810;&#27425;&#20803;&#12460;&#12454;&#12473;&#20998;&#24067; . 多次元ガウス分布はD次元ベクトル$ bf{x} in mathbb{R}^D$を生成するための確率分布であり、以下の確率密度関数で表される。 . . Important: 多次元ガウス分布の確率密度関数 $$ frac{1}{ sqrt{(2 pi)^D | bf{ Sigma}}|} exp{ {- frac{1}{2}( bf{x}- bf{ mu})^ mathrm{T} bf{ Sigma}^{-1} ( bf{x}- bf{ mu}) }}$$ . $ bf{ mu} in mathbb{R}^D$は平均パラメータ、$ bf{ Sigma}$は共分散行列パラメータでD×Dの正定値行列である必要がある。 . . Important: 正定値行列 . 固有値が全て正の実正方行列を正定値行列と呼ぶ。実正方行列$ bf{A}$が正定値行列である必要十分条件は任意の非ゼロベクトル$ bf{x}$に関して、 . $$ bf{x}^ mathrm{T} bf{A} bf{x} &gt; 0$$が成り立つこと。正定値行列の逆行列も正定値行列である。また全ての固有値が正であることから、 . $$| bf{A}| &gt; 0$$が成り立つ。 . また、対称行列であるので . $$ bf{A}^{ mathrm{T}} = bf{A}$$が成り立つ。 . 多次元ガウス分布を対数で表示すると、 . . Important: 多次元ガウス分布の対数表示 $$ ln mathcal{N}( bf{x}| bf{ mu}, bf{ Sigma})=- frac{1}{2} {( bf{x}- bf{ mu})^ mathrm{T} bf{ Sigma}^{-1}( bf{x}- bf{ mu}) + ln | bf{ Sigma}| + D ln 2 pi }$$ . 1次元ガウス分布と同様に分散の逆元として精度を定義できる。共分散行列$ bf{ Sigma}$の逆行列として精度行列$ bf{ Lambda}$を定義する。すなわち$ bf{ Lambda}= bf{ Sigma}^{-1}$である。 . . Important: 多次元ガウス分布を精度行列で表した場合 $$ frac{1}{ sqrt{(2 pi)^D}}| bf{ Lambda}|^{ frac{1}{2}} exp{ {- frac{1}{2}( bf{x}- bf{ mu})^ mathrm{T} bf{ Lambda} ( bf{x}- bf{ mu}) }}$$ . . Important: 多次元ガウス分布の対数表示(精度行列で表した場合) $$ ln mathcal{N}( bf{x}| bf{ mu}, bf{ Lambda}^{-1})=- frac{1}{2} {( bf{x}- bf{ mu})^ mathrm{T} bf{ Lambda}( bf{x}- bf{ mu}) - ln | bf{ Lambda}| + D ln 2 pi }$$ . この多次元ガウス分布のベイズ推論を行っていく。1次元ガウス分布と同様、平均パラメータ未知、精度パラメータ未知、両方未知の場合の順に行う。なお本稿では特に断り無い限り多次元ガウス分布のことをガウス分布と呼ぶ。 . &#24179;&#22343;&#26410;&#30693; . D次元の確率変数$ bf{x} in mathbb{R}^D$の平均パラメータ$ bf{ mu} in mathbb{R}^D$のみが未知で、精度行列$ bf{ Lambda} in mathbb{R}^{D times D}$は既に与えられている、またはハイパーパラメータとして、ベイズ推論を行ってみる。N個のデータ$ bf{X} = { bf{x}_1, dots, bf{x}_N }$が観測されていて、予測する未知の観測を$ bf{x}_*$とおく。 . &#12514;&#12487;&#12523;&#12398;&#27083;&#31689; . 平均のみが未知の時は、ガウス分布を事前分布とすることで共役性が満たされることがわかっている。$ bf{m} in mathbb{R}^D, bf{ Lambda}_{ mu} in mathbb{R}^{D times D}$をハイパーパラメータとして同時分布は次のようになる。 . $$ begin{eqnarray} p( bf{X}, bf{x}_*, bf{ mu}) &amp;=&amp; p( bf{X}| bf{ mu})p( bf{x}_*| bf{ mu})p( bf{ mu}) p( bf{X}| bf{ mu}) &amp;=&amp; Pi_{n=1}^{N} mathcal{N}( bf{x}_n| bf{ mu}, bf{ Lambda}^{-1}) p( bf{x}_*| bf{ mu}) &amp;=&amp; mathcal{N}( bf{x}_*| bf{ mu}, bf{ Lambda}^{-1}) p( bf{ mu}) &amp;=&amp; mathcal{N}( bf{ mu}| bf{m}, bf{ Lambda}_{ mu}^{-1}) end{eqnarray} $$&#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . ベイズの定理を用いて事後分布$p( bf{ mu}| bf{X})$は次のようになる。 . $$ begin{eqnarray} p( bf{ mu}| bf{X}) &amp; propto&amp; p( bf{X}| bf{ mu})p( bf{ mu}) &amp;=&amp; { Pi_{n=1}^{N} p( bf{x}_n| bf{ mu}) }p( bf{ mu}) &amp;=&amp; Pi_{n=1}^{N} { mathcal{N}( bf{x}_n| bf{ mu}, bf{ Lambda}^{-1}) } mathcal{N}( bf{ mu}| bf{m}, bf{ Lambda}_{ mu}^{-1}) end{eqnarray} $$対数をとると . $$ begin{eqnarray} ln p( bf{ mu}| bf{X}) &amp;=&amp; Sigma_{n=1}^{N} ln mathcal{N}( bf{x}_n| bf{ mu}, bf{ Lambda}^{-1}) + ln mathcal{N}( bf{ mu}| bf{m}, bf{ Lambda}_{ mu}^{-1}) + const. &amp;=&amp; - frac{1}{2} Sigma_{n=1}^{N} ( bf{x}_n- bf{ mu})^ mathrm{T} bf{ Lambda}( bf{x}_n- bf{ mu}) - frac{1}{2}( bf{ mu}- bf{m})^ mathrm{T} bf{ Lambda}_{ mu}( bf{ mu}- bf{m}) + const. &amp;=&amp; - frac{1}{2} Sigma_{n=1}^{N} ( bf{x}_n^{ mathrm{T}}- bf{ mu}^{ mathrm{T}}) bf{ Lambda}( bf{x}_n- bf{ mu}) - frac{1}{2}( bf{ mu}^{ mathrm{T}}- bf{m}^{ mathrm{T}}) bf{ Lambda}_{ mu}( bf{ mu}- bf{m}) + const. &amp;=&amp; frac{1}{2} Sigma_{n=1}^{N} { bf{x}_n^{ mathrm{T}} bf{ Lambda} bf{ mu} } + frac{1}{2} bf{ mu}^{ mathrm{T}} bf{ Lambda} Sigma_{n=1}^{N} bf{x}_n - frac{N}{2} bf{ mu}^{ mathrm{T}} bf{ Lambda} bf{ mu} - frac{1}{2} bf{ mu}^{ mathrm{T}} bf{ Lambda}_{ mu} bf{ mu} + frac{1}{2} bf{ mu}^{ mathrm{T}} bf{ Lambda}_{ mu} bf{m} + frac{1}{2} bf{m}^{ mathrm{T}} bf{ Lambda}_{ mu} bf{ mu} + const. end{eqnarray} $$ ここで、$ bf{x}_n^{ mathrm{T}} bf{ Lambda} bf{ mu}$は行数と列数について(1×D)×(D×D)×(D×1)=(1×1)よりスカラーなので次が成り立つ。 . $$ begin{eqnarray} bf{x}_n^{ mathrm{T}} bf{ Lambda} bf{ mu} &amp;=&amp; ( bf{x}_n^{ mathrm{T}} bf{ Lambda} bf{ mu})^{ mathrm{T}}　(スカラーを転置しても同じ) &amp;=&amp; bf{ mu}^{ mathrm{T}} bf{ Lambda}^{ mathrm{T}} bf{x}_n　(これは公式通り) &amp;=&amp; bf{ mu}^{ mathrm{T}} bf{ Lambda} bf{x}_n　( bf{ Lambda}は対称行列) end{eqnarray} $$$ bf{m}^{ mathrm{T}} bf{ Lambda}_{ mu} bf{ mu}$についても同様であり、 . $$ begin{eqnarray} ln p( bf{ mu}| bf{X}) &amp;=&amp; frac{1}{2} Sigma_{n=1}^{N} { bf{x}_n^{ mathrm{T}} bf{ Lambda} bf{ mu} } + frac{1}{2} bf{ mu}^{ mathrm{T}} bf{ Lambda} Sigma_{n=1}^{N} bf{x}_n - frac{N}{2} bf{ mu}^{ mathrm{T}} bf{ Lambda} bf{ mu} - frac{1}{2} bf{ mu}^{ mathrm{T}} bf{ Lambda}_{ mu} bf{ mu} + frac{1}{2} bf{ mu}^{ mathrm{T}} bf{ Lambda}_{ mu} bf{m} + frac{1}{2} bf{m}^{ mathrm{T}} bf{ Lambda}_{ mu} bf{ mu} + const. &amp;=&amp; frac{1}{2} bf{ mu}^{ mathrm{T}} bf{ Lambda} Sigma_{n=1}^{N} bf{x}_n + frac{1}{2} bf{ mu}^{ mathrm{T}} bf{ Lambda} Sigma_{n=1}^{N} bf{x}_n - frac{N}{2} bf{ mu}^{ mathrm{T}} bf{ Lambda} bf{ mu} - frac{1}{2} bf{ mu}^{ mathrm{T}} bf{ Lambda}_{ mu} bf{ mu} + frac{1}{2} bf{ mu}^{ mathrm{T}} bf{ Lambda}_{ mu} bf{m} + + frac{1}{2} bf{ mu}^{ mathrm{T}} bf{ Lambda}_{ mu} bf{m} + const. &amp;=&amp; - frac{1}{2} { bf{ mu}^{ mathrm{T}} (N bf{ Lambda}+ bf{ Lambda}_{ mu}) bf{ mu} - 2 bf{ mu}^{ mathrm{T}}( bf{ Lambda} Sigma_{n=1}^{N} bf{x}_n + bf{ Lambda}_{ mu} bf{m}) } + const. end{eqnarray} $$$ bf{ mu}$に関する上に凸の二次関数となり、ガウス分布であることがわかる。1次元と同様に逆算的に計算していく。 . $$p( bf{ mu}| bf{X}) = mathcal{N}( bf{ mu}| hat{ bf{m}}, hat{ bf{ Lambda}}_{ bf{ mu}}^{-1})$$ . とおき、対数をとって$ bf{ mu}$について整理すると . $$ begin{eqnarray} ln p( bf{ mu}| bf{X}) &amp;=&amp; - frac{1}{2} {( bf{ mu}- hat{ bf{m}})^ mathrm{T} hat{ bf{ Lambda}}_{ bf{ mu}} ( bf{ mu}- hat{ bf{m}}) } + const. &amp;=&amp; - frac{1}{2} { bf{ mu}^{ mathrm{T}} hat{ bf{ Lambda}}_{ bf{ mu}} bf{ mu} - hat{ bf{m}}^{ mathrm{T}} hat{ bf{ Lambda}}_{ bf{ mu}} bf{ mu} - bf{ mu}^{ mathrm{T}} hat{ bf{ Lambda}}_{ bf{ mu}} hat{ bf{m}} } + const. &amp;=&amp; - frac{1}{2} { bf{ mu}^{ mathrm{T}} hat{ bf{ Lambda}}_{ bf{ mu}} bf{ mu}-2 bf{ mu}^{ mathrm{T}} hat{ bf{ Lambda}}_{ bf{ mu}} hat{ bf{m}} } + const. end{eqnarray} $$対応関係を見れば . $$ begin{eqnarray} hat{ bf{ Lambda}}_{ bf{ mu}} = N bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}} hat{ bf{m}} = hat{ bf{ Lambda}}_{ bf{ mu}}^{-1}( bf{ Lambda} Sigma_{n=1}^{N} bf{x}_n + bf{ Lambda}_{ mu} bf{m}) end{eqnarray} $$と事後分布のハイパーパラメータが求まる。 . &#20104;&#28204;&#20998;&#24067;&#12398;&#23566;&#20986; . 簡単のために学習前の事前分布を用いて予測分布を導出し、更新されたハイパーパラメータを代入することで学習後の予測分布を計算する。1次元の時と同様、ベイズの定理と対数化を利用し積分計算を避ける。 . $$ ln p( bf{x}_*) = ln p( bf{x}_*| bf{ mu}) - ln p( bf{ mu}| bf{x}_*) + const.$$ . $ ln p( bf{ mu}| bf{x}_*)$は$ bf{x}_*$を学習した後の事後分布と見なせるので、 . $$ begin{eqnarray} p( bf{ mu}| bf{x}_*) &amp;=&amp; mathcal{N}( bf{ mu}| bf{m}( bf{x}_*), ( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1}) ただし　 bf{m}( bf{x}_*) &amp;=&amp; ( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} ( bf{ Lambda} bf{x}_* + bf{ Lambda}_{ bf{ mu}} bf{m}) end{eqnarray} $$したがって、 . $$ begin{eqnarray} ln p( bf{x}_*) &amp;=&amp; ln p( bf{x}_*| bf{ mu}) - ln p( bf{ mu}| bf{x}_*) + const. &amp;=&amp; - frac{( bf{x}_*- bf{ mu})^ mathrm{T} bf{ Lambda}( bf{x}_*- bf{ mu})}{2} + frac{( bf{ mu}- bf{m}( bf{x}_*))^ mathrm{T}( bf{ Lambda}+ bf{ Lambda}_{ mu})( bf{ mu}- bf{m}( bf{x}_*))}{2} + const. &amp;=&amp; - frac{1}{2} { bf{x}_*^{ mathrm{T}} bf{ Lambda} bf{x}_* - bf{x}_*^{ mathrm{T}} bf{ Lambda} bf{ mu} - bf{ mu}^ mathrm{T} bf{ Lambda} bf{x}_* - bf{m}( bf{x}_*)^ mathrm{T} ( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}}) bf{m}( bf{x}_*) + bf{m}( bf{x}_*)^ mathrm{T}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}}) bf{ mu} + bf{ mu}^ mathrm{T}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}}) bf{m}( bf{x}_*) } + const. &amp;=&amp; - frac{1}{2} { bf{x}_*^{ mathrm{T}} bf{ Lambda} bf{x}_* - 2 bf{x}_*^{ mathrm{T}} bf{ Lambda} bf{ mu} - bf{m}( bf{x}_*)^ mathrm{T} ( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}}) bf{m}( bf{x}_*) + 2 bf{ mu}^ mathrm{T}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}}) bf{m}( bf{x}_*) } + const. &amp;=&amp; - frac{1}{2} { bf{x}_*^{ mathrm{T}} bf{ Lambda} bf{x}_* - 2 bf{x}_*^{ mathrm{T}} bf{ Lambda} bf{ mu} - bf{m}( bf{x}_*)^ mathrm{T} ( bf{ Lambda} bf{x}_* + bf{ Lambda}_{ bf{ mu}} bf{m}) + 2 bf{ mu}^ mathrm{T} bf{ Lambda} bf{x}_* } + const. &amp;=&amp; - frac{1}{2} { bf{x}_*^{ mathrm{T}} bf{ Lambda} bf{x}_* - ( bf{ Lambda} bf{x}_* + bf{ Lambda}_{ bf{ mu}} bf{m})^ mathrm{T} bf{m}( bf{x}_*) } + const.　( bf{m}( bf{x}_*)^ mathrm{T} ( bf{ Lambda} bf{x}_* + bf{ Lambda}_{ bf{ mu}} bf{m})はスカラーなので転置しても変わらない) &amp;=&amp; - frac{1}{2} { bf{x}_*^{ mathrm{T}} bf{ Lambda} bf{x}_* - ( bf{ Lambda} bf{x}_* + bf{ Lambda}_{ bf{ mu}} bf{m})^ mathrm{T} ( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} ( bf{ Lambda} bf{x}_* + bf{ Lambda}_{ bf{ mu}} bf{m}) } + const. &amp;=&amp; - frac{1}{2} { bf{x}_*^{ mathrm{T}} bf{ Lambda} bf{x}_* - ( bf{ Lambda} bf{x}_*)^ mathrm{T}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} bf{ Lambda} bf{x}_* - ( bf{ Lambda} bf{x}_*)^ mathrm{T}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} bf{ Lambda}_{ bf{ mu}} bf{m} - ( bf{ Lambda}_{ bf{ mu}} bf{m})^ mathrm{T}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} bf{ Lambda} bf{x}_* } + const. &amp;=&amp; - frac{1}{2} { bf{x}_*^{ mathrm{T}} bf{ Lambda} bf{x}_* - bf{x}_*^ mathrm{T} bf{ Lambda}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} bf{ Lambda} bf{x}_* - 2 bf{x}_*^ mathrm{T} bf{ Lambda}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} bf{ Lambda}_{ bf{ mu}} bf{m} } + const. &amp;=&amp; - frac{1}{2} { bf{x}_*^{ mathrm{T}} ( bf{ Lambda}- bf{ Lambda}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} bf{ Lambda}) bf{x}_* - 2 bf{x}_*^ mathrm{T} bf{ Lambda}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} bf{ Lambda}_{ bf{ mu}} bf{m} } + const. end{eqnarray} $$ここで . $$ p( bf{x}_*) = mathcal{N}( bf{x}_*| bf{ mu}_*, bf{ Lambda}_*^{-1}) $$と書けるとすると . $$ ln p( bf{x}_*) = - frac{1}{2} { bf{x}_*^{ mathrm{T}} bf{ Lambda}_{*} bf{x}_* -2 bf{x}_*^{ mathrm{T}} bf{ Lambda}_{*} bf{ mu}_* } + const. $$であるから、対応関係から . $$ begin{eqnarray} bf{ Lambda}_* &amp;=&amp; bf{ Lambda}- bf{ Lambda}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} bf{ Lambda} bf{ mu}_* &amp;=&amp; bf{ Lambda}_*^{-1} bf{ Lambda}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} bf{ Lambda}_{ bf{ mu}} bf{m} end{eqnarray} $$ウッドベリーの公式を使うことで更に簡潔な形にできる。 . . Tip: ウッドベリーの公式 $$( bf{A}+ bf{U} bf{B} bf{V})^{-1} = bf{A}^{-1} - bf{A}^{-1} bf{U}( bf{B}^{-1}+ bf{V} bf{A}^{-1} bf{U})^{-1} bf{V} bf{A}^{-1}$$ . . Tip: ウッドベリーの公式($ bf{A}, bf{B}$の次元が等しく, $ bf{U}, bf{V}$が単位行列の場合) $$( bf{A}+ bf{B})^{-1} = bf{A}^{-1} - bf{A}^{-1}( bf{A}^{-1} + bf{B}^{-1})^{-1} bf{A}^{-1}$$ . $ bf{ Lambda}_*$について、$ bf{A}= bf{ Lambda}^{-1}, bf{B}= bf{ Lambda}_{ bf{ mu}}^{-1}$とおくと、 . $$ begin{eqnarray} bf{ Lambda}_* &amp;=&amp; bf{ Lambda}- bf{ Lambda}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} bf{ Lambda} &amp;=&amp; bf{A}^{-1} - bf{A}^{-1}( bf{A}^{-1} + bf{B}^{-1})^{-1} bf{A}^{-1} &amp;=&amp; ( bf{A}+ bf{B})^{-1} &amp;=&amp; ( bf{ Lambda}^{-1} + bf{ Lambda}_{ mu}^{-1})^{-1} end{eqnarray} $$$ bf{ mu}_*$は、$ bf{ Lambda}_* = bf{ Lambda}- bf{ Lambda}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} bf{ Lambda}$より . $$ begin{eqnarray} bf{ Lambda}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} bf{ Lambda} &amp;=&amp; bf{ Lambda} - bf{ Lambda}_* bf{ Lambda}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} &amp;=&amp; ( bf{ Lambda} - bf{ Lambda}_*) bf{ Lambda}^{-1} end{eqnarray} $$だから . $$ begin{eqnarray} bf{ mu}_* &amp;=&amp; bf{ Lambda}_*^{-1} bf{ Lambda}( bf{ Lambda}+ bf{ Lambda}_{ bf{ mu}})^{-1} bf{ Lambda}_{ bf{ mu}} bf{m} &amp;=&amp; bf{ Lambda}_*^{-1} ( bf{ Lambda} - bf{ Lambda}_*) bf{ Lambda}^{-1} bf{ Lambda}_{ bf{ mu}} bf{m} &amp;=&amp; { bf{ Lambda}_*^{-1} bf{ Lambda} bf{ Lambda}^{-1} bf{ Lambda}_{ bf{ mu}} - bf{ Lambda}_*^{-1} bf{ Lambda}_* bf{ Lambda}^{-1} bf{ Lambda}_{ bf{ mu}} } bf{m} &amp;=&amp; { bf{ Lambda}_*^{-1} bf{ Lambda}_{ bf{ mu}} - bf{ Lambda}^{-1} bf{ Lambda}_{ bf{ mu}} } bf{m} &amp;=&amp; { ( bf{ Lambda}^{-1} + bf{ Lambda}_{ mu}^{-1}) bf{ Lambda}_{ bf{ mu}} - bf{ Lambda}^{-1} bf{ Lambda}_{ bf{ mu}} } bf{m} &amp;=&amp; bf{I}_D bf{m} = bf{m} end{eqnarray} $$まとめると、 . $$ begin{eqnarray} bf{ Lambda}_* &amp;=&amp; ( bf{ Lambda}^{-1} + bf{ Lambda}_{ mu}^{-1})^{-1} bf{ mu}_* &amp;=&amp; bf{m} end{eqnarray} $$これらに、更新されたハイパーパラメータ$ hat{ bf{m}}, hat{ bf{ Lambda}}_{ bf{ mu}}$を代入して学習後の予測分布$p( bf{x}_*| bf{X})$が求まる。 . &#31934;&#24230;&#34892;&#21015;&#26410;&#30693; . 執筆中 . &#24179;&#22343;&#12539;&#31934;&#24230;&#34892;&#21015;&#26410;&#30693; . 執筆中 . 1. 須山敦志. ベイズ推論による機械学習入門. 講談社, 2017↩ .",
            "url": "https://vintea01.github.io/tpt-medical-it/bayes/2020/04/06/bayes-part4.ipynb.html",
            "relUrl": "/bayes/2020/04/06/bayes-part4.ipynb.html",
            "date": " • Apr 6, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Kaggle勉強会 Part 1 Metrics",
            "content": "参考図書 1 . &#22238;&#24112;&#21839;&#38988;&#65288;Regression&#65289;&#12395;&#20351;&#12431;&#12428;&#12427;&#35413;&#20385;&#25351;&#27161; . MSE, RMSE, R-squared | MAE | (R)MSPE, MAPE | (R)MSLE | . notation . $N$ : オブジェクト数 | $y in mathbb{R}^N$ : ターゲット値のN次元ベクトル | $ hat y in mathbb{R}^N$ : 予測値のN次元ベクトル | $y_i in mathbb{R}$ : オブジェクト$x_i$のターゲット値 | $ hat y_i in mathbb{R}$ : オブジェクト$x_i$の予測値 | . MSE, RMSE, R-squared . MSE: Mean Square Error . $$MSE(y, hat y)= frac{1}{N} sum^N_{i=1}(y_i- hat y_i)^2$$ . 評価指標の特性を考える際、一定の予測値$ hat y_i = alpha$がどの値をとる時に一番良い評価指標の値が得られるかを考えると良く、今回は . $$ min_{ alpha} f( alpha) = frac{1}{N} sum_{i=1}^N ( alpha - y_i)^2 $$のように$ alpha$に関して微分可能な関数$f( alpha)$の最小化問題に帰結できます。これを満たす$ alpha^*$の必要条件は . $$ frac{d f}{d alpha} bigg|_{ alpha= alpha^*} = 0 $$となります。よってこれを解くと、 $$ frac{d f}{d alpha} bigg|_{ alpha= alpha^*} = frac{2}{N} sum_{i=1}^N ( alpha^* - y_i) = 0 $$ . $$ frac{2}{N} sum_{i=1}^N alpha^* - frac{2}{N} sum_{i=1}^N y_i = 0 $$$$ alpha^* - frac{1}{N} sum_{i=1}^N y_i = 0 $$より、 $$ alpha^* = frac{1}{N} sum_{i=1}^N y_i(= bar y) $$ . $ alpha^*$における２次導関数 $ frac{d^2 f}{d alpha^2}$ は正なのでMSEにおけるbest constantは、ターゲット値の平均(target mean value)となります。 . RMSE: Root Mean Square Error . $$ RMSE= sqrt{MSE} $$$$ frac{ partial RMSE}{ partial hat y_i}= frac{1}{2 sqrt{MSE}} frac{ partial MSE}{ partial hat y_i} $$ R-squared . $$ R^2=1- frac{MSE}{ frac{1}{N} sum^N_{i=1}(y_i- bar y)^2} $$ &#26368;&#36969;&#21270;&#12398;&#20181;&#26041; . MSE・RMSE・R-squaredは基本的に同じ意味を持つ評価指標で、また最適化する際もそのまま目的関数として使用することができます。詳しくは各ライブラリのdocを読みましょう。 . MAE: Mean Absolute Error . $$ MAE(y, hat y) = frac{1}{N} sum_{i=1}^N | hat y_i - y_i| $$同様にbest constant $ alpha^*$を求めてみましょう。 $$ min_{ alpha} f( alpha) = frac{1}{N} sum_{i=1}^N | alpha - y_i| $$ . ここで $ frac{ partial |x|}{dx} = sign(x)$（$sign$ は 符号関数, signum functionを指す）であるので、 $$ frac{d f}{d alpha} bigg|_{ alpha= alpha^*} = frac{1}{N} sum_{i=1}^N sign( alpha^* - y_i) = 0 $$ . 定数項を無視すると、 $$ g( alpha^*) = sum_{i=1}^N sign( alpha^* - y_i) = 0 $$ をみたす $ alpha^*$ を求めればよいことが分かります。例えばここで、ターゲットのN次元ベクトルが$y=[-3,-1,-1.5,0,1,2,3]$とすると、$g( alpha)$のグラフは以下のようになります。 . #collapse-hide import numpy as np import matplotlib.pyplot as plt %matplotlib inline def sgn(x,y): if x &lt; y: return -1 elif x == y: return 0 else: return 1 def g(alpha,y): total = 0 for i in y: total += sgn(alpha,i) return total y = np.array([-3,-1,-1.5,0,1,2,3]) alpha = np.arange(y.min()-0.5,y.max()+0.5,0.01) median = np.median(y) gs_a = [] for a in alpha: gs_a.append(g(a,y)) gs_y = [] for yi in y: gs_y.append(g(yi,y)) plt.figure(figsize=(10,7)) plt.xlabel(&quot;α&quot;) plt.ylabel(&#39;g(α)&#39;) plt.xlim(alpha.min()-0.1,alpha.max()+0.1) plt.ylim(-len(y)-0.5,len(y)+0.5) plt.plot(alpha,gs_a,label=&#39;g(α)&#39;) plt.scatter(y,gs_y,label=&#39;g($y_i$)&#39;) plt.scatter(median,g(median,y),label=&#39;median&#39;) plt.legend(loc=&#39;upper left&#39;) plt.show() . . このように、値がN回不連続的に飛び飛びの値をとることがわかり、０になるには約$ frac{N}{2}$回飛ばなければならないことが分かります。グラフの様にその値はターゲットの中央値（target median）となることが分かります。Nが偶数奇数の場合分けが必要ですが、いずれの場合もbest constantはtarget medianとなります。 . . Note: MAEのbest constantはターゲットの中央値であることから、MAEはターゲットの外れ値（outliers）の影響を受けずらいことが分かる。一方MSEはoutliersの影響を受けやすい。よって、ターゲットにouteliersを含む場合はMAEがよりrobustな評価指標と言える。 . &#26368;&#36969;&#21270;&#12398;&#20181;&#26041; . MAEも目的関数として扱うことができますが、$ hat y_i=y_i$の時に微分可能でないのでsmoothingして0に近いエラーに関しても処理できるようにする必要があります。このsmoothingには様々な方法がありますが、有名なものにHuber lossがあります。0に近い時はMSE、エラーが大きい値ではMAEのような挙動を示す関数です。詳しくは各ライブラリのdocを読みましょう。 . (R)MSPE, MAPE: Percentage Error . 単純なMSEやMAEでは、ターゲットの値が大きい時に同じ精度の予測値に対して過小評価されてしまいます。例えば、 $$ MSE(10,9)=1 $$ $$ MSE(1000,900)=10000 $$ のように同じ90％の予測精度でもMSEの値が大きくなることが分かります。そこで、MSE・MAEそれぞれに対し、ターゲット値の逆数で重みを付けた評価指標がそれぞれMSPE・MAPEという訳です。 $$ MSPE(y, hat y)= frac{100 %}{N} sum^N_{i=1}( frac{y_i- hat y_i}{y_i})^2 $$ $$ MAPE(y, hat y)= frac{100 %}{N} sum^N_{i=1}| frac{y_i- hat y_i}{y_i}| $$ . それではそれぞれのbest constantはどの値をとるのでしょうか？ MSPE、MAPEそれぞれその値は重み付け平均値、重み付け中央値を取ります。小さい値のターゲットに重みを大きくつけた新しいターゲット値の平均、中央値という訳です。ターゲット値に$w_i= frac{1/y_i}{ sum^N_{i=1}1/y_i}$を付加した後、MSE・MAE同様の議論をすれば証明できます。 . &#26368;&#36969;&#21270;&#12398;&#20181;&#26041; . MSPE・MAPEを直接モデル最適化の目的関数として扱うことは難しく、以下のステップが必要となります。 . ターゲットの値を用いて各オブジェクト$x_i$に対してSample weights: $w_i$を対応させる | その重みに従って新たに元のデータからサンプリングを行う | サンプリングされた新たなデータセットに対して、MSE・MAEを適用する | $w_i$に関してはMSPE・MASEについてそれぞれ、 $$ MSPE: w_i= frac{1/y_i^2}{ sum^N_{i=1}1/y_i^2} $$ $$ MAPE: w_i= frac{1/y_i}{ sum^N_{i=1}1/y_i} $$ となります。 . . Note: $w_i$の合計は必ずしも１である必要はない。また、サンプル数はもとのデータセットのオブジェクト数Nを超えても良い。 . (R)MSLE: (Root) Mean Square Logarithmic Error . $$ RMSLE(y, hat y)= sqrt{ frac{1}{N} sum^N_{i=1}(log(y_i+1)-log( hat y_i+1))^2} =RMSE(log(y+1),log( hat y+1))= sqrt{MSE(log(y+1),log( hat y+1))} $$こちらもターゲットのスケールによる誤差の見積もり変化に対して、頑強な評価指標です。MSEの対数バージョンということですね。 . ではbest constantはどの値をとるかというとこの場合はlog spaceでのtarget meanです。log spaceでの平均が分かった後にその値を指数化して戻してあげる必要がありますがコンセプトはMSEと変わりません。 . &#26368;&#36969;&#21270;&#12398;&#20181;&#26041; . これも単純に目的関数としては使えないので以下のステップが必要です。 . ターゲット値をlog spaceに変換する; $z_i=log(y_i+1)$ | 変換された新しいターゲットに対して、目的関数をMSEに設定しモデルをfitする | 予測値を指数化し想定されるスケールに戻す; $ hat y_i=exp( hat z_i)-1$ | 詳しくは各ライブラリのdocを読みましょう。 . &#20998;&#39006;&#21839;&#38988;&#65288;Classification&#65289;&#12395;&#20351;&#12431;&#12428;&#12427;&#35413;&#20385;&#25351;&#27161; . Accuracy | Logarithmic Loss | Area under ROC curve | (Quadratic weighted) Kappa | . notation . $N$ : オブジェクト数 | $L$ : カテゴリ数 | $y$ : 真値 | $ hat y$ : 予測値 | $[a=b]$ : 1 if a=b else 0 | . Accuracy . $$ Accuracy= frac{1}{N} sum^N_{i=1}[ hat y_i=y_i] $$この指標はクラス予測がどのくらいの頻度で正しいか表しています。best constantは最も現れる頻度の高いカテゴリ値です。例えばターゲットに猫が10、犬が90あるとしたら、常にイッヌと予測したら0.9が得られ最大となります。 . &#26368;&#36969;&#21270;&#12398;&#20181;&#26041; . 何でもいいのである評価指標でモデルを最適化・fitする | 最適化済みのモデルの各カテゴリに対する確率予測値に対して、閾値を調節する | 閾値の最適解によってそのモデルの実力を最も発揮したAccuracyが求められます。 詳しくは各ライブラリのdocを読みましょう。 . Logarithmic Loss . Binary $$ LogLoss=- frac{1}{N} sum^N_{i=1}y_ilog( hat y_i)+(1-y_i)log(1- hat y_i) $$ Multiclass $$ LogLoss=- frac{1}{N} sum^N_{i=1} sum^L_{l=1}y_{il}log( hat y_{il}) $$ . 2値分類と多クラス分類のタスクで上のように書き分けられますが、多クラス分類の方は一般化されている形になっています。実践的には$log$の中身$x$に対して$10^{-15} leqq x leqq 1-10^{-15}$のようにクリッピングした関数 $$ LogLoss=- frac{1}{N} sum^N_{i=1} sum^L_{l=1}y_{il}log(min(max( hat y_{il},10^{-15}),1-10^{-15})) $$ . が使われます。下のグラフはターゲットが０の時の予測確率値とLogLossを示していますが、誤ったクラスの予測確率値が大きいほど、つまり間違った答えをはっきりこれだと言ってしまうほど大きいペナルティが課せられることが分かります。 . #collapse-hide y_pred = np.arange(0,1,0.01) def logloss(y_pred): return -np.log(1-y_pred) plt.figure(figsize=(10,7)) plt.xlabel(&quot;$ hat y$&quot;) plt.ylabel(&#39;Loss&#39;) plt.xlim(-0.01,1.01) plt.ylim(-0.1,6) plt.plot(y_pred,logloss(y_pred),label=&#39;LogLoss&#39;) plt.legend(loc=&#39;upper left&#39;) plt.show() . . best constantは各カテゴリの頻度値となります。猫1割、犬9割だったら猫0.1、犬0.9と常に予測するときに最小のLossが得られます。 . &#26368;&#36969;&#21270;&#12398;&#20181;&#26041; . これは目的関数として設定できます。そのまま使いましょう。詳しくは各ライブラリのdocを読みましょう。 . Area under ROC curve . 2値分類においてモデルのNegativeの予測確率値を小さい順に並び替えた時に、ある値より前の対応するターゲットが全てPositive、後は全てNegativeになる場合、閾値を適切に設定すればAccuracy100％の完全なモデルであることが分かります。つまりある閾値を境に綺麗にpositiveからnegativeを予測できていることが理想です。しかし、現実は予測確率をsortした時に対応するターゲットは綺麗に並んでくれはしません。本来positiveの所にnegativeが来てしまうことがあるのです。このようにどれくらい綺麗な並びでpositiveとnegativeを分けられているかを示すのがこの評価指標です。詳しいアルゴリズムは以下の動画が分かりやすく説明しているので参考にして下さい。 . それではbest constantはどの値をとるのでしょうか。この評価指標のアルゴリズムから分かるように、予測確率の大きさの順番しかこのスコアに影響しないので、どの値でも$AUC=0.5$と同じスコアになります。 . Note: ランダムに予測した場合予測確率の大小順はばらばらになるので$AUC=0.5$となり、最低値となる。 . &#26368;&#36969;&#21270;&#12398;&#20181;&#26041; . これを目的関数として設定できるモデルライブラリがあるのでその場合はそのまま使いましょう。そうでない場合はLogLossを最適化することで代用できます。詳しくは各ライブラリのdocを読みましょう。 . Kappa . Cohen&#39;s Kappa . お馴染みの例、猫10、犬90の場合、すべて犬と予想するだけで$Accuracy=0.9$となりますが、このようにモデルには最低限これはいけるっしょ的な精度、つまりBaseline Accuracyなるものが存在します。この値でAccuracyをscalingしたものがKappaという指標です。 . 詳しいアルゴリズムについて説明します。 例えば猫20、犬80と結果的に予測したとするとこの予測値をオブジェクトごとに適当に並び変えても最低限、$0.2*0.1+0.8*0.9=0.74$のAccuracyが得られます。このようにBaseline Accuracyは以下の様に定義できます。 $$ p_e= frac{1}{N^2} sum_kn_{k1}n_{k2} $$ ここで$k$は予測したカテゴリ値、$n_{k1}$、$n_{k2}$はそれぞれカテゴリkの予測した数、ターゲット内の数を示します。 そしてKappaは $$ Cohen&#39;s Kappa=1- frac{1-accuracy}{1-p_e} $$ または $$ Cohen&#39;s Kappa=1- frac{error}{baseline error} $$ と表されます。 . Weighted Kappa . この$error$と$baseline error$に関して与えられた重みでscalingしたものがこの指標です。例えば猫を犬と間違えたらそれは万死に値すると考える人によって、予測値犬、ターゲット猫に対応する重みは100000と設定されるとそこのペナルティが大きくなるのは明白ですね。この重み付けの種類によって以下のように名前が変わります。 . Linear weights $$ w_{ij}=|i-j| $$ Quadratic weights $$ w_{ij}=(i-j)^2 $$ ここでi、jはそれぞれターゲット、予測のクラス値です。比較的データサイエンスコンペティションで使われる指標であるQuadratic Weighted Kappaは予測値とターゲットの距離をerrorと捉えたMSEのような側面も持ち合わせていることが分かります。 . &#26368;&#36969;&#21270;&#12398;&#20181;&#26041;&#65288;Quadratic Weighted Kappa&#65289; . 目的関数そのままで扱うことは難しいため、以下のステップが必要となります。 . MSEを評価指標に設定しモデルを最適化 | Accuracyが最大となるように閾値を調節 | または、 . 微分可能な近似関数を設計 | GBDT（Gradient Boosting Decision Tree）やNeural net系のモデルに設計した関数を目的関数として設定し最適化 | 前者の方が行いやすいです。また、後者の近似関数の参考として以下の論文があります。 詳しくは各ライブラリのdocを読みましょう。 . &#26368;&#24460;&#12395; . 結構盛沢山の評価指標ですが、基本的にKaggleではコンペティションの指定した評価指標について最良のスコアを目指すだけです。しかし、現実社会の問題を考える時に、データや問題の特性に対応した最適な評価指標があります。自分で評価指標を決定しその指標に対してモデルを最適化するデータサイエンスの基本を知ることは広く役に立つと考えます。 . 1. 『How to Win a Data Science Competition: Learn from Top Kagglers』(National Research University Higher School of Economics, week3)↩ .",
            "url": "https://vintea01.github.io/tpt-medical-it/kaggle/2020/04/05/_03_31_Kaggle_Part1.html",
            "relUrl": "/kaggle/2020/04/05/_03_31_Kaggle_Part1.html",
            "date": " • Apr 5, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "ベイズ勉強会 Part 3 1次元ガウス分布のベイズ推論",
            "content": "ベイズ勉強会資料は『ベイズ推論による機械学習入門』1を元に、途中式計算をできるだけ省略せずに行ったものです。 . 1&#27425;&#20803;&#12460;&#12454;&#12473;&#20998;&#24067; . 1次元のガウス分布(以下本ページでは単に「ガウス分布」と呼ぶ)は、次の確率密度関数で表される$x in mathbb{R}$を生成する確率分布である。 . . Important: 1次元ガウス分布の確率密度関数$$ mathcal{N}(x| mu, sigma^2) = frac{1}{ sqrt{2 pi sigma^2}} exp {- frac{(x- mu)^2}{2 sigma^2} }$$ . パラメータは$ mu in mathbb{R}, sigma^2 in mathbb{R^+}$の2つで、それぞれ平均と分散である。精度パラメータ$ lambda = sigma^{-2}$を用いて書くこともある。精度で書くと以下のようになる。 . . Important: 精度で表した1次元ガウス分布の確率密度関数$$ mathcal{N}(x| mu, lambda^{-1}) = frac{1}{ sqrt{2 pi}} lambda^{ frac{1}{2}}exp {- frac{1}{2}(x- mu)^2 lambda }$$ . 以下、観測されたデータ$ mathcal{D}= {x_1, dots,x_N }$の各点$x_n$と未知の観測$x_*$は同じ1次元ガウス分布から独立に生成されたと仮定してベイズ推論を行う。 . &#24179;&#22343;&#12364;&#26410;&#30693;&#12289;&#31934;&#24230;&#12364;&#26082;&#30693;&#12398;&#22580;&#21512; . ガウス分布の2つのパラメータのうち、精度パラメータ$ lambda$が既知である状況でベイズ推論を行う。 . &#12514;&#12487;&#12523;&#12398;&#27083;&#31689; . 平均$ mu$だけが未知という条件で、尤度関数をガウス分布にした場合、そのパラメータ$ mu$の事前分布はどうすればよいだろうか。$ mu$の条件は$ mu in mathbb{R}$であることのみであり、実数を1つ出力する分布を事前分布とすればベイズ推論ができそうだ。このような分布は様々だが、1次元ガウス分布を用いることで事後分布も1次元ガウス分布となることが知られている。つまり尤度関数が1次元ガウス分布の場合の共役事前分布は1次元ガウス分布である。これを用いて同時分布を構築すると以下のようになる。 . $$ begin{eqnarray} p( mathcal{D},x_*, mu) &amp;=&amp; p( mathcal{D}| mu)p(x_*| mu)p( mu) p( mathcal{D}| mu) &amp;=&amp; Pi_{n=1}^{N} mathcal{N}(x_n| mu, lambda^{-1}) p(x_*| mu) &amp;=&amp; mathcal{N}(x_*| mu, lambda^{-1}) p( mu) &amp;=&amp; mathcal{N}( mu|m, lambda_{ mu}^{-1}) end{eqnarray} $$$p( mu)$の$m in mathbb{R}, lambda_{ mu} in mathbb{R^+}$は固定されたハイパーパラメータである。 . &#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . 事後分布$p( mu| mathcal{D})$を求める。ベイズの定理から次のように書ける。分母は形状には関わらないので省く。 . $$ begin{eqnarray} p( mu| mathcal{D}) &amp; propto&amp; p( mathcal{D}| mu) p( mu) &amp;=&amp; { Pi_{n=1}^{N} p(x_n| mu) }p( mu) &amp;=&amp; { Pi_{n=1}^{N} mathcal{N}(x_n| mu, lambda^{-1}) } mathcal{N}( mu|m, lambda_{ mu}^{-1}) end{eqnarray} $$対数をとると、 . $$ begin{eqnarray} p( mu| mathcal{D}) &amp;=&amp; Sigma_{n=1}^{N} ln mathcal{N}(x_n| mu, lambda^{-1}) + ln mathcal{N}( mu|m, lambda_{ mu}^{-1}) + const. &amp;=&amp; Sigma_{n=1}^{N} {- frac{1}{2}(x_n- mu)^2 lambda } + {- frac{1}{2}( mu-m)^2 lambda_{ mu} } + const. &amp;=&amp; - frac{1}{2} left[ Sigma_{n=1}^{N} {(x_n^2 -2x_n mu + mu^2) lambda } + ( mu^2 - 2 mu m + m^2) lambda_{ mu} right] + const. &amp;=&amp; - frac{1}{2} {(N lambda + lambda_{ mu}) mu^2 - 2( Sigma_{n=1}^{N} x_n lambda + m lambda_{ mu}) mu } + const. end{eqnarray} $$最後の変形では$ mu$に関わらない値は$const.$に吸収させている。これを平方完成するとガウス分布の形になっていることがわかるがここでは結果から逆算的に求める。事後分布が次のようなガウス分布で書けるとする。 . $$ p( mu| mathcal{D}) = mathcal{N}( mu| hat{m}, hat{ lambda_{ mu}}^{-1}) $$対数をとると . $$ begin{eqnarray} ln p( mu| mathcal{D}) &amp;=&amp; - frac{1}{2}( mu- hat{m})^2 hat{ lambda_{ mu}} &amp;=&amp; - frac{1}{2} { hat{ lambda_{ mu}} mu^2 - 2 hat{m} hat{ lambda_{ mu}} mu } + const. end{eqnarray} $$となるので、事後分布のパラメータ$ hat{m}, hat{ lambda_{ mu}}$は次のように求まる。 . $$ begin{eqnarray} hat{ lambda_{ mu}} &amp;=&amp; N lambda + lambda_{ mu} hat{m} &amp;=&amp; frac{ lambda Sigma_{n=1}^{N} x_n + lambda_{ mu}m}{ hat{ lambda_{ mu}}} end{eqnarray} $$以上で事後分布の推論が完了した。 . . Note: 更新された精度パラメータは、ハイパーパラメータに$N lambda$だけ加えたものでありデータ数$N$が大きくなる程精度が上がる、すなわち事後分布のばらつきが小さくなりかつハイパーパラメータの影響が小さくなることを示している。平均パラメータはハイパーパラメータ$m$と$ Sigma{n=1}^{N}x_n$の重み付き和の形になっておりこれもデータ数が増えるほどハイパーパラメータの影響を受けにくくなることがわかる。 . &#20104;&#28204;&#20998;&#24067;&#12398;&#31639;&#20986; . モデル全体の事後分布をパラメータ$ mu$で周辺化することで未知の観測$x_*$に対する予測分布が得られる。ハット記号を付けるのが面倒なので、学習していない事前分布から予測分布を算出し、後で更新されたパラメータを代入してみることにする。 . $$ begin{eqnarray} p(x_*) &amp;=&amp; int p(x_*| mu) p( mu) d mu &amp;=&amp; int mathcal{N}(x_*| mu, lambda^{-1}) mathcal{N}( mu|m, lambda_{ mu}^{-1}) d mu end{eqnarray} $$これを直接計算するのは大変なので、ベイズの定理と対数をうまく使ってみる。ベイズの定理から、 . $$ p( mu|x_*) = frac{p(x_*| mu)p( mu)}{p(x_*)} $$$p(x_*)$を左辺に置いて対数をとると、 . $$ ln p(x_*) = ln p(x_*| mu) - ln p( mu|x_*) + const. $$$ ln p( mu)$は$x_*$には関係ないので$const.$とした。$p( mu|x_*)$は$p( mu| mathcal{D})$に$ mathcal{D}=x_*$とすれば求まる。 . $$ begin{eqnarray} p( mu|x_*) &amp;=&amp; mathcal{N}( mu|m(x_*), ( lambda + lambda_{ mu})^{-1}) ただし　m(x_*) &amp;=&amp; frac{ lambda x_* + lambda_{ mu}m}{ lambda + lambda_{ mu}} end{eqnarray} $$これと$p(x_*| mu) = mathcal{N}( mu, lambda^{-1})$を代入すると . $$ begin{eqnarray} ln p(x_*) &amp;=&amp; ln p(x_*| mu) - ln p( mu|x_*) + const. &amp;=&amp; - frac{1}{2} { lambda (x_* - mu)^2 - ( lambda + lambda_{ mu})( mu - m(x_*))^2 } + const. &amp;=&amp; - frac{1}{2} { lambda x_*^2 - 2 lambda mu x_* - frac{ lambda^2 x_*^2 + 2 lambda lambda_{ mu} m x_*}{ lambda + lambda_{ mu}} + 2 lambda mu x_* } + const. &amp;=&amp; - frac{1}{2} { frac{ lambda^2 x_*^2 + lambda lambda_{ mu} x_*^2 - lambda^2 x_*^2 - 2 lambda lambda_{ mu} m x_*}{ lambda + lambda_{ mu}} } + const. &amp;=&amp; - frac{1}{2} { frac{ lambda lambda_{ mu}}{ lambda + lambda_{ mu}} x_*^2 - frac{2m lambda lambda_{ mu}}{ lambda + lambda_{ mu}} x_* } + const. end{eqnarray} $$$x_*$の2次関数の形にできたので事後分布と同じく逆算的に計算すると、予測分布$p(x_*)$は . $$ begin{eqnarray} p(x_*) &amp;=&amp; mathcal{N} (x_* | mu_*, lambda_{*}^{-1}) ただし　 lambda_* &amp;=&amp; frac{ lambda lambda_{ mu}}{ lambda + lambda_{ mu}} mu_* &amp;=&amp; m end{eqnarray} $$となる。これに$ hat{m}, hat{ lambda_{ mu}}$を代入することで学習した後の予測分布$p(x_*| mathcal{D})$は . $$ begin{eqnarray} p(x_*) &amp;=&amp; mathcal{N} (x_* | mu_*, lambda_{*}^{-1}) ただし　 lambda_* &amp;=&amp; frac{ lambda (N lambda + lambda_{ mu})}{ lambda + (N lambda + lambda_{ mu})} mu_* &amp;=&amp; frac{ lambda Sigma_{n=1}^{N} x_n + lambda_{ mu}m}{N lambda + lambda_{ mu}} end{eqnarray} $$と求まる。 . . Note: 精度から見た結果の意味 . 精度について逆数をとると意味がわかりやすい。 . $$ lambda_*^{-1} = lambda^{-1} + hat{ lambda_{ mu}}^{-1}$$精度の逆数は分散なので、この式は「予測分布の分散は観測分布の分散と事後分布の分散の和である」という意味になる。 . 今回は観測分布の分散が実際の分散に等しいことを仮定しているので、データ数が増え事後分布の分散が小さくなれば予測分布は実際の分布の分散とほぼ一致する。 . &#24179;&#22343;&#12364;&#26082;&#30693;&#12289;&#31934;&#24230;&#12364;&#26410;&#30693;&#12398;&#22580;&#21512; . 今度は、平均パラメータ$ mu$が既知で、精度パラメータ$ lambda$が未知の場合でベイズ推論を行う。 . &#12514;&#12487;&#12523;&#12398;&#27083;&#31689; . 精度パラメータ$ lambda$は正の実数である必要がある。正の実数を出力する確率分布にはガンマ分布があり、平均既知精度未知の場合の1次元ガウス分布の共役事前分布として知られている。事前分布にガンマ分布を採用すると次のようにモデル構築することになる。 . $$ begin{eqnarray} p( mathcal{D},x_*, lambda) &amp;=&amp; p( mathcal{D}| lambda)p(x_*| lambda)p( lambda) p( mathcal{D}| lambda) &amp;=&amp; Pi_{n=1}^{N} mathcal{N}(x_n| mu, lambda^{-1}) p(x_*| lambda) &amp;=&amp; mathcal{N}(x_*| mu, lambda^{-1}) p( lambda) &amp;=&amp; Gam( lambda|a, b) end{eqnarray} $$このモデルのハイパーパラメータは$a,b$である。$ mu$は既知の値という設定だが、$ mu$をハイパーパラメータとして推論していると考えることもできる。 . . Important: ガンマ分布 . ガンマ分布は$a, b in mathbb{R^+}$をパラメータに持ち、正の実数を生成する確率分布である。ガンマ分布の確率密度関数は次の通り。 . $$Gam( lambda|a,b) = C_G(a,b) lambda^{a-1}e^{-b lambda}$$$C_G(a,b)$は正規化係数であり、 . $$C_G(a,b) = frac{b^a}{ Gamma(a)}$$ &#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . 事後分布$p( lambda| mathcal{D})$を推論する。ベイズの定理から . $$ begin{eqnarray} p( lambda| mathcal{D}) &amp; propto&amp; p( mathcal{D}| lambda)p( lambda) &amp;=&amp; { Pi_{n=1}^{N} p(x_n| lambda) } p( lambda) &amp;=&amp; { Pi_{n=1}^{N} mathcal{N}(x_n| mu, lambda^{-1}) } Gam( lambda|a,b) end{eqnarray} $$対数をとる。 . $$ begin{eqnarray} ln p( lambda| mathcal{D}) &amp;=&amp; Sigma_{n=1}^{N} ln mathcal{N}(x_n| mu, lambda^{-1}) + ln Gam( lambda|a,b) + const. &amp;=&amp; Sigma_{n=1}^{N} { frac{1}{2} ln lambda - frac{(x_n- mu)^2 lambda}{2} } + (a-1) ln lambda -b lambda + const. &amp;=&amp; ( frac{N}{2}+a-1) ln lambda - { frac{1}{2} Sigma_{n=1}^{N}(x_n- mu)^2 + b } lambda + const. end{eqnarray} $$対数を戻せばこれはガンマ分布となることがわかる。 . $$ begin{eqnarray} p( lambda| mathcal{D}) &amp;=&amp; Gam( lambda| hat{a}, hat{b}) ただし　 hat{a} &amp;=&amp; frac{N}{2} + a hat{b} &amp;=&amp; frac{1}{2} Sigma_{n=1}^{N} (x_n- mu)^2 + b end{eqnarray} $$&#20104;&#28204;&#20998;&#24067;&#12398;&#31639;&#20986; . 事後分布の形状が事前分布と同じなので、学習前の予測分布$p(x_*)$を計算すれば、学習後の$ hat{a}, hat{b}$を代入するだけで$p(x_*| mathcal{D})$がわかる。 . $$ p(x_*) = int p(x_*| lambda)p( lambda) d lambda $$を直接計算せずにベイズの定理と対数計算で簡単に計算してみる。 . $$ p( lambda|x_*) = frac{p(x_*| lambda)p( lambda)}{p(x_*)} $$対数をとり、$p( lambda)$を定数にまとめれば . $$ ln p(x_*) = ln p(x_*| lambda) - ln p( lambda|x_*) + const. $$$ ln p( lambda|x_*)$は事後分布の形に合わせれば . $$ begin{eqnarray} p( lambda|x_*) &amp;=&amp; Gam( lambda| frac{1}{2}+a,b(x_*)) ただし　b(x_*) &amp;=&amp; frac{1}{2}(x_*- mu)^2 + b end{eqnarray} $$と書ける。これを代入して . $$ begin{eqnarray} ln p(x_*) &amp;=&amp; ln mathcal{N}(x_*| mu, lambda^{-1}) - ln Gam( lambda| frac{1}{2}+a,b(x_*)) + cosnt. &amp;=&amp; frac{1}{2} ln lambda - frac{(x_*- mu)^2 lambda}{2} - (a- frac{1}{2}) ln lambda + { frac{1}{2}(x_*- mu)^2 + b } lambda - ln C_G(a+ frac{1}{2}, frac{1}{2}(x_*- mu)^2 + b) + const. &amp;=&amp; - (a+ frac{1}{2}) ln { frac{1}{2}(x_*- mu)^2 + b } + Gamma(a+ frac{1}{2}) + const. &amp;=&amp; - frac{2a+1}{2} ln { 1 + frac{1}{2b}(x_*- mu)^2 } + const. end{eqnarray} $$となる。途中、$x_*$を含まない項は$const.$に吸収させている。また、$ lambda$に関わる項は消えている。この結果は1次元のStudentのt分布に対数をとったものと同じ形になっている。 . . Important: 1次元のStudentのt分布 . 1次元のStudentのt分布は次の確率密度関数で表される。 . $$St(x| mu_s, lambda_s, nu_s) = frac{ Gamma( frac{ nu_s + 1}{2})}{ Gamma( frac{ nu_s}{2})}( frac{ lambda_s}{ pi nu_s})^{ frac{1}{2}} { 1 + frac{ lambda_s}{ nu_s} (x- mu_s)^2 }^{- frac{ nu_s+1}{2}}$$対数をとり$x$に関わらない部分をconst.にまとめると . $$ ln St(x| mu_s, lambda_s, nu_s) = - frac{ nu_s+1}{2} ln { 1 + frac{ lambda_s}{ nu_s} (x- mu_s)^2 } + const.$$ 対数t分布との対応を見れば、予測分布は次のように書けることがわかる。 . $$ begin{eqnarray} p(x_*) &amp;=&amp; St(x_*| mu_s, lambda_s, nu_s) ただし　 mu_s &amp;=&amp; mu lambda_s &amp;=&amp; frac{a}{b} nu_s &amp;=&amp; 2a end{eqnarray} $$学習により更新された$ hat{a}, hat{b}$を代入すると次のようになる。 . $$ begin{eqnarray} p(x_*| mathcal{D}) &amp;=&amp; St(x_*| mu_s, lambda_s, nu_s) ただし　 mu_s &amp;=&amp; mu lambda_s &amp;=&amp; frac{N+2a}{ Sigma_{n=1}^{N} (x_n- mu)^2 + 2b} nu_s &amp;=&amp; N + 2a end{eqnarray} $$ &#24179;&#22343;&#12392;&#31934;&#24230;&#12364;&#12392;&#12418;&#12395;&#26410;&#30693;&#12398;&#22580;&#21512; . 次に、平均と精度がともに未知の場合のベイズ推論を実践してみる。モデルのパラメータが2個になっても、やることは変わらない。 . &#12514;&#12487;&#12523;&#12398;&#27083;&#31689; . 平均についてガウス事前分布を、精度についてガンマ事前分布をそれぞれ設定し次のような同時分布を作ることも可能である(尤度関数は前と同じなので省略)。 . $$ begin{eqnarray} p( mathcal{D},x_*, mu, lambda) &amp;=&amp; p( mathcal{D}| mu, lambda^{-1})p(x_*| mu, lambda^{-1})p( mu)p( lambda) p( mu) &amp;=&amp; mathcal{N}( mu|m, lambda_{ mu}^{-1}) p( lambda) &amp;=&amp; Gam( lambda|a,b) end{eqnarray} $$が、実はガウス・ガンマ分布という事前分布を用いると事後分布もガウス・ガンマ分布となることが知られている。ここではガウス・ガンマ分布を用いる。 . . Important: ガウス・ガンマ分布 . ガウス・ガンマ分布は$m, beta, a, b$をパラメータに持ち、$ mu, lambda$という2つの確率変数を生成する確率分布である。確率密度関数は次のように書ける。 . $$ begin{eqnarray} p( mu, lambda) &amp;=&amp; NG( mu, lambda|m, beta,a,b) &amp;=&amp; mathcal{N}( mu|m,( beta lambda)^{-1})Gam( lambda|a,b) end{eqnarray} $$ . ガウス事前分布・ガンマ事前分布を別々に設定する場合との違いは$ mu$が$ lambda$に条件づけられていることである。グラフィカルモデルで示すと次のようになる。 . . . ガウス・ガンマ分布を使った場合モデルは次のようになる(尤度関数は省略)。 . $$ begin{eqnarray} p( mathcal{D},x_*, mu, lambda) &amp;=&amp; p( mathcal{D}| mu, lambda^{-1})p(x_*| mu, lambda^{-1})p( mu, lambda) p( mu, lambda) &amp;=&amp; NG( mu, lambda|m, beta,a,b) end{eqnarray} $$&#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . $ mu$が$ lambda$に条件づけられているので、同時分布$p( mathcal{D}, mu, lambda)$は次のように変形できる。 . $$ p( mathcal{D}, mu, lambda) = p( mu| lambda, mathcal{D})p( lambda| mathcal{D})p( mathcal{D}) $$未観測の変数の事後分布は同時分布を観測された変数の確率で割ることで求まるのでこの場合の事後分布は、 . $$ frac{p( mathcal{D}, mu, lambda)}{p( mathcal{D})} = p( mu| lambda, mathcal{D})p( lambda| mathcal{D}) $$より、$p( mu| lambda, mathcal{D})p( lambda| mathcal{D})$のことを指す。 . &#24179;&#22343;&#12395;&#27880;&#30446; . まず平均にのみ注目し$p( mu| lambda, mathcal{D})$について考える。平均未知精度既知の場合の事後分布の結果に対し$ lambda$を$ beta lambda$に置き換えれば、 . $$ begin{eqnarray} p( mu| lambda, mathcal{D}) &amp;=&amp; mathcal{N}( mu| hat{m},( hat{ beta} lambda)^{-1}) ただし　 hat{ beta} &amp;=&amp; N + beta hat{m} &amp;=&amp; frac{1}{ hat{ beta}}( Sigma_{n=1}^{N} x_n + beta m) end{eqnarray} $$ . Note: 置き換えによって$ lambda_{ mu}= beta lambda$となっていることを利用した。 . &#31934;&#24230;&#12395;&#27880;&#30446; . 次に精度に関わる部分$p( lambda| mathcal{D})$を求める。同時分布から、 . $$ begin{eqnarray} p( lambda| mathcal{D}) &amp;=&amp; frac{p( mathcal{D}, mu, lambda)}{p( mu| lambda, mathcal{D})p( mathcal{D})} &amp; propto&amp; frac{p( mathcal{D}, mu, lambda)}{p( mu| lambda, mathcal{D})} &amp;=&amp; frac{p( mathcal{D}| mu, lambda)p( mu, lambda)}{p( mu| lambda, mathcal{D})} &amp;=&amp; frac{ { Pi_{n=1}^{N} mathcal{N}(x_n| mu, lambda^{-1}) } mathcal{N}( mu|m,( beta lambda)^{-1})Gam( lambda|a,b)}{ mathcal{N}( mu| hat{m},( hat{ beta} lambda)^{-1})} end{eqnarray} $$対数をとって整理していく。 . $$ begin{eqnarray} ln p( lambda| mathcal{D}) &amp;=&amp; Sigma_{n=1}^{N} { ln mathcal{N}(x_n| mu, lambda^{-1}) } + ln mathcal{N}( mu|m,( beta lambda)^{-1}) + ln Gam( lambda|a,b) - ln mathcal{N}( mu| hat{m},( hat{ beta} lambda)^{-1}) + const. &amp;=&amp; Sigma_{n=1}^{N} { frac{1}{2} ln lambda - frac{(x_n- mu)^2 lambda}{2} } + frac{ ln beta + ln lambda}{2} - frac{( mu-m)^2 beta lambda}{2} + (a-1) ln lambda -b lambda - frac{ ln hat{ beta} + ln lambda}{2} + frac{( mu- hat{m})^2 hat{ beta} lambda}{2} + const. &amp;=&amp; ( frac{N}{2} + a - 1) ln lambda - frac{1}{2} { Sigma_{n=1}^{N} x_n^2 - 2 mu Sigma_{n=1}^{N} x_n + N mu^2 + beta mu^2 - 2 mu m beta + m^2 beta + 2 b - mu^2 hat{ beta} + 2 mu hat{m} hat{ beta} - hat{m}^2 hat{ beta} } lambda + const. &amp;=&amp; ( frac{N}{2} + a - 1) ln lambda - frac{1}{2} { Sigma_{n=1}^{N} x_n^2 + 2 mu( hat{m} hat{ beta}- Sigma_{n=1}^{N} x_n - m beta) + (N + beta - hat{ beta}) mu^2 + m^2 beta - hat{m}^2 hat{ beta} + 2b } lambda + const. &amp;=&amp; ( frac{N}{2} + a - 1) ln lambda - { frac{1}{2}( Sigma_{n=1}^{N} x_n^2 + beta m^2 - hat{ beta} hat{m}^2) + b } lambda + const. end{eqnarray} $$ガンマ分布の定義式と照らし合わせて . $$ begin{eqnarray} p( lambda| mathcal{D}) &amp;=&amp; Gam( lambda| hat{a}, hat{b}) ただし　 hat{a} &amp;=&amp; frac{N}{2} + a hat{b} &amp;=&amp; frac{1}{2}( Sigma_{n=1}^{N} x_n^2 + beta m^2 - hat{ beta} hat{m}^2) + b end{eqnarray} $$&#12414;&#12392;&#12417; . 結局求めたい事後分布$p( mu| lambda, mathcal{D})p( lambda| mathcal{D})$は更新されたハイパーパラメータ$ hat{m}, hat{ beta}, hat{a}, hat{b}$を持つガウス・ガンマ分布の形になる。 . $$ begin{eqnarray} p( mu| lambda, mathcal{D})p( lambda| mathcal{D}) &amp;=&amp; mathcal{N}( mu| hat{m},( hat{ beta} lambda)^{-1})Gam( lambda| hat{a}, hat{b}) &amp;=&amp; NG( mu, lambda| hat{m}, hat{ beta}, hat{a}, hat{b}) end{eqnarray} $$&#20104;&#28204;&#20998;&#24067;&#12398;&#23566;&#20986; . 事前分布と事後分布が同じ形状であるから、学習前の予測分布を導出し、更新されたハイパーパラメータを代入することで学習後の予測分布を求めることができる。 . 学習前の予測分布は以下のように2つの変数を積分除去することで求められる。 . $$p(x_*) = int int p(x_*| mu, lambda)p( mu, lambda)d mu d lambda$$ . でもできれば積分はしたくないのでベイズの定理から求めてみる。 . . Note: 積分は式変形も面倒だしコンピュータにとっても計算コストが高いのでできるだけしたくない。いかに積分を回避するかが肝。 . ベイズの定理から . $$ p( mu, lambda|x_*) = frac{p(x_*| mu, lambda)p( mu, lambda)}{p(x_*)} $$より . $$ ln p(x_*) = ln p(x_*| mu, lambda) - ln p( mu, lambda|x_*) + const. $$事後分布の結果を流用して、 . $$ begin{eqnarray} p( mu, lambda|x_*) &amp;=&amp; mathcal{N}( mu|m(x_*), {(1+ beta) lambda }^{-1})Gam( lambda| frac{1}{2}+a,b(x_*)) ただし　m(x_*) &amp;=&amp; frac{x_*+ beta m}{1+ beta} b(x_*) &amp;=&amp; frac{ beta}{2(1+ beta)}(x_*-m)^2 + b end{eqnarray} $$ . Note: $m(x_*),b(x_*)$の導出 . $ hat{m}, hat{b}$を$ mathcal{D}=x_*$として計算すると . $$ begin{eqnarray} hat{m} &amp;=&amp; frac{1}{ hat{ beta}}( Sigma_{n=1}^{N} x_n + beta m) &amp;=&amp; frac{1}{1+ beta}(x_*+ beta m) end{eqnarray} $$$$ begin{eqnarray} hat{b} &amp;=&amp; frac{1}{2}( Sigma_{n=1}^{N} x_n^2 + beta m^2 - hat{ beta} hat{m}^2) + b &amp;=&amp; frac{1}{2} {x_*^2 + beta m^2 - (1+ beta)( frac{x_*+ beta m}{1+ beta})^2 } + b &amp;=&amp; frac{1}{2(1+ beta)} {(1+ beta)(x_*^2+ beta m^2) - x_*^2 - 2x_* beta m - beta^2 m^2 } + b &amp;=&amp; frac{1}{2(1+ beta)} { beta x_*^2 - 2 beta x_* m + beta m^2 } +b &amp;=&amp; frac{ beta}{2(1+ beta)}(x_*-m)^2 + b end{eqnarray} $$ よって予測分布$p(x_*)$は . $$ begin{eqnarray} ln p(x_*) &amp;=&amp; ln mathcal{N}(x_*| mu, lambda) - ln mathcal{N}( mu|m(x_*), {(1+ beta) lambda }^{-1}) - ln Gam( lambda| frac{1}{2}+a,b(x_*)) + const. &amp;=&amp; frac{1}{2} ln lambda - frac{(x_*- mu)^2 lambda}{2} - frac{ ln(1+ beta) + ln lambda}{2} + frac{( mu-m(x_*))^2(1+ beta) lambda}{2} - (a- frac{1}{2}) ln lambda + b(x_*) lambda - ln C_G(a+ frac{1}{2}, b(x_*)) + const. &amp;=&amp; - frac{(x_*- mu)^2 lambda}{2}+ frac{( mu-m(x_*))^2(1+ beta) lambda}{2}+ b(x_*) lambda - (a+ frac{1}{2}) ln b(x_*) + const. end{eqnarray} $$ . Note: $x_*$について整理する。気合で計算する。 . $$ begin{eqnarray} ln p(x_*) &amp;=&amp; - frac{(1+ beta) lambda}{2(1+ beta)}x_*^2 + frac{2(1+ beta) mu lambda}{2(1+ beta)}x_* + frac{(1+ beta)^2 lambda}{2(1+ beta)}m(x_*)^2 - frac{2(1+ beta)^2 mu lambda}{2(1+ beta)} m(x_*) + frac{ beta lambda}{2(1+ beta)} x_*^2 - frac{2 beta m lambda}{2(1+ beta)}x_* - (a+ frac{1}{2}) ln b(x_*) + const. &amp;=&amp; frac{ beta lambda - (1+ beta) lambda}{2(1+ beta)} x_*^2 + frac{2(1+ beta) mu lambda - 2 beta m lambda}{2(1+ beta)} + frac{ lambda}{2(1+ beta)} x_*^2 + frac{2 beta m lambda}{2(1+ beta)} x_* - frac{2(1+ beta) mu lambda}{2(1+ beta)}x_* - (a+ frac{1}{2}) ln b(x_*) + const. &amp;=&amp; -(a+ frac{1}{2}) ln b(x_*) + const. &amp;=&amp; - frac{1+2a}{2} ln { frac{ beta}{2(1+ beta)}(x_*-m)^2 + b } + const. &amp;=&amp; - frac{1+2a}{2} ln {1 + frac{ beta}{2(1+ beta)b}(x_*-m)^2 } + const. end{eqnarray} $$これはStudentのt分布になる。 . $$ begin{eqnarray} p(x_*) &amp;=&amp; St(x_*| mu_s, lambda_s, nu_s) ただし　 mu_s &amp;=&amp; m lambda_s &amp;=&amp; frac{ beta a}{(1+ beta)b} nu_s &amp;=&amp; 2a end{eqnarray} $$ したがって学習後の予測分布$p(x_*| mathcal{D})$は更新されたハイパーパラメータを代入して . $$ begin{eqnarray} p(x_*| mathcal{D}) &amp;=&amp; St(x_*| mu_s, lambda_s, nu_s) ただし　 mu_s &amp;=&amp; frac{ Sigma_{n=1}^{N} x_n + beta m}{N+ beta} lambda_s &amp;=&amp; frac{N+ beta frac{N}{2}+a}{(1+N+ beta)( frac{ Sigma_{n=1}^{N} x_n^2 + beta m^2 - (N+ beta)( frac{ Sigma_{n=1}^{N} x_n + beta m}{N+ beta})^2}{2} + b)} nu_s &amp;=&amp; N + 2a end{eqnarray} $$疲れましたね。 . 1. 須山敦志. ベイズ推論による機械学習入門. 講談社, 2017↩ .",
            "url": "https://vintea01.github.io/tpt-medical-it/bayes/2020/04/03/bayes_part3.html",
            "relUrl": "/bayes/2020/04/03/bayes_part3.html",
            "date": " • Apr 3, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "ベイズ勉強会 Part 2 ベルヌーイ分布のベイズ推論",
            "content": "ベイズ勉強会資料は『ベイズ推論による機械学習入門』1を元に、途中式計算をできるだけ省略せずに行ったものです。 . &#27010;&#35542;: &#12505;&#12523;&#12492;&#12540;&#12452;&#20998;&#24067; . ベルヌーイ分布は次の確率質量関数で表される確率分布である。 . この確率質量関数は確率$ mu$で1、$1- mu$で0を出力する。 . . Important: ベルヌーイ分布の確率質量関数$$Bern(x| mu) = mu^x (1- mu)^{1-x}　(x in {0, 1 }, mu in (0, 1))$$ . &#21839;&#38988; . 今N個のデータ点$ mathcal{D} = {x_1, x_2, dots, x_N }　(x_1, dots, x_N in {0, 1 })$が得られたとする。未知のデータ点$x_*$を予測するためにベイズ推測を行いたい。 . この問題が解ければ、コインを投げた時表が出る確率はどの程度かをベイズ推測で評価できるようになる。 . &#12514;&#12487;&#12523;&#27083;&#31689; . $ mathcal{D}, x_*, mu$で同時分布を構築する。データ点のとりうる値が2値なので、$ mathcal{D}, x_*$が$ mu$をパラメータに持つベルヌーイ分布から生成されているとする。$ mathcal{D}, x_*, mu$の関係をDAGで描くと以下のようになる。 . . よって同時分布は . $$ p( mathcal{D}, x_*, mu) = p( mathcal{D}| mu)p(x_*| mu)p( mu) $$という尤度関数×事前分布の形で書ける。 . &#23588;&#24230;&#38306;&#25968; . データ点はベルヌーイ分布から独立に生成されるとしているので . $$ p( mathcal{D}| mu) = Pi_{n=1}^{N} Bern(x_n| mu) p(x_*| mu) = Bern(x_*| mu) $$と書ける。 . &#20107;&#21069;&#20998;&#24067; . 事前分布$p( mu)$は$ mu in (0,1)$を満たすような確率分布である必要がある。これを満たす確率分布に、ベータ分布がある。 . . Important: ベータ分布の確率密度関数 . $$Beta( mu|a, b) = C_B(a,b) mu^{a-1} (1- mu)^{b-1}$$$$ただし, C_B (a,b) = frac{ Gamma(a+b)}{ Gamma(a) Gamma(b)}, mu in (0, 1), {a, b } in mathbb{R^+}を満たす.$$ $a, b$がベータ分布のパラメータである。 . . Note: ベータ分布の係数とガンマ関数 . $C_B(a,b)$は正規化されることを保証する係数である。$C_B(a,b)$中の$ Gamma(・)$はガンマ関数である。ガンマ関数は自然数に定義される階乗を一般化したものであり、正の実数$x in mathbb{R^+}$に対して、 . $$ Gamma(x) = int t^{x-1} e^{-t} dt$$と定義される。重要な性質として . $$ begin{eqnarray} Gamma(x+1) &amp;=&amp; x Gamma(x) Gamma(1) &amp;=&amp; 1 end{eqnarray}$$を満たし、自然数nに対しては . $$ Gamma(n+1) = n!$$が成り立つ。 . ベータ分布を用いることで事前分布$p( mu)$は . $$ p( mu) = Beta( mu|a, b) $$と定義できる。$a,b$も加えてDAGを描き直すと次のように描ける。 . . 更に$a,b$を出力する確率分布を考えることもできるが、モデルを複雑化すると計算も煩雑になるのでここまでにしておく。では$a,b$の値はどうするのかというと、事前に決めておくことになる。このような変数を、パラメータのためのパラメータということで、超パラメータ(ハイパーパラメータ)と呼ぶ。 . &#12414;&#12392;&#12417; . まとめると、推論のためのモデルは次のように書ける。 . $$ begin{eqnarray} p( mathcal{D}, x_*, mu) &amp;=&amp; p( mathcal{D}| mu)p(x_*| mu)p( mu) p( mathcal{D}| mu) &amp;=&amp; Pi_{n=1}^{N} Bern(x_n| mu) p(x_*| mu) &amp;=&amp; Bern(x_*| mu) p( mu) &amp;=&amp; Beta( mu|a,b) end{eqnarray} $$&#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . 実際に$ mathcal{D}$を観測した後の事後分布$p( mu| mathcal{D})$を求める。 . . Note: モデルの事後分布は$p(x_*, mu| mathcal{D}) = p(x_*| mu)p( mu| mathcal{D})$だがデータからの学習に関わるのは$p( mu| mathcal{D})$の部分のみ。学習のみに推論を絞ってこちらを事後分布と呼ぶ場合も多い。本節でも$p( mu| mathcal{D})$を事後分布と呼ぶ。 . ベイズの定理を用いて、 . $$ begin{eqnarray} p( mu| mathcal{D}) &amp;=&amp; frac{p( mathcal{D}| mu)p( mu)}{p( mathcal{D})} &amp;=&amp; frac{ { Pi_{n=1}^{N}p(x_n| mu) }p( mu)}{p( mathcal{D})} &amp; propto&amp; { Pi_{n=1}^{N}p(x_n| mu) }p( mu) end{eqnarray} $$である。分母は正規化されていることを保証する項であり、分布形状を決めるのは分子の部分であるため3行目では省略している。ベルヌーイ分布もベータ分布も指数部分があり、対数をとると計算が楽になる。 . $$ begin{eqnarray} ln p( mu| mathcal{D}) &amp;=&amp; Sigma_{n=1}^{N} ln p(x_n| mu) + ln p( mu) + const.　(対数化により分母は定数項に) &amp;=&amp; Sigma_{n=1}^{N} ln( mu^{x_n} (1- mu)^{1-x_n}) + ln(C_B(a,b) mu^{a-1} (1- mu)^{b-1}) + const.　(ベルヌーイ分布, ベータ分布の式を代入) &amp;=&amp; Sigma_{n=1}^{N} x_n ln mu + Sigma_{n=1}^{N} (1-x_n) ln (1- mu) + (a-1) ln mu + (b-1) ln (1- mu) + const.　(C_B(a,b)は対数化によりconst.に吸収) &amp;=&amp; ( Sigma_{n=1}^{N} x_n + a - 1) ln mu + (N - Sigma_{n=1}^{N} x_n + b - 1) ln (1- mu) + const. end{eqnarray} $$対数を元に戻すと . $$ p( mu| mathcal{D}) propto mu^{( Sigma_{n=1}^{N} x_n + a - 1)} (1- mu)^{N - Sigma_{n=1}^{N} x_n + b - 1} $$でありこれはベータ分布の形である。なお定数項は正規化されることを保証する係数となっている。つまり . $$ begin{eqnarray} p( mu| mathcal{D}) &amp;=&amp; Beta( mu| hat{a}, hat{b}) ただし　 hat{a} &amp;=&amp; Sigma_{n=1}^{N} x_n + a hat{b} &amp;=&amp; N - Sigma_{n=1}^{N} x_n + b end{eqnarray} $$となる。 . . Note: このように、特定の確率分布のパラメータの事前分布とすることで、事後分布が事前分布と同じ形になる確率分布を共役事前分布という。ベルヌーイ分布の共役事前分布はベータ分布である。 . . Note: ベルヌーイ分布の場合は、成功確率パラメータである$ mu$をベータ分布で幅を持たせて推定できることがベイズ推論の意義となる。 . . Note: $N$はデータ点の個数、$ Sigma_{n=1}^{N} x_n$は値が1だったデータ点の個数である。ハイパーパラメータ$a,b$をデータの情報で更新しているという見方ができる。また、$N$が大きくなると、$a,b$が無視できる、すなわちハイパーパラメータが結果に影響しなくなることがわかる。 . &#20104;&#28204;&#20998;&#24067;&#12398;&#31639;&#20986; . 未知のデータ点$x_*$の予測分布$p(x_*| mathcal{D})$は$p(x_*, mu| mathcal{D}) = p(x_*| mu)p( mu| mathcal{D})$をパラメータ$ mu$について周辺化することで求まる。 . $$ begin{eqnarray} p(x_*| mathcal{D}) &amp;=&amp; int p(x_*| mu)p( mu| mathcal{D}) d mu &amp;=&amp; int Bern(x_*| mu) Beta( mu| hat{a}, hat{b}) d mu &amp;=&amp; C_B( hat{a}, hat{b}) int mu^{x_*} (1- mu)^{1-x_*} mu^{ hat{a}-1}(1- mu)^{ hat{b}-1}d mu &amp;=&amp; C_B( hat{a}, hat{b}) int mu^{x_* + hat{a} -1}(1- mu)^{1-x_*+ hat{b}-1}d mu end{eqnarray} $$ここでベータ分布の定義式から . $$ int mu^{x_* + hat{a} -1}(1- mu)^{1-x_*+ hat{b}-1}d mu = frac{1}{C_B(x_* + hat{a}, 1-x_* + hat{b})} $$となる。 . . Note: ベータ分布は確率分布なので積分した時1になる。つまり係数$C_B$以外の部分を積分した時の値は係数$C_B$の逆数である。$ int mu^{x_* + hat{a} -1}(1- mu)^{1-x_*+ hat{b}-1}d mu$はベータ分布の積分から係数$C_B$の部分を除いた形になっている。 . したがって、 . $$ begin{eqnarray} p(x_*| mathcal{D}) &amp;=&amp; frac{C_B( hat{a}, hat{b})}{C_B(x_* + hat{a}, 1-x_* + hat{b})} &amp;=&amp; frac{ Gamma( hat{a}+ hat{b}) Gamma(x_* + hat{a}) Gamma(1-x_* + hat{b})}{ Gamma( hat{a}) Gamma( hat{b}) Gamma( hat{a}+ hat{b}+1)} end{eqnarray} $$複雑な式になっているが$x_*$は0か1しかとり得ないことを利用するともっと単純に書ける。 . $$ begin{eqnarray} p(x_* = 1| mathcal{D}) &amp;=&amp; frac{ Gamma( hat{a}+ hat{b}) Gamma(1 + hat{a}) Gamma( hat{b})}{ Gamma( hat{a}) Gamma( hat{b}) Gamma( hat{a}+ hat{b}+1)} &amp;=&amp; frac{ Gamma( hat{a}+ hat{b}) hat{a} Gamma( hat{a}) Gamma( hat{b})}{ Gamma( hat{a}) Gamma( hat{b})( hat{a}+ hat{b}) Gamma( hat{a}+ hat{b})} &amp;=&amp; frac{ hat{a}}{ hat{a}+ hat{b}} p(x_* = 0| mathcal{D}) &amp;=&amp; frac{ Gamma( hat{a}+ hat{b}) Gamma( hat{a}) Gamma(1 + hat{b})}{ Gamma( hat{a}) Gamma( hat{b}) Gamma( hat{a}+ hat{b}+1)} &amp;=&amp; frac{ hat{b}}{ hat{a}+ hat{b}} end{eqnarray} $$より . $$ begin{eqnarray} p(x_*| mathcal{D}) &amp;=&amp; ( frac{ hat{a}}{ hat{a}+ hat{b}})^{x_*} ( frac{ hat{b}}{ hat{a}+ hat{b}})^{1-x_*} &amp;=&amp; ( frac{ hat{a}}{ hat{a}+ hat{b}})^{x_*} (1- frac{ hat{a}}{ hat{a}+ hat{b}})^{1-x_*} &amp;=&amp; Bern(x_*| frac{ hat{a}}{ hat{a}+ hat{b}}) &amp;=&amp; Bern(x_*| frac{ Sigma_{n=1}^{N}x_n + a}{N+a+b}) end{eqnarray} $$と予測分布はベルヌーイ分布の形で書ける。 . . Note: 予測分布についても、$N$が大きくなると、$a,b$が無視できる、すなわちハイパーパラメータが結果に影響しなくなることがわかる。また予測分布の形状が尤度関数と変わっておらず、$ mu$の点推定を行った場合の予測と結局同じことをやっているように見える(特にNが大きければ最尤推定と同じである)が、尤度関数の種類によっては予測分布の形と異なる場合がある。ポアソン分布→負の二項分布、精度未知の1次元ガウス分布→Studentのt分布などの例がある。また、事後分布として$ mu$の分布が得られている。 . 1. 須山敦志. ベイズ推論による機械学習入門. 講談社, 2017↩ .",
            "url": "https://vintea01.github.io/tpt-medical-it/bayes/2020/03/29/bayes_part2.html",
            "relUrl": "/bayes/2020/03/29/bayes_part2.html",
            "date": " • Mar 29, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "とりあえずテストしてみるよー。",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . VERSION . v&#34;1.4.0&#34; . println(&quot;hello world&quot;) . hello world . π . π = 3.1415926535897... . a = 1.1 a += 0.1 a .",
            "url": "https://vintea01.github.io/tpt-medical-it/jupyter/2020/03/27/testjulia.html",
            "relUrl": "/jupyter/2020/03/27/testjulia.html",
            "date": " • Mar 27, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "自分のサイトを作ろう",
            "content": "概要 . 公式のドキュメントにしたがって作成したデフォルトのサイトを自分のサイトにするための設定項目。 . 変更するファイル . _config.yml | _pages/about.md | images/favicon.ico | . _config.yml . サイト名などの主要な設定項目は_config.ymlに含まれている。変更するのは以下の要素。 . title . サイト名になる。 . description . サイトの概要。ブラウザのタブにtitleともに表示される。 . minima: social_links: . GitHubとTwitterアカウント。 . use_math . TeX記法を使う場合はtrueにしておく。 . show_description . ホーム画面に各記事の概要を表示する。デフォルトでfalse。 . default_badges . 記事にGitHubやBinder, Colabへのリンクバッジが貼られる。使わないならfalseにする。 . _pages/about.md . 自己紹介や団体紹介を書いておく。 . images/favicon.ico . ブラウザのタブに表示されるマーク。団体ロゴなどの画像ファイルの名前をfavicon.icoにすればいい。 .",
            "url": "https://vintea01.github.io/tpt-medical-it/markdown/2020/03/27/fastpages.html",
            "relUrl": "/markdown/2020/03/27/fastpages.html",
            "date": " • Mar 27, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "ベイズ勉強会 Part 1 ベイズ推論のワークフロー",
            "content": "ベイズ勉強会資料は『ベイズ推論による機械学習入門』1を元に、途中式計算をできるだけ省略せずに行ったものです。 . &#27010;&#35542;: &#12505;&#12452;&#12474;&#25512;&#35542;&#12398;&#12527;&#12540;&#12463;&#12501;&#12525;&#12540; . . Important: ベイズ推論の共通するワークフロー . 観測データ$ mathcal{D}$と観測されていない未知の変数$ mathbf{X}$の同時分布$p( mathcal{D}, mathbf{X})$を構築 | 事後分布$p( mathbf{X}| mathcal{D}) = frac{p( mathcal{D}, mathbf{X})}{p( mathcal{D})}$を求める。 | 今回はさらに事後分布を用いて予測分布を計算するところまでを見る。 . &#20104;&#28204;&#20998;&#24067; . 観測されたデータ$ mathcal{D}$に対して、パラメタ$ theta$を持つ確率分布でモデルを組み、新しいデータ$x_*$を予測したい。$ mathcal{D}$と$x_*$が独立に生成されるとすると、以下のような予測分布を用いることができる。 . $$p(x_*| mathcal{D}) = int p(x_*| theta)p( theta| mathcal{D}) d theta$$ . $ mathcal{D}$, $ theta$, $x_*$の関係をDAGで表すと次のようになる。 . . この時、$ mathcal{D}$と$x_*$はパラメタ$ theta$が与えられた条件の下での条件付き独立である。 . &#21516;&#26178;&#20998;&#24067;&#12398;&#35352;&#36848; . $ mathcal{D}$と$x_*$がパラメタ$ theta$が与えられた条件の下での条件付き独立であることから同時分布は以下のようになる。 $$ p( mathcal{D}, x_*, theta) = p( mathcal{D}| theta)p(x_*| theta)p( theta) $$ . . Note: $p( theta)$は2個必要なのではないかと思うかもしれない。サイコロの目によって動きが決まる駒が2つあり、同時に動かす状況を考えよう。コマの動きを決めるのにサイコロを振る回数は1回である。 . . Note: $p( mathcal{D}| theta)$の部分はパラメタからデータが生成される過程を記述している。これを$ theta$の関数として見た場合尤度関数と呼ぶ。この尤度関数を最大化する$ theta$を$ theta$の予測値とする方法を最尤推定という。 . . Note: $p( theta)$を事前分布という。同時確率は尤度関数×事前分布の形で書くことができる。 . &#20107;&#24460;&#20998;&#24067;&#12398;&#25512;&#35542; . データ$ mathcal{D}$だけが手元にある時、残りの変数の事後分布は $$ begin{eqnarray} p(x_*, theta| mathcal{D}) &amp;=&amp; frac{p( mathcal{D}, x_*, theta)}{p( mathcal{D})} &amp;=&amp; frac{p( mathcal{D}| theta)p(x_*| theta)p( theta)}{p( mathcal{D})} &amp;=&amp; p(x_*| theta)p( theta| mathcal{D}) end{eqnarray} $$ となる。 . . Note: ベイズの定理から$p( theta| mathcal{D}) = frac{p( mathcal{D}| theta)p( theta)}{p( mathcal{D})}$となることを用いた。 . . Note: $p( theta| mathcal{D})$を最大化する$ theta$を$ theta$の予測値とする方法を事後確率最大化推定(MAP推定)と呼ぶ。 . &#20104;&#28204;&#20998;&#24067;&#12398;&#31639;&#20986; . $ mathcal{D}$が決まった時の$x_*$の確率分布、すなわち予測分布$p(x_*| mathcal{D})$は$ theta$を積分除去することで得られる。 . $$p(x_*| mathcal{D}) = int p(x_*| theta)p( theta| mathcal{D}) d theta$$ . 以上がベイズ推論の予測までを含めた一連の流れである。次回から離散確率分布について具体的にやってみる。 . 1. 須山敦志. ベイズ推論による機械学習入門. 講談社, 2017↩ .",
            "url": "https://vintea01.github.io/tpt-medical-it/bayes/2020/03/27/bayes_part1.html",
            "relUrl": "/bayes/2020/03/27/bayes_part1.html",
            "date": " • Mar 27, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://vintea01.github.io/tpt-medical-it/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://vintea01.github.io/tpt-medical-it/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "T/Tは東京医科歯科大学の医学生で結成されたデータサイエンスサークルです。 .",
          "url": "https://vintea01.github.io/tpt-medical-it/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}